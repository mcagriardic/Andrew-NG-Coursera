{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.integrate import simps\n",
    "%matplotlib inline\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2data2 = np.loadtxt(\"data/ex2data2.txt\", delimiter=\",\")\n",
    "\n",
    "exam_1_score = ex2data2[:, 0]\n",
    "\n",
    "exam_1_score = ex2data2[:, 0]\n",
    "exam_2_score = ex2data2[:, 1]\n",
    "\n",
    "X = ex2data2[:, :-1]\n",
    "y = ex2data2[:, -1]\n",
    "exam_2_score = ex2data2[:, 1]\n",
    "\n",
    "X = ex2data2[:, :-1]\n",
    "y = ex2data2[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLogisticRegression:\n",
    "\n",
    "    def __init__(self,\n",
    "                 X,\n",
    "                 y,\n",
    "                 alfa=0.001,\n",
    "                 num_iter=100000,\n",
    "                 fit_intercept=True,\n",
    "                 weights_to_initialise=0):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y.reshape(len(y), 1)\n",
    "\n",
    "        self._fit_intercept = fit_intercept\n",
    "        self._alfa = alfa\n",
    "        self._num_iter = num_iter\n",
    "        self._m = X.shape[0]\n",
    "        self._n = (X.shape[1] + 1) if fit_intercept else X.shape[1]\n",
    "\n",
    "        self.thetas = None\n",
    "        \n",
    "        self._add_constant()\n",
    "        self._initalise_θ(weights_to_initialise)\n",
    "\n",
    "\n",
    "    def _add_constant(self):\n",
    "        if self._fit_intercept:\n",
    "            constants = np.ones((self._m, 1))\n",
    "            self.X = np.concatenate((constants, self.X), axis=1)\n",
    "\n",
    "\n",
    "    def _initalise_θ(self, weight_to_initialise):\n",
    "        self.thetas = np.zeros(\n",
    "            self._n\n",
    "        ) + weight_to_initialise\n",
    "\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return (1 / (1 + np.exp(-z)))\n",
    "\n",
    "\n",
    "    def _h(self):\n",
    "        z = (self.X @ self.thetas.reshape(-1, 1))\n",
    "        return self._sigmoid(z)\n",
    "\n",
    "\n",
    "    def _calculate_cost(self, LAMBDA):\n",
    "        epsilon = 1e-5 # to silence the \"RuntimeWarning: divide by zero encountered in log\" errors\n",
    "        h = self._h()\n",
    "        regularisation = (LAMBDA / self._m * 2) * np.sum(np.square(self.thetas[1:]))\n",
    "\n",
    "        return np.mean(-1 * (\n",
    "            (self.y) * np.log(h + epsilon)\n",
    "            + (1 - self.y) * np.log(1 - h + epsilon)  \n",
    "        )) + regularisation\n",
    "\n",
    "\n",
    "    def _gradient(self, LAMBDA):\n",
    "        h = self._h()\n",
    "        regularisation = (LAMBDA / self._m) * self.thetas[1:]\n",
    "        regularisation_theta_0_added = np.insert(regularisation, 0, 0, axis=0).reshape(self._n, 1)\n",
    "        \n",
    "        gradient = (1 / self._m) * self.X.T @ (h - self.y) + regularisation_theta_0_added\n",
    "        return gradient.flatten()\n",
    "\n",
    "\n",
    "    def fit(self, LAMBDA=1, verbose=False):\n",
    "        print(\"COST: {}\".format(self._calculate_cost(LAMBDA=LAMBDA)))\n",
    "        print(self.thetas)\n",
    "        for i in range(self._num_iter):\n",
    "            self.thetas -= self._alfa * self._gradient(LAMBDA=LAMBDA)\n",
    "            if (i % 50000 == 0):\n",
    "                print(\"COST: {}\".format(self._calculate_cost(LAMBDA=LAMBDA)))\n",
    "                if verbose:\n",
    "                    print(self.thetas)\n",
    "\n",
    "\n",
    "    def predict_prob(self):\n",
    "        return self._sigmoid(self.X @ self.thetas)\n",
    "\n",
    "\n",
    "    def predict_prob_single_instance(self, index):\n",
    "        prob_matrix = self._sigmoid(self.X @ self.thetas)\n",
    "        \n",
    "        exam_scores = \"Exam Score 1: %.3f\\nExam Score 2: %.3f\" % (self.X[index, 1], self.X[index, 2])\n",
    "        probability = \"Probability of Being Admitted: %.2f%%\" % (prob_matrix[index] * 100)\n",
    "        print(exam_scores); print(probability)\n",
    "\n",
    "\n",
    "    def predict(self, threshold=0.5):\n",
    "        prediction = self.predict_prob()\n",
    "        prediction[prediction > threshold] = 1\n",
    "        prediction[prediction <= threshold] = 0\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(data, label_x, label_y, label_pos, label_neg, axes=None):\n",
    "    # Get indexes for class 0 and class 1\n",
    "    neg = data[:,2] == 0\n",
    "    pos = data[:,2] == 1\n",
    "    \n",
    "    # If no specific axes object has been passed, get the current axes.\n",
    "    if axes == None:\n",
    "        axes = plt.gca()\n",
    "    axes.scatter(data[pos][:,0], data[pos][:,1], marker='+', c='k', s=60, linewidth=2, label=label_pos)\n",
    "    axes.scatter(data[neg][:,0], data[neg][:,1], c='y', s=60, label=label_neg)\n",
    "    axes.set_xlabel(label_x)\n",
    "    axes.set_ylabel(label_y)\n",
    "    axes.legend(frameon= True, fancybox = True);\n",
    "\n",
    "\n",
    "def calculate_model_performance(actual, predicted):\n",
    "    TP = 0; TN = 0; FP = 0; FN = 0\n",
    "\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        if act == 1:\n",
    "            if act == pred:    TP += 1\n",
    "            else:              FN += 1\n",
    "        else:\n",
    "            if act == pred:    TN += 1\n",
    "            else:              FP += 1\n",
    "\n",
    "    def specificity():\n",
    "        return TN / (TN + FP) * 100\n",
    "\n",
    "    def sensitivity_recall():\n",
    "        return TP / (TP + FN) * 100\n",
    "\n",
    "    def accuracy():\n",
    "        return (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "\n",
    "    def prevalence():\n",
    "        return (TP + FN) / (TP + TN + FP + FN) * 100\n",
    "\n",
    "    def precision():\n",
    "        return TP / (TP + FP) * 100\n",
    "    \n",
    "    def false_positive():\n",
    "        return FP / (FP + TN) * 100\n",
    "    \n",
    "    def F1():\n",
    "        return (2 * (\n",
    "                (precision() * sensitivity_recall())\n",
    "                / (precision() + sensitivity_recall())\n",
    "            ))\n",
    "\n",
    "    model_metrics = {\n",
    "        \"specificty\": specificity(),\n",
    "        \"sensitivity/recall\": sensitivity_recall(),\n",
    "        \"accuracy\": accuracy(),\n",
    "        \"prevalence\": prevalence(),\n",
    "        \"precision\": precision(),\n",
    "        \"F1\": F1(),\n",
    "        \"false_positive_rate\": false_positive()\n",
    "    }\n",
    "    return model_metrics\n",
    "\n",
    "\n",
    "def plot_ROC(\n",
    "    RLogReg_instance,\n",
    "    threshold_spacing=50,\n",
    "    verbose=False\n",
    "):\n",
    "    false_positive_rate = []\n",
    "    true_positive_rate = []\n",
    "    actual = RLogReg_instance.y\n",
    "\n",
    "    for threshold in np.linspace(0, 0.95, threshold_spacing):\n",
    "        predicted = RLogReg_instance.predict(threshold)\n",
    "        model_metrics = calculate_model_performance(actual, predicted)\n",
    "        false_positive_rate.append(model_metrics[\"false_positive_rate\"])\n",
    "        true_positive_rate.append(model_metrics[\"sensitivity/recall\"])\n",
    "        if verbose:\n",
    "            print(\"Threshold: %.3f \\nF1:%s\\n\" %(threshold, model_metrics[\"F1\"]))\n",
    "            \n",
    "    #Here we multiply with -1 because recall is in decreasing order and therefore,\n",
    "    #np.trapz returns a negative value. However, taking the integral of an equation\n",
    "    #should return us the area under a curve which cannot be negative.\n",
    "    AUC = -1 * np.trapz(y=true_positive_rate, x=false_positive_rate) \n",
    "    \n",
    "    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(false_positive_rate, true_positive_rate)\n",
    "    plt.plot([0, 100], [0, 100])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    # AUC is divided by 100 here because in calculate_model_performance function,\n",
    "    # these metrics are multiplied by 100\n",
    "    plt.title(\"ROC Curve - AUC %.3f\" %(AUC/100)) \n",
    "    plt.legend([\"Logistic Regression\", \"Random guess\"], loc='lower right');\n",
    "\n",
    "\n",
    "def calculate_decision_boundary_values(coefficients, X):\n",
    "    x1 = X[:, 1]\n",
    "    x2 = (-1 / coefficients[2]) * (coefficients[0] + coefficients[1] * x1)\n",
    "    return x1, x2\n",
    "\n",
    "\n",
    "def plot_decision_boundary(coefficients, X):\n",
    "    x1, x2 = calculate_decision_boundary_values(coefficients, X)\n",
    "    plt.plot(x1,x2,'r-',label='Decision Boundary');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2de7RdVXX/P98ESMSAJCE3IrkxUGgU0BHIBUQUBUHRdgAqxUT9NdYwCNWqhdqCP6xarKPR+oPir75SRKIiUVIp8UEREh6VguZGnsHflRiEXB65l4CU8Lhccufvj70P2bn3vM9+nj0/Y5xxzll77b3nXmefPdeac665ZGY4juM4TqtMyloAx3Ecp5i4AnEcx3HawhWI4ziO0xauQBzHcZy2cAXiOI7jtMVuWQuQJvvuu6/NmzcvazEcx3EKxYYNGx43s1njy0ulQObNm0d/f3/WYjiO4xQKSQ9WK3cTluM4jtMWrkAcx3GctnAF4jiO47RFqXwgjuM4zTA6Osrg4CDPP/981qKkytSpU5kzZw677757U/VdgTiO44xjcHCQvfbai3nz5iEpa3FSwczYtm0bg4ODHHDAAU3t4yYsx3GccTz//PPMnDmzNMoDQBIzZ85sadTlCsRxHKcKZVIeFVq9ZjdhOaXGbIyhoSvZsuViRka2MGVKL72959DTsxjJ+1eOUw//hzilxWyMe+99DwMDy9i+fQOjo0Ns376BgYFlbNz4XszGshbRcWLjlltu4YgjjmC33XZj9erVsRzTFYhTWoaGruTJJ29gbOyZXcrHxp7hiSeuZ2hoVUaSOUVEUq7NXnPnzuXyyy/n/e9/f2zHdAXilJYtWy6eoDwqjI09w5YtF6UsUTKYjbF16xX09/dx662z6e/vY+vWK3yElWP+/u//nksuueSl7xdccAFf+cpXOjrmvHnzeP3rX8+kSfE99t0H4pSWkZEtDbYPpiRJclTMdNGR1ujoEAMDyxgeXs2hh/67+3pyyNKlS3nPe97DJz7xCcbGxli1ahW/+tWvJtR785vfzNNPPz2h/Mtf/jInnnhi4nK6AnFKy5QpvYyODtXZPidFaZKhGTPd7NnxmTTKRjWTVbTMzNo67rx585g5cyZ33HEHW7du5fDDD2fmzJkT6v3Xf/1XW8ePC1cgTmnp7T2HgYFlVc1Ykya9nN7eczOQKl6aMdO5AsknZ555JpdffjmPPfYYH/7wh6vW8RGI42RET89ihoaumtBDnzTp5cyYcRI9PYsylC4eymCmy5LoCKMy8mh31DGed7/73XzmM59hdHSU73//+1XrZD0CceOnU1qkSRx22I+YP38F06YtZPfdZzNt2kLmz1/RNb6BKVN6G2wvvpmuW9ljjz04/vjjOeOMM5g8eXLHx1u/fj1z5szhqquuYtmyZRx66KEdH9NHIE6pkSYxe/b7u9aMUwYzXbcyNjbG7bffzlVXXRXL8Y488kgGB+MdcRa/i+U4Tk16ehYzffqJTJr08l3Ku8lMlxfMLDbz1X333cdBBx3E2972Ng4++OBYjpkEPgJxnC6mYqYbGlrFli0XMTIyyJQpc+jtPZeenkVdYabrRg455BA2b96ctRgNyVSBSLoM+FNgyMwOq7JdwCXAu4BngQ+Z2a/DbUuAT4dV/9HMVqYjdXdRtlxQnVxvUduq2810TnZkPQK5HPhX4Ds1tr8TODh8HQ18HTha0gzgs0AfYMAGSWvM7MnEJe4iyjbJrJPrLVtbOU4zZHrHm9ktwBN1qpwKfMcCbgf2kbQf8A7gejN7IlQa1wMnJy9xd1G2XFCdXG/Z2spxmiHvXab9gWgg+2BYVqvcaYG85oJKKildJ9eb17ZynCzJuwKp9hSxOuUTDyCdJalfUv/w8HCswhWdsk0y6+R6y9ZWTvcxMjLC+973Pg466CCOPvpofv/733d8zLwrkEEgOhNqDvBInfIJmNkKM+szs75Zs2YlJmgRKdsks06ut2xt5TRPUbIdf+tb32L69Ols2rSJc845h/POO6/jY+ZdgawB/lwBbwCeMrNHgeuAt0uaLmk68PawzGmB3t5zJswPqJD2JLOK2SpquqpW1gmdXG+WbVWUB1QZSWpRsiTSuV9zzTUsWbIEgNNPP521a9d2PG8lUwUi6UrgNmC+pEFJSyWdLenssMrPgM3AJuDfgI8AmNkTwOeB9eHrwrDMaYGyTTLr5HqzaitfNTHfJBVcsXTpUlauXBkeK0jn/oEPfGBCvTe/+c0sWLBgwuuGG26YUPfhhx+mtzcYSe+222684hWvYNu2bW3JVyHTMF4zW9xguwEfrbHtMuCyJOQqC3FMMotrbkSSSel2Hrf9621l3zjni3g69nyTVLbjJNK5V/s/dTq6z3oeiJMB8T30izc3opNJdc3sG3ebeDr2fJNkcEXc6dznzJnDli1bmDNnDi+++CJPPfUUM2bMaFs+cAVSOuJ8wHnveCJxt4lHf+WbJBclizud+ymnnMLKlSs55phjWL16NSeccELHI5B8dQ+dxInTZpvU3Ig4k9KlTdxt4tFfjckyyCDJ4Iq407kvXbqUbdu2cdBBB3HRRRexfPnyjo/pI5CSEadJxHvHE4m7TTwde32yNqMmuShZ3Oncp06dGtuxKvgIpGTE+YDz3vFE4m6TskXKtUrWKWaSWpTM07k7uSROm633jicSd5t4Ovb65CHIIIlsx57O3cklcT7gyrCmeKsk0Saejr02SZpRzSyRnGx5plXfY7m7LyUkTpNIGdYUbxVvk3RJyow6depUtm3bVthgjnYwM7Zt28bUqVOb3kdlaqC+vj7r7+/PWozMCeaBuEnEaY08Lqi1desVdUfU8+evaGvkNjo6yuDgIM8//3wcYhaGqVOnMmfOHHbfffddyiVtMLO+8fVdgThODZKaEV9EqkU7wc6Ra1ajq7zK1W3UUiDeso7jNCTraKdauMkwW9yJ7nQdPnKInzxEO9XCgwyywxWI40SoFnUTLSurUvJJo041XIE4mVLG0UKczui0HNtJ5nxyiosrEKcriGvkkHRa+ThTb6SZxsMnjTrVcA+T46RInM7oNB3bcc0f8tUVuwtXIE7qJLF8bSWDb3S0UK0sa+LM1ptUNuRqxBHt5Ksrdh+ZmrAknQxcAkwGLjWz5eO2XwwcH37dE+gxs33CbTuAe8JtD5nZKelI7ZSFJBRPnM7otB3bnUY7+fox3UdmCkTSZOCrwEnAILBe0hozu69Sx8zOidT/GHB45BDPmdmCtOR14iON5WvzSpzO6KI5tuMKBc7jjPiykmVrHwVsMrPNZvYCsAo4tU79xcCVqUjmFJq8ma2ixLkAUZKLGSVBHCMmN4PliywVyP5A9I4aDMsmIOnVwAHAukjxVEn9km6XdFqtk0g6K6zXPzw8HIfchSBJZ6U7QtsnzmSWRVsrJI7Eh3mdEV9WslQg1byltbqNi4DVZrYjUjY3zM3yfuBfJP1RtR3NbIWZ9ZlZ36xZszqTuCAk2UuL+9hxjhY6ccLHTS1Z4ky9UbQ0HnGMmNIMHHAak6UTfRCIdknmAI/UqLsI+Gi0wMweCd83S7qJwD/yu/jFLB5JOivz4Agtut8kztQbcRwrrfaMY60UnxGfL7LsoqwHDpZ0gKQ9CJTEmvGVJM0HpgO3RcqmS5oSft4XOBa4b/y+eScpU1CSvbRu6wHmadTS7cQxYvJllPNFZiMQM3tR0l8B1xGE8V5mZhslXQj0m1lFmSwGVtmu3aPXAt+UNEagBJdHo7eKQJKziJPspeWtB5in3FV5kiUrGo1mOh0x+Yz4fJHpPBAz+xnws3Flnxn3/XNV9vtv4HWJCpcwSZqCkgzvzCp0tNHD2WmNoiq7vCyj7KHEAeW50pyRpCkoyfDOvIaOtjIDPYmZ8LXOm8fZ8EUmD4EDHkq8E0+mmBFJmoKS7KVl1QMs8+TDJIizPdMezTRjBktyhJCHQJK84COQjEjSGdhuL62ZHngeeoCd4iOF7ibpEUK3BZJ0go9AMiJpZ2CSq7TlaQW4vNry86iIavXKJehE3LyNDpMeIeQtkCRL8t9d7FKKNos4T/hIoXXq9crvvvs0xsZ2ND5IQUh6hOChxDtxBZIReTEFJeVQTotOzVFlUUZlSgGS9Aghr4EkWeAmrAzp1BSUB3OBUwziyoTbiCTvxWYd40mHmucllDgP+Aik5LhDuRw06pU/9NCGlCRpj1Yc40mPEPJiPcgDPgJxuoZuUHhJjSob9cqHam/KBa04xtMYIeQpkCRLyqMqu4Si+yycbKjXK3/uOVi9OmWBWqQVx7iPENLDRyDOS3RDD75VyuJHqtUrf+456O+HdevyEf5ci1Yd4z5CSAdXICkSx+zYvMXc550itFEzeb46lb/SKx8aWsWWLRfx0EMbGBoKRh7r1nU2DyQNirZ8b1lQnv9YcdPX12f9/f2ZnLta9l3YaZdtZ2hdhIdj1jTODpt9GzZjekxSvjy0QSO2br2i7sTb+fNX+GgjQSRtCBfw2wU3BqZEmeLw807e/Ej1IuGapdt9YD7xNp+4AkmJJGbHeqhtdfKmINqh6PLHjTvG80lNH4ikQ4FvAvsD1wKfMrOnwm23mdkx6YjYHZQhf04RTCHgfqTxFOXa03KM+1ofzVOvNb4BLAeOBB4CfiHpgHDb1DhOLulkSQOSNkk6v8r2D0kalnRn+Dozsm2JpPvD15I45EmSJPLnJLUkbtEp8uTIqJyN5O+GkVbe8LU+WqOeAtnLzH5iZo+b2XLgHODnko4EOv4XSpoMfBV4J3AIsFjSIVWq/sDMFoSvS8N9ZwCfBY4GjgI+K2l6pzIlSdyzY/1Gd7qRrJWf+ypbo54CmSRp78oXM7sB+DPg+8DcGM59FLDJzDab2QvAKuDUJvd9B3C9mT1hZk8C1wMnxyBTYsTtBMzLjR5XLzhrB3YRKfJIK6/4Wh+tUU+B/DNwaLTAzO4ETgJ+HMO59weijoHBsGw875V0t6TVkip2oGb3RdJZkvol9Q8PD8cgdnvE7QTs9EbPuqeXFkV/mBZd/qJRBl9lnNR0opvZd2uU/x74ixjOXe3pNf6f8mPgSjMbkXQ2sBI4ocl9g0KzFcAKCOaBtC9u58TpBMzLje4OaadT8rQomE9YbI0sQwoGgahneQ7wSLSCmW0zs5Hw678BC5vdt9vphkVt3AkcHz5SaY/x95qv9dEaWSqQ9cDBkg6QtAewCFgTrSBpv8jXU4DfhJ+vA94uaXroPH97WFYa2rnR/YHt5JE8+XJ8wmJrNFQgkt7QTFmrmNmLwF8RPPh/A/zQzDZKulDSKWG1j0vaKOku4OPAh8J9nwA+T6CE1gMXhmWlIY83eqt/+Dw9OBwHfMJiqzTMhSXp12Z2xLiyDWa2sNY+eSXLXFhJEEx4CpLjjYwMMmXKHHp7z6WnZ1HDGz1v/oq8yeNkQxr3QaPRtt+DE6mVC6veTPSjgGOAWZI+Htm0N7B7/CI6reIpq51uwx/exaJeOveXA/uGdWZFyp8mmA/iOLFRpAeHj5aKjUcOxke9MN4bgRslfdvMNgMoaO09zaz6BASnMPgfxnGcTmnGI/Q5SXtL2hPYCDwgyWPZHMdxSk4zCuR1ZvY/wGnAzwnmXHwoSaEcJ294CHR3klXEX7ckQm1mSds9JO1GkKfq62b2gqRiXaXTdbjt2ikq1VYnHR0dYmBgGcPDqwsVLtyMlJcSpHOfDtwsaS6wPVGpHCdn+JwVJy7ykgg1DhoqEDO72MxeZWZvt+CfMkiQj8rJADeZOE6x6aaMv83MRJ8l6ZuSfhIWvQbwiQdO6rgfwukG8pIINQ6aMWFdDtzMzuSF9wN/k5RAjpN33GzldEI3JEKt0IwC6TGz7wNjAGY2CuxIVKockmXURNF63knJ5X4Ipxvopoy/zSiQZ8IlZA0gXNL26USlyhm+fKzjOHGRx0So7dJMGO8nCRZ2OlDSzQQr/52eqFQ5o5moifH5qIJEh1eyZcvFjIxsYcqUXnp7z6GnZ3HLIXqeesFxuodKxt92E6HmiZrZeCW9wcxuDz/vAbyWYCXA+8I1zAtHu9l4+/v72L59Q83t06YtpK9v53GrxXnDzh5GJ3HeeVUgnuHUKRNxdhCLQK1svPWu9GuVD2b2gpndZWZ3FlV5dEKrURPdFOftOFmTN1+fm7R30n2qMgFajZpIMs47rw5jd3A7ZcE7iDup5wM5UNKaWhvN7JRa27qN3t5zGBhYVlUpVIua6KY4b8dxdqWZDmJZ1uipp0CGgf+T5MklnQxcAkwGLjWz5eO2nwucCbwYyvNhM3sw3LYDuCes+lCSCq2nZzFDQ1fV9GmMj5qYMqWX0dGhmscrUpy342RBNZNVtCzLUa13EHdST4E8bWY3J3ViSZOBrwInEaRHWS9pjZndF6l2B9BnZs9K+kvgS8D7wm3PmdmCpOTbVdbWoiZaHbF0G26ycroZ7yDupJ4C+X3C5z4K2BRZrGoVQcbflxRIuKhVhduBDyYsU01aWT621RFL3slr5JfTveQ5dL3sHcQoNZ3oZvaehM+9PxAdCw6GZbVYClwb+T5VUr+k2yWdVmsnSWeF9fqHh4c7k7hJKiOW+fNXMG3aQnbffTbTpi1k/vwVmadqzltEi+MUjW6aCNgpzUwkTIpqT7GqXQxJHwT6gLdEiuea2SOSDgTWSbrHzH434YBmK4AVEMwD6Vzs5mhlxOI4TnHopomAnZKlAhlkZ4JGCFY6fGR8JUknAhcAbzGzkUq5mT0Svm+WdBNwODBBgTjtkWcnplMu8niveQcxoCkFIuk9wJsIRgi/MLOrYzj3euBgSQcADwOLGJcmXtLhwDeBk81sKFI+HXjWzEYk7QscS+Bgd6rgysBxnCRoqEAkfQ04CLgyLFom6UQz+2gnJzazFyX9FXAdQRjvZWa2UdKFQL+ZrQH+GZgGXBU+8Crhuq8FvhkurTsJWD4uesvpkDw7MSGfMjlO2aiZC+ulCtJG4LBwNUIUGPjuMbNDU5AvVtrNhdVNtPPgzePDOo8yOdng90LytJMLq8IAMDfyvRe4Oy7BHMdxnGLSjA9kJvAbSb8Kvx8J3FZJc1KmlCZlJS89O/flOE6+aEaBfCZxKZzU8Ies0w14ZyIfNFQgSaYzcZxWyLtj33HKRk0FIukXZvYmSU+z6wQ/AWZmeycuneM4ThW8M5EPaioQM3tT+L5XeuI4juM4nZDmaonNTiScDMyO1jezh2KVxHFawHubjjORastpj44OMTCwjOHh1bHn4mtmIuHHgM8CW4HKWo0GvD42KRzHcdqkWzoTcYwcmlktMc70K82MQD4BzDezbbGd1XEcx3mJuEYOaa+W2Ixa2wI8FdsZHcdxnF2Ia531tFdLrBeFVVkVZTNwk6SfAtFsuBfFKonjOE5JiWvkkPZqifVGIHuFr4eA64E9ImUemRUDZmNs3XoF/f193HrrbPr7+9i69QrMxhrv7DhO1xDXyKG395wJC11VSGK1xHphvP8Q65mcXUg7WiIpPAbfcTonrpFD2stpN3xCSbpe0j6R79MlXRerFCUkLptnkfHldR0nIK6RQ9rLaTcThTXLzP5Q+WJmT0rqiVWKEpJ2tITjpI2PThsTDd01e5GgT7/ThN3OyCHN1RKbUSA7JM2tTByU9GpqrF3uNE+c0RJp/1E9kZ3jdE41M3bAJKTd2XPPQ5k7929yvc56M1JdAPxC0nclfRe4BfhUHCeXdLKkAUmbJJ1fZfsUST8It/9S0rzItk+F5QOS3hGHPGkyZUpvg+3xRkvkhYrZKqpwqpU5TrdTy4wNY0i7MXfu3zB79vtzqzygCQViZv8JHAH8IHwtNLOOfSBhepSvAu8EDgEWSzpkXLWlwJNmdhBwMfDFcN9DCNZQPxQ4GfhaeLzCkHa0RJyY2UuvemVJ4Iom33gHoXmaMWPnnWZV2xuBt4avN8R07qOATWa22cxeAFYBp46rcyqwMvy8GnibgrvwVGCVmY2Y2QPApvB4haGnZzHTp584QYk0a/Ms6h81S+XjdB9FDoVPe9JfEjQThbWcIJ3JfeHrE5L+KYZz708wy73CYFhWtY4FHqanCFZIbGbfivxnSeqX1D88PByD2PGQdrSE46RBmh2Eig9hYGAZ27dvYHR0iO3bNzAwsIyNG9+beyXSDWbsZpzo7wIWWPhrSFoJ3EHnfpBq3eTxd1itOs3sGxSarQBWAPT19eWqi9tJtERe1kNI45zutHeqkXbiwLjp7T2HgYFlVc1YeTdjV2i2m7tP5PMrYjr3IBBVwXOAR2rVkbRbeO4nmtzXyTlutnI6oeg+hE7N2HmgmRHIPwF3SLqRoOd/HPFEYa0HDpZ0APAwgVN8fHdhDbAEuA04HVhnZiZpDfB9SRcBrwIOBn4Vg0y5p1rK5xNPhLVrs5asdZpNX52X0ZbTGkn/RkX3IVTM2ENDq9iy5SJGRgaZMmUOvb3n5jp0N4rq/cihw3oO8CJwJIEC+aWZPRbLyaV3Af8CTAYuM7MvSLoQ6DezNZKmAt8FDicYeSwys83hvhcAHw5l+2szu7bR+fr6+qy/vz8O0TOhVtx4pcdSJN9Ju9fiCsSp0N/fx/btG2punzZtIX19xf2/5wlJG8ysb0J5oz9iuOPCxCRLkSwVSByLxWzdekVdm+n8+StybfON0u61uAJxKuTx/5DmcrJpUkuBNHNFt0s6MgGZSkNc0SJFt/lGafda3G/iVMibD6HoUWHt0IwCOR64TdLvJN0t6R5JdyctWDdR1MVikqSbrsXJhryFwpcxQWozTvR3Ji5Fl1PUxWKSpJuuxcmONBMHNqKMCVKbUdH7AU+Y2YNm9iCBM/uVyYrVXRR1sZgk6aZrcRwo56i6GQXydWB75PszYZnTJHHNOE3a5ptmWoi82a8dp1O6YWZ5qzSjQGQRr2U4I70Z05cTUoTFYtJ2AObNfu10B1nmgivjqLqZMN4fATexc9TxEeB4MzstWdHiJ6sw3iLM38hjSKTjtEq2aX3y/z9vl07CeM8myMb7MEEKkaOBs+IVr7spQm+7m0KE80TesyM78VGE/3ncNDRFmdkQQZoRpwPyFC1SjTI6AJ3uIE/JNvP+P4+bmgpE0t+Z2Zck/V+qZLo1s48nKpmTKh5WG+Az3ZMh7+2ad/nySr0RyG/Cd08mUwLSTi3dzX/YPPWIy4An28yOmgrEzH4cvq+sVcfpHnp6FjM0dFVNB6CH1TpOe3Rrfiyob8JaU29HMzslfnGcrG62PKeWTrpXGfeIwXvEAXkfiaUhX7XIrNHRIQYGljE8vLrwzvV6JqxjCJaNvRL4JdVXAXRiJOubLWkHYN4fKE7xyds9VPRVExtR72n0SuB/A4cBlwAnAY+b2c1mdnMawpWNMiZjywNpruOdNWmGFee9XdOQr9vD42sqEDPbYWb/aWZLgDcAm4CbJH0sNelKRrffbK38YSsPuujDrlpZ3snLw7IM5PHe6Pbw+LrzQCRNAf4EWAzMA74C/Ch5scpJt99sjlM2uj08vuYIRNJK4L+BI4B/MLMjzezzZvZwpyeVNEPS9ZLuD9+nV6mzQNJtkjaG65C8L7LtckkPSLozfC3oVKYkaDU5YdGSsSWZfDEr80c3jhjyMJrLe7smJV+358eqmQtL0hhB5l3YdSKhADOzvds+qfQlghTxyyWdD0w3s/PG1fnj8Dz3S3oVsAF4rZn9QdLlwE/MbHUr500zF1Y7eXGKkI+q8sAZG9uRWt6fTiKZyhwFVaGRkihy2+T92rolP1bLubDMbJKZ7RW+9o689upEeYScClTml6wEJiRmNLPfmtn94edHgCFgVofnTY12HOJFSnHuDv/ikHdndjfT7fmxGmbjTeSk0h/MbJ/I9yfNbIIZK7L9KAJFc6iZjYUjkGOAEWAtcL6ZjdTY9yzC5I9z585d+OCDD8Z3IXXo7+9j+/YNNbdPm7aQvr6Jo6FgHkj+5mJUqPT41q9f2Nb1pY2PQHalm9ujm68ta2qNQBJb10PSDVRfufCCFo+zH/BdYIntNK5/CngM2ANYAZwHXFhtfzNbEdahr68vtTurXYd4msnYmp20WM1M8NBDG5gxo/axs3T4+3wTx0mHxBSImZ1Ya5ukrZL2M7NHQwVRNUxB0t7AT4FPm9ntkWM/Gn4ckfRt4JMxih4LeY++6HTS4vAwdRVI1tfnVMeVpxMnWdlE1gBLws9LgGvGV5C0B3A18B0zu2rctv3CdxH4T+5NVNo2yHv0RSs+jGr28tNO+15ur89t/uXEf9/0yUqBLAdOknQ/wQz35QCS+iRdGtY5AzgO+FCVcN0rJN0D3APsC/xjuuI3Ju8O8U4nLeb9+hzHSZ5MnOhZkfaStnl2iN966+y6Jrbdd5/Nscc+NqE86qjM8/VVcMeq43RO6k50J9+rk7Xro9k102x+r6+CKw7HSY58dBOd1Mm7j8ZxnPzjCqSkdLMPI8kUK45TjbLec+4DKTFF8GG0SrekjnCKQxnuOfeBOBMogg+jVbp9AR8nf5T5niu2WnSccTQKT7766g/kbs0Ip9h0+zo+9fARiNMSWa3Z3iyNUsj09MR/zjyECudBhrJS5nV8XIEUlCwe5Fmv2d4MjcKTh2pvcmIk7x2NOMl72qIk6a5fsiRUHuQDA8vYvn0Do6NDbN++gYGBZWzc+N7EIj+KkMK9Xnjyc8/B6nAFmSIuj1sUsro/s6LMIfGuQApIVg/yIth6a4UnP/cc9PfDunXxnCcPq/zlQYZqFKGjESfdHBLfCFcgBSSrB3kRbL3jF/CZPHlvJk3ak2nT9ubkk4/gbW8DyZMrJkkROhpx0u2LRtXDfSAFJKsHeVFsvdIkenoWMTT0Q5599v8xNvYsAM8882vOPReOOy4ws3Tyx941pUs2Duw8yFCNInQ04qYbQ+KboXtVYxczZUpvg+3JPMiLZOutZUZ52cugr4+uM6PkiazuTyd9XIEUkKwe5EWy9dYzo7zsZXSdGSVPFKmj4XSGK5ACktWDvEi23jTNKHnwpeRBhgpF6mg4neE+kAJSeZBnkceqKLbeovhrupEs708nXTJJpihpBvADYB7we+AMM3uySr0dBKsOAjxkZqeE5QcAq4AZwK+B/2VmLzQ6rydTLA9bt17BwMCyqmasSTybqkYAAA6bSURBVJNezvz5K3KvBB0nL9RKpphVV+B8YK2ZHQysDb9X4zkzWxC+TomUfxG4ONz/SWBpsuI6RaOIZpSs529kSRGvvawp3KNkNQIZAN5qZo9K2g+4yczmV6m33cymjSsTMAy80sxelHQM8Dkze0ej8/oIpFwULV19nkJx06Zo116GFO5R8pbOfbaZPQoQKpFaKe6mSuoHXgSWm9l/ADOBP5jZi2GdQWD/WieSdBZwFsDcuXPjkt8pAEXx13QzWSuGpM5f5hTuURJTIJJuAF5ZZdMFLRxmrpk9IulAYJ2ke4D/qVKv5t1hZiuAFRCMQFo4t+MkTjWzTbSsKD3ydijytTcz294VSAeY2Ym1tknaKmm/iAmrariMmT0Svm+WdBNwOPDvwD6SdgtHIXOAR2K/AMdxHKpnFn7uufvr7tONs+2rkZWRbg2wJPy8BLhmfAVJ0yVNCT/vCxwL3GdBt+RG4PR6+ztOEaiWkyuvebqadXQ3m+QxqWuPM8lkrczCO3Zsr7tfWcLEs1Igy4GTJN0PnBR+R1KfpEvDOq8F+iXdRaAwlpvZfeG284BzJW0i8Il8K1Xpna4my+gaiczO7VFFE6nl64DabVKm2faZRGFlhUdhOY3IMrpm0iRx4YVw3HEvT/3czVz3pEmTw7rNPzOadWIn5ezu9Lj9/X1s376hTo1JRJVJ2aKwuucKHScGslzL4tFHvzdBeaR17nrXvWXLf3DSSZNfKotjzZHxo5316xfy2GPfy91op1FKnMmTp+U+rU+SeCoTx4mQZXRNK+eOu8feKPnk6afD2rWxnKoQSyNXaJQS52UvO5i+vvJaNfLxKzlOTshyLYs8n/t1r5v90udWHN3V6qU5yuvUIe+ZhevjCsRxImS5lkVZzl2kFQuLmBInTVyBOLkli6igLHucjc59/vkbElsDPc3rLtKKhUVawiALyn31Tm6pFX8/MLCMjRvfm5gSybLH2ejc69YlduqmrjuuuSlFW7GwkhKnr6+fY499jL6+fmbPfn/plQe4AnFySlbRUFn2OBude2wsuUmHaV63+xW6B58H4uSSRvH306YtLHX0S9ZJCjuhbJlsu4G8ZeN1nLoUyU7utIavWNg9uAJxcokvSVufIo48oniq/e7AVb2TS9xO7jj5xxWIk0s8/t5x8o+bsJxc4nZyx8k/rkCc3OJ2csfJN96NcxzHcdrCRyCO4+SaakvK9vaeQ0/PYjdlZowrEMdJAX8ItkeRUr+XkUxaXtIMSddLuj98n16lzvGS7oy8npd0WrjtckkPRLYtSP8qHKc5ssrr1Q1kucCX05isVPf5wFozOxhYG37fBTO70cwWmNkC4ATgWeDnkSp/W9luZnemIrXjtEHWD8Eir3VepNTvZSQrBXIqsDL8vBI4rUH904FrzezZRKVynATI8iFY9NGPp7TJN1kpkNlm9ihA+N7ToP4i4MpxZV+QdLekiyVNqbWjpLMk9UvqHx4e7kxqx2mDLB+CWY9+OqVoqd/LRmIKRNINku6t8jq1xePsB7wOuC5S/CngNcCRwAzgvFr7m9kKM+szs75Zs2a1cSWO0xlZPgSLbgLylDb5JjEFYmYnmtlhVV7XAFtDxVBRELWz5sEZwNVmNho59qMWMAJ8GzgqqetwnE7J8iFYdBOQp7TJN1mZsNYAS8LPS4Br6tRdzDjzVUT5iMB/cm8CMjpOLGT5ECy6CciXlM03mSwoJWkm8ENgLvAQ8Gdm9oSkPuBsMzszrDcPuBXotYi3T9I6YBYg4M5wn+2NzusLSjlZEcwDST+v19atVzAwsKyqGWvSpJczf/4KTxXjNKTWglK+IqHjdDG++p8TB74ioeOUEM9q7CSJKxDH6XI8q7GTFN79cBzHcdrCFYjjOI7TFq5AHMdxnLZwBeI4juO0hSsQx3Ecpy1cgTiO4zht4QrEcRzHaYtSzUSXNAw8mMGp9wUez+C8zZJn+Vy29smzfC5be2Ql26vNbEI681IpkKyQ1F8tDUBeyLN8Llv75Fk+l6098iabm7Acx3GctnAF4jiO47SFK5B0WJG1AA3Is3wuW/vkWT6XrT1yJZv7QBzHcZy28BGI4ziO0xauQBzHcZy2cAUSE5JmSLpe0v3h+/QqdY6XdGfk9byk08Jtl0t6ILJtQdryhfV2RGRYEyk/QNIvw/1/IGmPNGWTtEDSbZI2Srpb0vsi22JvO0knSxqQtEnS+VW2TwnbYVPYLvMi2z4Vlg9IekensrQh27mS7gvbaa2kV0e2Vf19U5TtQ5KGIzKcGdm2JLwH7pe0JG7ZmpTv4ohsv5X0h8i2pNvuMklDku6tsV2SvhLKfrekIyLbEm+7qpiZv2J4AV8Czg8/nw98sUH9GcATwJ7h98uB07OWD9heo/yHwKLw8zeAv0xTNuCPgYPDz68CHgX2SaLtgMnA74ADgT2Au4BDxtX5CPCN8PMi4Afh50PC+lOAA8LjTE5ZtuMj99VfVmSr9/umKNuHgH+tsu8MYHP4Pj38PD1t+cbV/xhwWRptFx7/OOAI4N4a298FXAsIeAPwy7TartbLRyDxcSqwMvy8EjitQf3TgWvN7NlEpdpJq/K9hCQBJwCr29k/DtnM7Ldmdn/4+RFgCJgwMzYmjgI2mdlmM3sBWBXKWEvm1cDbwnY6FVhlZiNm9gCwKTxearKZ2Y2R++p2YE6M5+9Itjq8A7jezJ4wsyeB64GTM5ZvMXBlzDLUxMxuIehU1uJU4DsWcDuwj6T9SKftquIKJD5mm9mjAOF7T4P6i5h4c34hHJpeLGlKRvJNldQv6faKeQ2YCfzBzF4Mvw8C+2cgGwCSjiLoQf4uUhxn2+0PbIl8r3a9L9UJ2+UpgnZqZt+kZYuylKDXWqHa75u2bO8Nf6vVknpb3DcN+QjNfgcA6yLFSbZdM9SSP422q4qvid4Ckm4AXlll0wUtHmc/4HXAdZHiTwGPETwYVwDnARdmIN9cM3tE0oHAOkn3AP9TpV5L8d8xt913gSVmNhYWd9x2409TpWz89daq08y+ndD08SV9EOgD3hIpnvD7mtnvqu2fkGw/Bq40sxFJZxOM4k5oct805KuwCFhtZjsiZUm2XTNkdc/VxBVIC5jZibW2SdoqaT8zezR8yA3VOdQZwNVmNho59qPhxxFJ3wY+mYV8oXkIM9ss6SbgcODfCYbLu4W97TnAI2nLJmlv4KfAp8MhfOXYHbfdOAaB3sj3atdbqTMoaTfgFQTmh2b2TVo2JJ1IoJzfYmYjlfIav29cD8GGspnZtsjXfwO+GNn3reP2vSkmuZqWL8Ii4KPRgoTbrhlqyZ9G21XFTVjxsQaoRD8sAa6pU3eCbTV8cFb8DacBVSMxkpRP0vSK+UfSvsCxwH0WeOpuJPDb1Nw/Ydn2AK4msAFfNW5b3G23HjhYQeTZHgQPk/FRN1GZTwfWhe20BlikIErrAOBg4FcdytOSbJIOB74JnGJmQ5Hyqr9vyrLtF/l6CvCb8PN1wNtDGacDb2fXEXoq8oUyzidwRt8WKUu67ZphDfDnYTTWG4Cnws5TGm1XnTQ89WV4Edi/1wL3h+8zwvI+4NJIvXnAw8CkcfuvA+4hePh9D5iWtnzAG0MZ7grfl0b2P5DgQbgJuAqYkrJsHwRGgTsjrwVJtR1BxMtvCXqYF4RlFxI8lAGmhu2wKWyXAyP7XhDuNwC8M4F7rZFsNwBbI+20ptHvm6Js/wRsDGW4EXhNZN8Ph+25CfiLuGVrRr7w++eA5eP2S6PtriSILhwlGFUsBc4Gzg63C/hqKPs9QF+abVft5alMHMdxnLZwE5bjOI7TFq5AHMdxnLZwBeI4juO0hSsQx3Ecpy1cgTiO4zht4QrEKQWSTNJ3I993U5AV9ifh91NUJTtrjOf/nKSqExwl/XcLx7k6zAa7SdJT2pkd9o0tynNCOJeg2rZDFWQ+HpH0160c1ykXPhPdKQvPAIdJepmZPQecRDAfBwAzW0OVSWXVCCcsynamUukIM2v64W9m7w5leCvwSTP70zZPewLwOEGyxfE8TpCJ9vQq2xznJXwE4pSJa4E/CT/vkg1AwToV/xp+nh329O8KX2+UNE/SbyR9Dfg10CtpsaR7JN0r6YuRY50s6dfhvmsj5z9E0k2SNkv6eKT+9vD9rZJuCc99n6RvSGr6PyrpSEk3S9og6VpJs8Pyc8Lj3SXpe5L+CDgT+Ntqoxcz22pm/cCLVU7jOC/hIxCnTKwCPhOarV4PXAa8uUq9rwA3m9m7JU0GphGktphPMMv3I5JeRZDHaSHwJPBzBRlabyXI8XScmT0gaUbkuK8hWKtjL2BA0tctkg8t5CiCNUUeBP4TeA870+jXJEyzcQnBjOrHJX0A+DxwFvB3wKvN7AVJ+5jZHyRdCjxuZv/S6NiOUwtXIE5pMLO7FawcuBj4WZ2qJwB/Hu6zA3gqzDH0oO1M4ngkcJOZDQNIuoJgQaAdwC0WrAWCmUXXd/ipBYkNRyQNAbMJUlZE+ZWZbQ6PeSXwJppQIMBrgUOBGwILG5Mjx94IfE/SNcB/NHEsx2kKVyBO2VgDfJkge+nMFvd9JvK5WgrtSnmt/EAjkc87qP7/G79vs7mGBNxtZtVGVO8gSOl+KvBpSYc1eUzHqYv7QJyycRlwoZndU6fOWoKlYJE0WUEa+fH8EniLpH1DM9di4GaCDK5vCTPxMs6E1QxHhdliJwHvA37R5H73AfsrWGwLSXuE0VSTgTlmtg74W4JVHPcEniYwpTlO27gCcUqFmQ2a2SUNqn0COF7BYlobCExD44/zKMFCVjcSZGj9tZldE5q0zgJ+JOku4ActingbsJwgs/ADBCnsGxKaxk4HLgrPewdwNMEo5/uS7iZw/n/RzJ4mSJl/hqQ7xjvRJc2RNAh8HPicpEFJe7Z4HU4J8Gy8jpMTYgjNdZxU8RGI4ziO0xY+AnEcx3HawkcgjuM4Tlu4AnEcx3HawhWI4ziO0xauQBzHcZy2cAXiOI7jtMX/Bz2qxQtKUboiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData(ex2data2, 'Microchip Test 1', 'Microchip Test 2', 'y = 1', 'y = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(6)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAMBDA 1\n",
    "# COST: 0.6123004121966032\n",
    "# [ 5.41873718e-01  8.15689394e-02  4.44733168e-01 -8.58393639e-01\n",
    "#  -2.58049951e-01 -4.78806310e-01 -8.96596604e-02 -1.19484116e-01\n",
    "#  -1.27027966e-01 -1.66617683e-01 -6.73534367e-01 -2.86055214e-02\n",
    "#  -2.34906880e-01 -6.60561186e-02 -5.50170050e-01 -2.06797391e-01\n",
    "#  -7.87061617e-02 -3.99384067e-02 -1.01469022e-01 -8.78571394e-02\n",
    "#  -3.52644832e-01 -5.10746788e-01 -5.00221792e-03 -1.18833681e-01\n",
    "#  -6.85807850e-04 -1.30317401e-01 -2.90675602e-02 -5.35642401e-01]\n",
    "\n",
    "# LAMBDA 0.5\n",
    "# COST: 0.5744751405183768\n",
    "# [ 8.81537304e-01  3.35671221e-01  8.32893203e-01 -1.42281415e+00\n",
    "#  -4.98526952e-01 -8.14863753e-01 -2.07809043e-02 -2.20282027e-01\n",
    "#  -2.19482740e-01 -1.99188142e-01 -1.09391078e+00 -5.01465688e-02\n",
    "#  -4.05943583e-01 -1.35126282e-01 -8.78106800e-01 -2.57371276e-01\n",
    "#  -1.40830995e-01 -5.63667877e-02 -1.77559419e-01 -1.64491029e-01\n",
    "#  -4.94644589e-01 -8.12694924e-01 -3.32089336e-03 -2.02963435e-01\n",
    "#  -3.83179928e-04 -2.22178257e-01 -6.33609091e-02 -8.16097720e-01]\n",
    "\n",
    "# LAMBDA 0.1\n",
    "# COST: 0.4699577214240188\n",
    "# [ 1.86395856  1.16508302  1.98304149 -3.06606528 -1.68430674 -2.15390219\n",
    "#   0.3262334  -0.67036688 -0.62886034 -0.22663156 -2.32857998 -0.12929081\n",
    "#  -1.01492937 -0.53779789 -1.90802507 -0.34306065 -0.38036578 -0.06835069\n",
    "#  -0.48408633 -0.54731775 -0.71255162 -1.70764088  0.02274304 -0.48648496\n",
    "#   0.00992452 -0.55205037 -0.30091823 -1.50750995]\n",
    "\n",
    "# LAMBDA 0\n",
    "# COST: 0.334673945570482\n",
    "# [ 3.5080398   2.46926824  3.86962766 -5.23868756 -4.66377316 -5.71771698\n",
    "#   1.17925608 -1.60257917 -0.72796692 -0.5006645  -4.42408228  0.64707117\n",
    "#  -2.47593563 -1.8255301  -3.63869771 -0.75298571 -0.70275886  0.7903935\n",
    "#  -1.5877627  -1.76426312  0.08455283 -3.66454125  0.57610037 -1.06033281\n",
    "#   0.49043072 -1.56780282 -1.4681976  -1.39528306]\n",
    "\n",
    "self = RLogisticRegression(X_poly,\n",
    "                           y,\n",
    "                           alfa=0.0003,\n",
    "                           num_iter=10**7,\n",
    "                           fit_intercept=False,\n",
    "                           weights_to_initialise=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAMBDA 1\n",
    "# self.thetas = [ 5.41873718e-01, 8.15689394e-02,  4.44733168e-01, -8.58393639e-01,\n",
    "#   -2.58049951e-01, -4.78806310e-01, -8.96596604e-02, -1.19484116e-01,\n",
    "#   -1.27027966e-01, -1.66617683e-01, -6.73534367e-01, -2.86055214e-02,\n",
    "#   -2.34906880e-01, -6.60561186e-02, -5.50170050e-01, -2.06797391e-01,\n",
    "#   -7.87061617e-02, -3.99384067e-02, -1.01469022e-01, -8.78571394e-02,\n",
    "#   -3.52644832e-01, -5.10746788e-01, -5.00221792e-03, -1.18833681e-01,\n",
    "#   -6.85807850e-04, -1.30317401e-01, -2.90675602e-02, -5.35642401e-01,]\n",
    "\n",
    "# LAMBDA 0.5\n",
    "# self.thetas = [8.81537304e-01,  3.35671221e-01,  8.32893203e-01, -1.42281415e+00,\n",
    "#   -4.98526952e-01, -8.14863753e-01, -2.07809043e-02, -2.20282027e-01,\n",
    "#   -2.19482740e-01, -1.99188142e-01, -1.09391078e+00, -5.01465688e-02,\n",
    "#   -4.05943583e-01, -1.35126282e-01, -8.78106800e-01, -2.57371276e-01,\n",
    "#   -1.40830995e-01, -5.63667877e-02, -1.77559419e-01, -1.64491029e-01,\n",
    "#   -4.94644589e-01, -8.12694924e-01, -3.32089336e-03, -2.02963435e-01,\n",
    "#   -3.83179928e-04, -2.22178257e-01, -6.33609091e-02, -8.16097720e-01,]\n",
    "\n",
    "# LAMBDA 0.1\n",
    "# self.thetas = [\n",
    "# 1.86395856,  1.16508302,  1.98304149, -3.06606528, -1.68430674, -2.15390219,\n",
    "# 0.3262334,  -0.67036688, -0.62886034, -0.22663156, -2.32857998, -0.12929081,\n",
    "# -1.01492937, -0.53779789, -1.90802507, -0.34306065, -0.38036578, -0.06835069,\n",
    "# -0.48408633, -0.54731775, -0.71255162, -1.70764088,  0.02274304, -0.48648496,\n",
    "# 0.00992452, -0.55205037, -0.30091823, -1.50750995\n",
    "# ]\n",
    "\n",
    "# LAMBDA 0\n",
    "# self.thetas = [\n",
    "# 3.5080398,   2.46926824,  3.86962766, -5.23868756, -4.66377316, -5.71771698,\n",
    "# 1.17925608, -1.60257917, -0.72796692, -0.5006645,  -4.42408228,  0.64707117,\n",
    "# -2.47593563, -1.8255301,  -3.63869771, -0.75298571, -0.70275886,  0.7903935,\n",
    "# -1.5877627,  -1.76426312,  0.08455283, -3.66454125,  0.57610037, -1.06033281,\n",
    "# 0.49043072, -1.56780282, -1.4681976,  -1.39528306\n",
    "# ]\n",
    "\n",
    "#0.6931271807599428\n",
    "#0.6931233407211389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COST: 0.6931271807599428\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "COST: 0.6931233407211389\n",
      "COST: 0.6020610898068063\n",
      "COST: 0.5542160996175354\n",
      "COST: 0.5206543006770912\n",
      "COST: 0.49547135711164064\n",
      "COST: 0.47583154808284805\n",
      "COST: 0.4600718386211779\n",
      "COST: 0.44714001395951875\n",
      "COST: 0.43633666145906463\n",
      "COST: 0.42717811796947447\n",
      "COST: 0.4193186361556912\n",
      "COST: 0.4125040133482776\n",
      "COST: 0.406542825437855\n",
      "COST: 0.40128793846353034\n",
      "COST: 0.39662424763703813\n",
      "COST: 0.3924603170591417\n",
      "COST: 0.38872253663159473\n",
      "COST: 0.3853509475284213\n",
      "COST: 0.3822962007661373\n",
      "COST: 0.3795173022225811\n",
      "COST: 0.3769799143692088\n",
      "COST: 0.3746550591759143\n",
      "COST: 0.3725181148050601\n",
      "COST: 0.37054803062514174\n",
      "COST: 0.36872670663195184\n",
      "COST: 0.3670384981859971\n",
      "COST: 0.3654698173313562\n",
      "COST: 0.36400880930726304\n",
      "COST: 0.3626450881472158\n",
      "COST: 0.3613695191092569\n",
      "COST: 0.36017403851830493\n",
      "COST: 0.35905150371589156\n",
      "COST: 0.3579955674046289\n",
      "COST: 0.357000571884704\n",
      "COST: 0.3560614596074233\n",
      "COST: 0.35517369718803243\n",
      "COST: 0.35433321057876993\n",
      "COST: 0.3535363295414718\n",
      "COST: 0.35277973990537465\n",
      "COST: 0.3520604423710347\n",
      "COST: 0.35137571684145424\n",
      "COST: 0.350723091438553\n",
      "COST: 0.3501003155062972\n",
      "COST: 0.34950533601811107\n",
      "COST: 0.3489362769012091\n",
      "COST: 0.348391420868383\n",
      "COST: 0.34786919341198025\n",
      "COST: 0.3473681486678919\n",
      "COST: 0.3468869569014862\n",
      "COST: 0.346424393404162\n",
      "COST: 0.3459793286199679\n",
      "COST: 0.34555071934754544\n",
      "COST: 0.3451376008844034\n",
      "COST: 0.3447390799989135\n",
      "COST: 0.3443543286309867\n",
      "COST: 0.3439825782356408\n",
      "COST: 0.34362311469494927\n",
      "COST: 0.3432752737335213\n",
      "COST: 0.34293843678092956\n",
      "COST: 0.34261202723160317\n",
      "COST: 0.34229550705884254\n",
      "COST: 0.3419883737448802\n",
      "COST: 0.3416901574935013\n",
      "COST: 0.3414004186956928\n",
      "COST: 0.34111874562225436\n",
      "COST: 0.3408447523202928\n",
      "COST: 0.3405780766931558\n",
      "COST: 0.340318378745647\n",
      "COST: 0.34006533897837854\n",
      "COST: 0.3398186569168729\n",
      "COST: 0.3395780497625934\n",
      "COST: 0.3393432511544222\n",
      "COST: 0.3391140100303408\n",
      "COST: 0.33889008958011163\n",
      "COST: 0.33867126628070715\n",
      "COST: 0.33845732900708075\n",
      "COST: 0.3382480782115982\n",
      "COST: 0.3380433251661261\n",
      "COST: 0.3378428912613495\n",
      "COST: 0.33764660735842517\n",
      "COST: 0.3374543131885351\n",
      "COST: 0.3372658567963364\n",
      "COST: 0.33708109402366865\n",
      "COST: 0.33689988803022014\n",
      "COST: 0.33672210884816145\n",
      "COST: 0.33654763296801177\n",
      "COST: 0.336376342953267\n",
      "COST: 0.33620812708152575\n",
      "COST: 0.3360428790100479\n",
      "COST: 0.33588049746386933\n",
      "COST: 0.3357208859447453\n",
      "COST: 0.3355639524593559\n",
      "COST: 0.3354096092653259\n",
      "COST: 0.33525777263374273\n",
      "COST: 0.33510836262695753\n",
      "COST: 0.3349613028905621\n",
      "COST: 0.33481652045851557\n",
      "COST: 0.334673945570482\n",
      "COST: 0.33453351150051863\n",
      "COST: 0.33439515439631157\n",
      "COST: 0.33425881312823125\n",
      "COST: 0.33412442914752805\n",
      "COST: 0.33399194635304186\n",
      "COST: 0.33386131096585114\n",
      "COST: 0.3337324714113278\n",
      "COST: 0.3336053782081005\n",
      "COST: 0.3334799838634743\n",
      "COST: 0.33335624277488185\n",
      "COST: 0.33323411113697143\n",
      "COST: 0.33311354685397104\n",
      "COST: 0.33299450945699144\n",
      "COST: 0.3328769600259496\n",
      "COST: 0.332760861115827\n",
      "COST: 0.3326461766869889\n",
      "COST: 0.33253287203931226\n",
      "COST: 0.33242091374988897\n",
      "COST: 0.33231026961408483\n",
      "COST: 0.332200908589751\n",
      "COST: 0.33209280074439806\n",
      "COST: 0.33198591720515513\n",
      "COST: 0.3318802301113493\n",
      "COST: 0.33177571256955\n",
      "COST: 0.33167233861093465\n",
      "COST: 0.33157008315084\n",
      "COST: 0.3314689219503742\n",
      "COST: 0.33136883157996927\n",
      "COST: 0.33126978938476626\n",
      "COST: 0.33117177345172677\n",
      "COST: 0.3310747625783752\n",
      "COST: 0.3309787362430802\n",
      "COST: 0.3308836745767907\n",
      "COST: 0.33078955833614543\n",
      "COST: 0.330696368877881\n",
      "COST: 0.33060408813446823\n",
      "COST: 0.3305126985909093\n",
      "COST: 0.3304221832626356\n",
      "COST: 0.3303325256744451\n",
      "COST: 0.33024370984042434\n",
      "COST: 0.3301557202448058\n",
      "COST: 0.3300685418237069\n",
      "COST: 0.3299821599477106\n",
      "COST: 0.32989656040523746\n",
      "COST: 0.3298117293866744\n",
      "COST: 0.32972765346921734\n",
      "COST: 0.32964431960239376\n",
      "COST: 0.329561715094229\n",
      "COST: 0.32947982759802524\n",
      "COST: 0.32939864509972183\n",
      "COST: 0.3293181559058092\n",
      "COST: 0.3292383486317663\n",
      "COST: 0.32915921219099936\n",
      "COST: 0.32908073578425473\n",
      "COST: 0.3290029088894838\n",
      "COST: 0.3289257212521384\n",
      "COST: 0.3288491628758749\n",
      "COST: 0.3287732240136492\n",
      "COST: 0.32869789515918196\n"
     ]
    }
   ],
   "source": [
    "self.fit(LAMBDA=0, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance measurement metrics\n",
    "\n",
    "[The link can be found here - type .pdf](http://www.academicos.ccadet.unam.mx/jorge.marquez/cursos/Instrumentacion/FalsePositive_TrueNegative_etc.pdf)\n",
    "\n",
    "[Another link for the confusion matrix - type .pdf](https://www.lexjansen.com/nesug/nesug10/hl/hl07.pdf)\n",
    "\n",
    "[Metrics explained - Towards Data Science(TDS) Article](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)\n",
    "\n",
    "[Metrics explained for non-technical - TDS Article](https://towardsdatascience.com/data-science-performance-metrics-for-everyone-4d68f4859eef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_model_performance(self.y, self.predict(threshold=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(RLogReg_instance=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1, sharey = True, figsize=(10,8))\n",
    "plotData(ex2data2, 'Microchip Test 1', 'Microchip Test 2', 'y = 1', 'y = 0')\n",
    "\n",
    "x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n",
    "x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "h = self._sigmoid(poly.fit_transform(np.c_[xx1.ravel(), xx2.ravel()]).dot(self.thetas))\n",
    "h = h.reshape(xx1.shape)\n",
    "axes.contour(xx1, xx2, h, [0.5], linewidths=2, colors='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
