{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utility_functions import (calculate_model_performance,\n",
    "                               plot_ROC,\n",
    "                               one_hot_encode,\n",
    "                               split_data_as,\n",
    "                               grid_search)\n",
    "\n",
    "\n",
    "def get_shapes(any_):\n",
    "    for array in any_:\n",
    "        try:\n",
    "            print(array.shape)\n",
    "        except:\n",
    "            print(\"NONE\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# ============= ACTIVATION FUNCTIONS ===============#\n",
    "\n",
    "def sigmoid(Z, prime=False):\n",
    "    # np.\n",
    "    if prime:\n",
    "        return sigmoid(Z) * (1 - sigmoid(Z))\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "def linear(Z, prime=False):\n",
    "    if prime:\n",
    "        return np.ones_like(Z)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def relu(Z, alpha=0.01, prime=False):\n",
    "    if prime:\n",
    "        Z_relu = np.ones_like(Z, dtype=np.float64)\n",
    "        Z_relu[Z < 0] = alpha\n",
    "        return Z_relu\n",
    "    return np.where(Z < 0, alpha * Z, Z)\n",
    "\n",
    "\n",
    "def tanh(Z, prime=False):\n",
    "    # np.tanh() could be used directly to speed this up\n",
    "    if prime:\n",
    "        return 1 - np.power(tanh(Z), 2)\n",
    "    return (2 / (1 + np.exp(-2 * Z))) - 1\n",
    "\n",
    "\n",
    "def elu(Z, prime=False):\n",
    "    # https://mlfromscratch.com/activation-functions-explained/#/\n",
    "    alpha = 0.2\n",
    "    if prime:\n",
    "        return np.where(Z < 0, alpha * (np.exp(Z)), 1)\n",
    "    return np.where(Z < 0, alpha * (np.exp(Z) - 1), Z)\n",
    "\n",
    "\n",
    "def softmax(Z, prime=False):\n",
    "    # https://deepnotes.io/softmax-crossentropy\n",
    "    # max(Z) term is added to stabilise the function.\n",
    "    exps = np.exp(Z - np.max(Z))\n",
    "    return exps / np.sum(exps, axis=0)\n",
    "\n",
    "\n",
    "# ============== LOSS FUNCTIONS ===============#\n",
    "\n",
    "# https://deepnotes.io/softmax-crossentropy\n",
    "EPSILON = 1e-8\n",
    "\n",
    "\n",
    "def calculate_error(Y, Y_hat):\n",
    "    # Y and Y_hat should be in the form of (no_of_classes, no_of_training_examples)\n",
    "    m = Y.shape[1]\n",
    "    return -np.sum(Y * np.log(Y_hat + EPSILON)) / m\n",
    "\n",
    "\n",
    "# References\n",
    "# https://mc.ai/multilayered-neural-network-from-scratch-using-python/\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "# https://www.coursera.org/learn/machine-learning/home/week/5\n",
    "# https://www.coursera.org/specializations/deep-learning\n",
    "# https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py\n",
    "# https://github.com/JWarmenhoven/Coursera-Machine-Learning\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_layer: tuple,\n",
    "            hidden_layer: list,  # list of tuples\n",
    "            output_layer: int,\n",
    "            batch_size=16,\n",
    "            alpha=1,\n",
    "            epoch=500,\n",
    "            random_state=42,\n",
    "            verbose=True,\n",
    "            metrics=\"accuracy\"\n",
    "    ):\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.mini_batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.epoch = epoch\n",
    "        self.seed = random_state\n",
    "        self.verbose = verbose\n",
    "        self.metrics = metrics\n",
    "\n",
    "        self.layers = len(self.weight_set_dimensions) + 1\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        parameters = (\n",
    "            \"Input layer: {0}\\n\"\n",
    "            \"Hidden layer: {1}\\n\"\n",
    "            \"Output layer: {2}\\n\"\n",
    "            \"Batch size: {3}\\n\"\n",
    "            \"Learning rate: {4}\\n\"\n",
    "            \"Epoch: {5}\\n\"\n",
    "            \"Seed: {6}\\n\"\n",
    "            \"Verbose: {7}\\n\"\n",
    "            \"Metric: {8}\"\n",
    "        ).format(\n",
    "            self.input_layer,\n",
    "            self.hidden_layer,\n",
    "            self.output_layer,\n",
    "            self.mini_batch_size,\n",
    "            self.alpha,\n",
    "            self.epoch,\n",
    "            self.seed,\n",
    "            self.verbose,\n",
    "            self.metrics\n",
    "        )\n",
    "        return parameters\n",
    "\n",
    "    def get_A(self, X):\n",
    "        A, _ = self.forwardpass(X)\n",
    "        return A\n",
    "\n",
    "    def get_Z(self, X):\n",
    "        _, Z = self.forwardpass(X)\n",
    "        return Z\n",
    "\n",
    "    def display_information(self, X, Y, epoch_no):\n",
    "        model_performance_metrics = calculate_model_performance(\n",
    "            np.argmax(Y, axis=0),\n",
    "            self.predict(X)\n",
    "        )\n",
    "        print(\"%s: %.10f - epoch %s    iteration %s - loss %.20f\" % (\n",
    "            self.metrics,\n",
    "            model_performance_metrics[self.metrics],\n",
    "            epoch_no,\n",
    "            self.no_of_iterations,\n",
    "            calculate_error(Y,\n",
    "                            self.get_A(X)[-1])\n",
    "        )\n",
    "              )\n",
    "\n",
    "    def get_dimensions_and_activations(self):\n",
    "        self.dimensions = []\n",
    "        self.activation_functions = []\n",
    "\n",
    "        self.dimensions.append(self.input_layer[0])\n",
    "        self.activation_functions.append(self.input_layer[1])\n",
    "\n",
    "        for dim, act_func in self.hidden_layer:\n",
    "            self.dimensions.append(dim)\n",
    "            self.activation_functions.append(act_func)\n",
    "\n",
    "        self.dimensions.append(self.output_layer)\n",
    "\n",
    "    @property\n",
    "    def weight_set_dimensions(self):\n",
    "        self.get_dimensions_and_activations()\n",
    "        a, b = itertools.tee(self.dimensions[::-1])\n",
    "        next(b, None)\n",
    "        weight_set_dimensions = list(zip(a, b))[::-1]\n",
    "        return weight_set_dimensions\n",
    "\n",
    "    def initialise_weights(self, layer=None):\n",
    "        self.W = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.B = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.W[0] = None\n",
    "        self.B[0] = None\n",
    "        for layer, (y, x) in zip(range(1, self.layers), self.weight_set_dimensions):\n",
    "            np.random.seed(self.seed)\n",
    "            self.W[layer] = np.random.rand(y, x) / np.sqrt(self.dimensions[layer - 1])\n",
    "            self.B[layer] = np.random.rand(y, 1)\n",
    "\n",
    "    def forwardpass(self, X):\n",
    "        Z = np.empty_like(range(self.layers), dtype=object)\n",
    "        A = np.empty_like(range(self.layers), dtype=object)\n",
    "        A[0] = X\n",
    "        Z[0] = None\n",
    "        for layer in range(1, self.layers):\n",
    "            # activation_function starts from 0 whereas layer starts from 1\n",
    "            active_function = self.activation_functions[layer - 1]\n",
    "            arg_to_pass_to_eval = \"(Z[layer])\"\n",
    "\n",
    "            Z[layer] = self.W[layer] @ A[layer - 1] + self.B[layer]\n",
    "            A[layer] = eval(active_function + arg_to_pass_to_eval)\n",
    "        return A, Z\n",
    "\n",
    "    def backpropagation(self, Y, A, Z):\n",
    "        self.delta = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.delta[0] = None\n",
    "\n",
    "        self.gradient_W = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.gradient_B = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.gradient_W[0] = None\n",
    "        self.gradient_B[0] = None\n",
    "\n",
    "        self.delta[-1] = A[-1] - Y\n",
    "\n",
    "        # We substract 1 here as delta_final is calculated seperately above\n",
    "        for layer in reversed(range(1, self.layers - 1)):\n",
    "            # 1 is substracted from layer as activation_functions start indexing from 0\n",
    "            active_function = self.activation_functions[layer - 1]\n",
    "            arg_to_pass_to_eval = \"(Z[layer], prime=True)\"\n",
    "\n",
    "            self.delta[layer] = (\n",
    "                    self.W[layer + 1].T @ self.delta[layer + 1] *\n",
    "                    eval(active_function + arg_to_pass_to_eval)\n",
    "            )\n",
    "\n",
    "            # calculate the gradient\n",
    "\n",
    "        for layer in range(1, self.layers):\n",
    "            self.gradient_W[layer] = (self.delta[layer] @ A[layer - 1].T) / self.m\n",
    "            self.gradient_B[layer] = np.sum(self.delta[layer], axis=1, keepdims=True) / self.m\n",
    "\n",
    "        # update the weights\n",
    "        for layer in range(1, self.layers):\n",
    "            self.W[layer] -= self.alpha * self.gradient_W[layer]\n",
    "            self.B[layer] -= self.alpha * self.gradient_B[layer]\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.m = X.shape[1] # where (no_of_features, no_of_training_examples)\n",
    "        self.initialise_weights()\n",
    "\n",
    "        # By default the method is SGD(Stochastic Gradient Descent) if one wishes to use\n",
    "        # the whole batch, simply pass the number of traning examples available as the\n",
    "        # batch size when instantiating the class\n",
    "        self.no_of_iterations = 0\n",
    "        shuffled = np.arange(self.m)\n",
    "        if self.verbose:\n",
    "            print(\"Initialising weights...\")\n",
    "            print(\"Starting the training...\")\n",
    "            print(\"Initial cost: %.10f\\n\" % calculate_error(Y, self.get_A(X)[-1]))\n",
    "        for epoch_no in range(1, self.epoch + 1):\n",
    "            np.random.shuffle(shuffled)\n",
    "            X_shuffled = X[:, shuffled]\n",
    "            Y_shuffled = Y[:, shuffled]\n",
    "            for i in range(0, self.m, self.mini_batch_size):\n",
    "                self.no_of_iterations += 1\n",
    "                X_mini_batch = X_shuffled[:, i: i + self.mini_batch_size]\n",
    "                Y_mini_batch = Y_shuffled[:, i: i + self.mini_batch_size]\n",
    "\n",
    "                A, Z = self.forwardpass(X_mini_batch)\n",
    "                self.backpropagation(Y_mini_batch, A, Z)\n",
    "                if self.no_of_iterations % 5000 == 0 and self.verbose:\n",
    "                    self.display_information(X, Y, epoch_no)\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            X: np.ndarray,\n",
    "            return_prob_matrix=False\n",
    "    ):\n",
    "        \"\"\"Predict the output given the training data.\n",
    "\n",
    "            Returns the predicted values in two forms:\n",
    "\n",
    "            1.either by picking up the highest value along the columns for every row,\n",
    "                i.e. \"np.argmax(self.A[-1].T, axis=1)\"\n",
    "            2.or by returning a matrix that is in the shape of Y.T where each column\n",
    "                represents the probability of the instance belonging to that class.\n",
    "                Please note that every column in Y.T represents a class. To be able to\n",
    "                return the probability matrix, the final activation function must be\n",
    "                softmax!\n",
    "                i.e. \"array([0.9650488423, 0.0354737543, 0.0005225966])\"\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Training set in the shape of\n",
    "                (no_of_features, no_of_training examples).\n",
    "            return_prob_matrix (bool, optional): Returns the probability matrix if True.\n",
    "                Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray:\n",
    "\n",
    "            if return_prob_matrix is False, the output is in the shape of\n",
    "                (no_of_training_examples, 1)\n",
    "            if return_prob_matrix is True, the output is in the shape of\n",
    "                (no_of_training_examples, no_of_features)\n",
    "        \"\"\"\n",
    "        A, Z = self.forwardpass(X)\n",
    "        if return_prob_matrix:\n",
    "            np.set_printoptions(precision=10, suppress=True)\n",
    "            return A[-1].T\n",
    "        return np.argmax(A[-1].T, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with benchmark datasets\n",
    "\n",
    "## 1.Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "x = data.data[:,[0,2]]\n",
    "y = data.target\n",
    "\n",
    "X = x.T\n",
    "Y = one_hot_encode(y).T\n",
    "\n",
    "# test, train = split_data_as(x, y, train=0.8, test=0.2)\n",
    "\n",
    "# X_train = train[:, :-1]\n",
    "# Y_train = train[:, -1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 150)\n",
      "(3, 150)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "# print(\"\\n\")\n",
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)\n",
    "# print(\"\\n\")\n",
    "# print(X_validation.shape)\n",
    "# print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********1/216*********\n",
      "Running model 1 fold 1\n",
      "\n",
      "*********2/216*********\n",
      "Running model 1 fold 2\n",
      "\n",
      "*********3/216*********\n",
      "Running model 1 fold 3\n",
      "\n",
      "*********4/216*********\n",
      "Running model 2 fold 1\n",
      "\n",
      "*********5/216*********\n",
      "Running model 2 fold 2\n",
      "\n",
      "*********6/216*********\n",
      "Running model 2 fold 3\n",
      "\n",
      "*********7/216*********\n",
      "Running model 3 fold 1\n",
      "\n",
      "*********8/216*********\n",
      "Running model 3 fold 2\n",
      "\n",
      "*********9/216*********\n",
      "Running model 3 fold 3\n",
      "\n",
      "*********10/216*********\n",
      "Running model 4 fold 1\n",
      "\n",
      "*********11/216*********\n",
      "Running model 4 fold 2\n",
      "\n",
      "*********12/216*********\n",
      "Running model 4 fold 3\n",
      "\n",
      "*********13/216*********\n",
      "Running model 5 fold 1\n",
      "\n",
      "*********14/216*********\n",
      "Running model 5 fold 2\n",
      "\n",
      "*********15/216*********\n",
      "Running model 5 fold 3\n",
      "\n",
      "*********16/216*********\n",
      "Running model 6 fold 1\n",
      "\n",
      "*********17/216*********\n",
      "Running model 6 fold 2\n",
      "\n",
      "*********18/216*********\n",
      "Running model 6 fold 3\n",
      "\n",
      "*********19/216*********\n",
      "Running model 7 fold 1\n",
      "\n",
      "*********20/216*********\n",
      "Running model 7 fold 2\n",
      "\n",
      "*********21/216*********\n",
      "Running model 7 fold 3\n",
      "\n",
      "*********22/216*********\n",
      "Running model 8 fold 1\n",
      "\n",
      "*********23/216*********\n",
      "Running model 8 fold 2\n",
      "\n",
      "*********24/216*********\n",
      "Running model 8 fold 3\n",
      "\n",
      "*********25/216*********\n",
      "Running model 9 fold 1\n",
      "\n",
      "*********26/216*********\n",
      "Running model 9 fold 2\n",
      "\n",
      "*********27/216*********\n",
      "Running model 9 fold 3\n",
      "\n",
      "*********28/216*********\n",
      "Running model 10 fold 1\n",
      "\n",
      "*********29/216*********\n",
      "Running model 10 fold 2\n",
      "\n",
      "*********30/216*********\n",
      "Running model 10 fold 3\n",
      "\n",
      "*********31/216*********\n",
      "Running model 11 fold 1\n",
      "\n",
      "*********32/216*********\n",
      "Running model 11 fold 2\n",
      "\n",
      "*********33/216*********\n",
      "Running model 11 fold 3\n",
      "\n",
      "*********34/216*********\n",
      "Running model 12 fold 1\n",
      "\n",
      "*********35/216*********\n",
      "Running model 12 fold 2\n",
      "\n",
      "*********36/216*********\n",
      "Running model 12 fold 3\n",
      "\n",
      "*********37/216*********\n",
      "Running model 13 fold 1\n",
      "\n",
      "*********38/216*********\n",
      "Running model 13 fold 2\n",
      "\n",
      "*********39/216*********\n",
      "Running model 13 fold 3\n",
      "\n",
      "*********40/216*********\n",
      "Running model 14 fold 1\n",
      "\n",
      "*********41/216*********\n",
      "Running model 14 fold 2\n",
      "\n",
      "*********42/216*********\n",
      "Running model 14 fold 3\n",
      "\n",
      "*********43/216*********\n",
      "Running model 15 fold 1\n",
      "\n",
      "*********44/216*********\n",
      "Running model 15 fold 2\n",
      "\n",
      "*********45/216*********\n",
      "Running model 15 fold 3\n",
      "\n",
      "*********46/216*********\n",
      "Running model 16 fold 1\n",
      "\n",
      "*********47/216*********\n",
      "Running model 16 fold 2\n",
      "\n",
      "*********48/216*********\n",
      "Running model 16 fold 3\n",
      "\n",
      "*********49/216*********\n",
      "Running model 17 fold 1\n",
      "\n",
      "*********50/216*********\n",
      "Running model 17 fold 2\n",
      "\n",
      "*********51/216*********\n",
      "Running model 17 fold 3\n",
      "\n",
      "*********52/216*********\n",
      "Running model 18 fold 1\n",
      "\n",
      "*********53/216*********\n",
      "Running model 18 fold 2\n",
      "\n",
      "*********54/216*********\n",
      "Running model 18 fold 3\n",
      "\n",
      "*********55/216*********\n",
      "Running model 19 fold 1\n",
      "\n",
      "*********56/216*********\n",
      "Running model 19 fold 2\n",
      "\n",
      "*********57/216*********\n",
      "Running model 19 fold 3\n",
      "\n",
      "*********58/216*********\n",
      "Running model 20 fold 1\n",
      "\n",
      "*********59/216*********\n",
      "Running model 20 fold 2\n",
      "\n",
      "*********60/216*********\n",
      "Running model 20 fold 3\n",
      "\n",
      "*********61/216*********\n",
      "Running model 21 fold 1\n",
      "\n",
      "*********62/216*********\n",
      "Running model 21 fold 2\n",
      "\n",
      "*********63/216*********\n",
      "Running model 21 fold 3\n",
      "\n",
      "*********64/216*********\n",
      "Running model 22 fold 1\n",
      "\n",
      "*********65/216*********\n",
      "Running model 22 fold 2\n",
      "\n",
      "*********66/216*********\n",
      "Running model 22 fold 3\n",
      "\n",
      "*********67/216*********\n",
      "Running model 23 fold 1\n",
      "\n",
      "*********68/216*********\n",
      "Running model 23 fold 2\n",
      "\n",
      "*********69/216*********\n",
      "Running model 23 fold 3\n",
      "\n",
      "*********70/216*********\n",
      "Running model 24 fold 1\n",
      "\n",
      "*********71/216*********\n",
      "Running model 24 fold 2\n",
      "\n",
      "*********72/216*********\n",
      "Running model 24 fold 3\n",
      "\n",
      "*********73/216*********\n",
      "Running model 25 fold 1\n",
      "\n",
      "*********74/216*********\n",
      "Running model 25 fold 2\n",
      "\n",
      "*********75/216*********\n",
      "Running model 25 fold 3\n",
      "\n",
      "*********76/216*********\n",
      "Running model 26 fold 1\n",
      "\n",
      "*********77/216*********\n",
      "Running model 26 fold 2\n",
      "\n",
      "*********78/216*********\n",
      "Running model 26 fold 3\n",
      "\n",
      "*********79/216*********\n",
      "Running model 27 fold 1\n",
      "\n",
      "*********80/216*********\n",
      "Running model 27 fold 2\n",
      "\n",
      "*********81/216*********\n",
      "Running model 27 fold 3\n",
      "\n",
      "*********82/216*********\n",
      "Running model 28 fold 1\n",
      "\n",
      "*********83/216*********\n",
      "Running model 28 fold 2\n",
      "\n",
      "*********84/216*********\n",
      "Running model 28 fold 3\n",
      "\n",
      "*********85/216*********\n",
      "Running model 29 fold 1\n",
      "\n",
      "*********86/216*********\n",
      "Running model 29 fold 2\n",
      "\n",
      "*********87/216*********\n",
      "Running model 29 fold 3\n",
      "\n",
      "*********88/216*********\n",
      "Running model 30 fold 1\n",
      "\n",
      "*********89/216*********\n",
      "Running model 30 fold 2\n",
      "\n",
      "*********90/216*********\n",
      "Running model 30 fold 3\n",
      "\n",
      "*********91/216*********\n",
      "Running model 31 fold 1\n",
      "\n",
      "*********92/216*********\n",
      "Running model 31 fold 2\n",
      "\n",
      "*********93/216*********\n",
      "Running model 31 fold 3\n",
      "\n",
      "*********94/216*********\n",
      "Running model 32 fold 1\n",
      "\n",
      "*********95/216*********\n",
      "Running model 32 fold 2\n",
      "\n",
      "*********96/216*********\n",
      "Running model 32 fold 3\n",
      "\n",
      "*********97/216*********\n",
      "Running model 33 fold 1\n",
      "\n",
      "*********98/216*********\n",
      "Running model 33 fold 2\n",
      "\n",
      "*********99/216*********\n",
      "Running model 33 fold 3\n",
      "\n",
      "*********100/216*********\n",
      "Running model 34 fold 1\n",
      "\n",
      "*********101/216*********\n",
      "Running model 34 fold 2\n",
      "\n",
      "*********102/216*********\n",
      "Running model 34 fold 3\n",
      "\n",
      "*********103/216*********\n",
      "Running model 35 fold 1\n",
      "\n",
      "*********104/216*********\n",
      "Running model 35 fold 2\n",
      "\n",
      "*********105/216*********\n",
      "Running model 35 fold 3\n",
      "\n",
      "*********106/216*********\n",
      "Running model 36 fold 1\n",
      "\n",
      "*********107/216*********\n",
      "Running model 36 fold 2\n",
      "\n",
      "*********108/216*********\n",
      "Running model 36 fold 3\n",
      "\n",
      "*********109/216*********\n",
      "Running model 37 fold 1\n",
      "\n",
      "*********110/216*********\n",
      "Running model 37 fold 2\n",
      "\n",
      "*********111/216*********\n",
      "Running model 37 fold 3\n",
      "\n",
      "*********112/216*********\n",
      "Running model 38 fold 1\n",
      "\n",
      "*********113/216*********\n",
      "Running model 38 fold 2\n",
      "\n",
      "*********114/216*********\n",
      "Running model 38 fold 3\n",
      "\n",
      "*********115/216*********\n",
      "Running model 39 fold 1\n",
      "\n",
      "*********116/216*********\n",
      "Running model 39 fold 2\n",
      "\n",
      "*********117/216*********\n",
      "Running model 39 fold 3\n",
      "\n",
      "*********118/216*********\n",
      "Running model 40 fold 1\n",
      "\n",
      "*********119/216*********\n",
      "Running model 40 fold 2\n",
      "\n",
      "*********120/216*********\n",
      "Running model 40 fold 3\n",
      "\n",
      "*********121/216*********\n",
      "Running model 41 fold 1\n",
      "\n",
      "*********122/216*********\n",
      "Running model 41 fold 2\n",
      "\n",
      "*********123/216*********\n",
      "Running model 41 fold 3\n",
      "\n",
      "*********124/216*********\n",
      "Running model 42 fold 1\n",
      "\n",
      "*********125/216*********\n",
      "Running model 42 fold 2\n",
      "\n",
      "*********126/216*********\n",
      "Running model 42 fold 3\n",
      "\n",
      "*********127/216*********\n",
      "Running model 43 fold 1\n",
      "\n",
      "*********128/216*********\n",
      "Running model 43 fold 2\n",
      "\n",
      "*********129/216*********\n",
      "Running model 43 fold 3\n",
      "\n",
      "*********130/216*********\n",
      "Running model 44 fold 1\n",
      "\n",
      "*********131/216*********\n",
      "Running model 44 fold 2\n",
      "\n",
      "*********132/216*********\n",
      "Running model 44 fold 3\n",
      "\n",
      "*********133/216*********\n",
      "Running model 45 fold 1\n",
      "\n",
      "*********134/216*********\n",
      "Running model 45 fold 2\n",
      "\n",
      "*********135/216*********\n",
      "Running model 45 fold 3\n",
      "\n",
      "*********136/216*********\n",
      "Running model 46 fold 1\n",
      "\n",
      "*********137/216*********\n",
      "Running model 46 fold 2\n",
      "\n",
      "*********138/216*********\n",
      "Running model 46 fold 3\n",
      "\n",
      "*********139/216*********\n",
      "Running model 47 fold 1\n",
      "\n",
      "*********140/216*********\n",
      "Running model 47 fold 2\n",
      "\n",
      "*********141/216*********\n",
      "Running model 47 fold 3\n",
      "\n",
      "*********142/216*********\n",
      "Running model 48 fold 1\n",
      "\n",
      "*********143/216*********\n",
      "Running model 48 fold 2\n",
      "\n",
      "*********144/216*********\n",
      "Running model 48 fold 3\n",
      "\n",
      "*********145/216*********\n",
      "Running model 49 fold 1\n",
      "\n",
      "*********146/216*********\n",
      "Running model 49 fold 2\n",
      "\n",
      "*********147/216*********\n",
      "Running model 49 fold 3\n",
      "\n",
      "*********148/216*********\n",
      "Running model 50 fold 1\n",
      "\n",
      "*********149/216*********\n",
      "Running model 50 fold 2\n",
      "\n",
      "*********150/216*********\n",
      "Running model 50 fold 3\n",
      "\n",
      "*********151/216*********\n",
      "Running model 51 fold 1\n",
      "\n",
      "*********152/216*********\n",
      "Running model 51 fold 2\n",
      "\n",
      "*********153/216*********\n",
      "Running model 51 fold 3\n",
      "\n",
      "*********154/216*********\n",
      "Running model 52 fold 1\n",
      "\n",
      "*********155/216*********\n",
      "Running model 52 fold 2\n",
      "\n",
      "*********156/216*********\n",
      "Running model 52 fold 3\n",
      "\n",
      "*********157/216*********\n",
      "Running model 53 fold 1\n",
      "\n",
      "*********158/216*********\n",
      "Running model 53 fold 2\n",
      "\n",
      "*********159/216*********\n",
      "Running model 53 fold 3\n",
      "\n",
      "*********160/216*********\n",
      "Running model 54 fold 1\n",
      "\n",
      "*********161/216*********\n",
      "Running model 54 fold 2\n",
      "\n",
      "*********162/216*********\n",
      "Running model 54 fold 3\n",
      "\n",
      "*********163/216*********\n",
      "Running model 55 fold 1\n",
      "\n",
      "*********164/216*********\n",
      "Running model 55 fold 2\n",
      "\n",
      "*********165/216*********\n",
      "Running model 55 fold 3\n",
      "\n",
      "*********166/216*********\n",
      "Running model 56 fold 1\n",
      "\n",
      "*********167/216*********\n",
      "Running model 56 fold 2\n",
      "\n",
      "*********168/216*********\n",
      "Running model 56 fold 3\n",
      "\n",
      "*********169/216*********\n",
      "Running model 57 fold 1\n",
      "\n",
      "*********170/216*********\n",
      "Running model 57 fold 2\n",
      "\n",
      "*********171/216*********\n",
      "Running model 57 fold 3\n",
      "\n",
      "*********172/216*********\n",
      "Running model 58 fold 1\n",
      "\n",
      "*********173/216*********\n",
      "Running model 58 fold 2\n",
      "\n",
      "*********174/216*********\n",
      "Running model 58 fold 3\n",
      "\n",
      "*********175/216*********\n",
      "Running model 59 fold 1\n",
      "\n",
      "*********176/216*********\n",
      "Running model 59 fold 2\n",
      "\n",
      "*********177/216*********\n",
      "Running model 59 fold 3\n",
      "\n",
      "*********178/216*********\n",
      "Running model 60 fold 1\n",
      "\n",
      "*********179/216*********\n",
      "Running model 60 fold 2\n",
      "\n",
      "*********180/216*********\n",
      "Running model 60 fold 3\n",
      "\n",
      "*********181/216*********\n",
      "Running model 61 fold 1\n",
      "\n",
      "*********182/216*********\n",
      "Running model 61 fold 2\n",
      "\n",
      "*********183/216*********\n",
      "Running model 61 fold 3\n",
      "\n",
      "*********184/216*********\n",
      "Running model 62 fold 1\n",
      "\n",
      "*********185/216*********\n",
      "Running model 62 fold 2\n",
      "\n",
      "*********186/216*********\n",
      "Running model 62 fold 3\n",
      "\n",
      "*********187/216*********\n",
      "Running model 63 fold 1\n",
      "\n",
      "*********188/216*********\n",
      "Running model 63 fold 2\n",
      "\n",
      "*********189/216*********\n",
      "Running model 63 fold 3\n",
      "\n",
      "*********190/216*********\n",
      "Running model 64 fold 1\n",
      "\n",
      "*********191/216*********\n",
      "Running model 64 fold 2\n",
      "\n",
      "*********192/216*********\n",
      "Running model 64 fold 3\n",
      "\n",
      "*********193/216*********\n",
      "Running model 65 fold 1\n",
      "\n",
      "*********194/216*********\n",
      "Running model 65 fold 2\n",
      "\n",
      "*********195/216*********\n",
      "Running model 65 fold 3\n",
      "\n",
      "*********196/216*********\n",
      "Running model 66 fold 1\n",
      "\n",
      "*********197/216*********\n",
      "Running model 66 fold 2\n",
      "\n",
      "*********198/216*********\n",
      "Running model 66 fold 3\n",
      "\n",
      "*********199/216*********\n",
      "Running model 67 fold 1\n",
      "\n",
      "*********200/216*********\n",
      "Running model 67 fold 2\n",
      "\n",
      "*********201/216*********\n",
      "Running model 67 fold 3\n",
      "\n",
      "*********202/216*********\n",
      "Running model 68 fold 1\n",
      "\n",
      "*********203/216*********\n",
      "Running model 68 fold 2\n",
      "\n",
      "*********204/216*********\n",
      "Running model 68 fold 3\n",
      "\n",
      "*********205/216*********\n",
      "Running model 69 fold 1\n",
      "\n",
      "*********206/216*********\n",
      "Running model 69 fold 2\n",
      "\n",
      "*********207/216*********\n",
      "Running model 69 fold 3\n",
      "\n",
      "*********208/216*********\n",
      "Running model 70 fold 1\n",
      "\n",
      "*********209/216*********\n",
      "Running model 70 fold 2\n",
      "\n",
      "*********210/216*********\n",
      "Running model 70 fold 3\n",
      "\n",
      "*********211/216*********\n",
      "Running model 71 fold 1\n",
      "\n",
      "*********212/216*********\n",
      "Running model 71 fold 2\n",
      "\n",
      "*********213/216*********\n",
      "Running model 71 fold 3\n",
      "\n",
      "*********214/216*********\n",
      "Running model 72 fold 1\n",
      "\n",
      "*********215/216*********\n",
      "Running model 72 fold 2\n",
      "\n",
      "*********216/216*********\n",
      "Running model 72 fold 3\n"
     ]
    }
   ],
   "source": [
    "results_dict_all_models, results_average_dict, models = grid_search(\n",
    "    x,\n",
    "    y,\n",
    "    metric='F1',\n",
    "    clf=NeuralNetwork,\n",
    "    n_fold=3,\n",
    "    param_grid_dict={\n",
    "        'batch_size': [8, 16, 32, 64],\n",
    "        'input_layer': [(2, 'relu'), (2, 'tanh')],\n",
    "        'hidden_layer': [\n",
    "            [(4,'relu'), (8,'sigmoid'), (16,'relu'), (8,'sigmoid'), (4,'softmax')],\n",
    "            [(4,'relu'), (4,'relu'),(4,'softmax')],\n",
    "            [(4,'sigmoid'),(4,'softmax')]\n",
    "        ],\n",
    "        'output_layer': [3],\n",
    "        'alpha': [1, 2, 4],\n",
    "        'verbose': [False],\n",
    "        'epoch': [1]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_1': <__main__.NeuralNetwork at 0x151a06b0>,\n",
       " 'model_10': <__main__.NeuralNetwork at 0x73254b0>,\n",
       " 'model_11': <__main__.NeuralNetwork at 0x151350d0>,\n",
       " 'model_12': <__main__.NeuralNetwork at 0x14ee1530>,\n",
       " 'model_13': <__main__.NeuralNetwork at 0x14ec4dd0>,\n",
       " 'model_14': <__main__.NeuralNetwork at 0x151a0c90>,\n",
       " 'model_15': <__main__.NeuralNetwork at 0x151a0bb0>,\n",
       " 'model_16': <__main__.NeuralNetwork at 0x151a0a10>,\n",
       " 'model_17': <__main__.NeuralNetwork at 0x151a06f0>,\n",
       " 'model_18': <__main__.NeuralNetwork at 0x151a0670>,\n",
       " 'model_19': <__main__.NeuralNetwork at 0x13a49e50>,\n",
       " 'model_2': <__main__.NeuralNetwork at 0xfcbf830>,\n",
       " 'model_20': <__main__.NeuralNetwork at 0x13a49a90>,\n",
       " 'model_21': <__main__.NeuralNetwork at 0x14ec4b70>,\n",
       " 'model_22': <__main__.NeuralNetwork at 0x73253d0>,\n",
       " 'model_23': <__main__.NeuralNetwork at 0x1518fc30>,\n",
       " 'model_24': <__main__.NeuralNetwork at 0x7325450>,\n",
       " 'model_25': <__main__.NeuralNetwork at 0x151a0e30>,\n",
       " 'model_26': <__main__.NeuralNetwork at 0x151a0770>,\n",
       " 'model_27': <__main__.NeuralNetwork at 0x151a0810>,\n",
       " 'model_28': <__main__.NeuralNetwork at 0x151a0cb0>,\n",
       " 'model_29': <__main__.NeuralNetwork at 0x151a0b90>,\n",
       " 'model_3': <__main__.NeuralNetwork at 0x151a0990>,\n",
       " 'model_30': <__main__.NeuralNetwork at 0x151a0b50>,\n",
       " 'model_31': <__main__.NeuralNetwork at 0x151a0f30>,\n",
       " 'model_32': <__main__.NeuralNetwork at 0x151a0870>,\n",
       " 'model_33': <__main__.NeuralNetwork at 0x1518f290>,\n",
       " 'model_34': <__main__.NeuralNetwork at 0x7b33110>,\n",
       " 'model_35': <__main__.NeuralNetwork at 0x7325490>,\n",
       " 'model_36': <__main__.NeuralNetwork at 0x14ec41f0>,\n",
       " 'model_37': <__main__.NeuralNetwork at 0x14ee16d0>,\n",
       " 'model_38': <__main__.NeuralNetwork at 0x151a0ff0>,\n",
       " 'model_39': <__main__.NeuralNetwork at 0x151a0d70>,\n",
       " 'model_4': <__main__.NeuralNetwork at 0x151a0ab0>,\n",
       " 'model_40': <__main__.NeuralNetwork at 0x151a06d0>,\n",
       " 'model_41': <__main__.NeuralNetwork at 0x151a0c50>,\n",
       " 'model_42': <__main__.NeuralNetwork at 0x151a0a30>,\n",
       " 'model_43': <__main__.NeuralNetwork at 0x151a05f0>,\n",
       " 'model_44': <__main__.NeuralNetwork at 0x151a0fd0>,\n",
       " 'model_45': <__main__.NeuralNetwork at 0x162a8170>,\n",
       " 'model_46': <__main__.NeuralNetwork at 0x162a8250>,\n",
       " 'model_47': <__main__.NeuralNetwork at 0x151a0690>,\n",
       " 'model_48': <__main__.NeuralNetwork at 0x151a0910>,\n",
       " 'model_49': <__main__.NeuralNetwork at 0x151a0b30>,\n",
       " 'model_5': <__main__.NeuralNetwork at 0x151a0bd0>,\n",
       " 'model_50': <__main__.NeuralNetwork at 0x151a0bf0>,\n",
       " 'model_51': <__main__.NeuralNetwork at 0x151a0710>,\n",
       " 'model_52': <__main__.NeuralNetwork at 0x14ee10d0>,\n",
       " 'model_53': <__main__.NeuralNetwork at 0x14ec4970>,\n",
       " 'model_54': <__main__.NeuralNetwork at 0x13a49990>,\n",
       " 'model_55': <__main__.NeuralNetwork at 0x1518fb90>,\n",
       " 'model_56': <__main__.NeuralNetwork at 0x7b33550>,\n",
       " 'model_57': <__main__.NeuralNetwork at 0x162a82d0>,\n",
       " 'model_58': <__main__.NeuralNetwork at 0x162a82b0>,\n",
       " 'model_59': <__main__.NeuralNetwork at 0x162a80d0>,\n",
       " 'model_6': <__main__.NeuralNetwork at 0x151a0cf0>,\n",
       " 'model_60': <__main__.NeuralNetwork at 0x7b33130>,\n",
       " 'model_61': <__main__.NeuralNetwork at 0x72f9270>,\n",
       " 'model_62': <__main__.NeuralNetwork at 0x7325430>,\n",
       " 'model_63': <__main__.NeuralNetwork at 0x13a49a50>,\n",
       " 'model_64': <__main__.NeuralNetwork at 0x72f9bb0>,\n",
       " 'model_65': <__main__.NeuralNetwork at 0x151a0cd0>,\n",
       " 'model_66': <__main__.NeuralNetwork at 0x151a0890>,\n",
       " 'model_67': <__main__.NeuralNetwork at 0x151a0f10>,\n",
       " 'model_68': <__main__.NeuralNetwork at 0x72f9ff0>,\n",
       " 'model_69': <__main__.NeuralNetwork at 0x13a49a30>,\n",
       " 'model_7': <__main__.NeuralNetwork at 0x1518f5d0>,\n",
       " 'model_70': <__main__.NeuralNetwork at 0x162a8430>,\n",
       " 'model_71': <__main__.NeuralNetwork at 0x162a8370>,\n",
       " 'model_72': <__main__.NeuralNetwork at 0x162a8150>,\n",
       " 'model_8': <__main__.NeuralNetwork at 0x7b33030>,\n",
       " 'model_9': <__main__.NeuralNetwork at 0x7325570>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F1': 0.0,\n",
       " 'accuracy': 33.33333333311111,\n",
       " 'false_positive_rate': 49.9999999995,\n",
       " 'precision': 0.0,\n",
       " 'prevalence': 33.33333333311111,\n",
       " 'sensitivity/recall': 0.0,\n",
       " 'specificity': 49.9999999995}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_model_performance(\n",
    "    np.argmax(Y, axis=0),\n",
    "    models[\"model_17\"].predict(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer: (2, 'tanh')\n",
      "Hidden layer: [(4, 'sigmoid'), (4, 'softmax')]\n",
      "Output layer: 3\n",
      "Batch size: 8\n",
      "Learning rate: 2\n",
      "Epoch: 1\n",
      "Seed: 42\n",
      "Verbose: False\n",
      "Metric: accuracy\n"
     ]
    }
   ],
   "source": [
    "print(models[\"model_17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "dt = data.data[:,[0,2]]\n",
    "x_min, x_max = dt[:, 0].min() - 1, dt[:, 0].max() + 1\n",
    "y_min, y_max = dt[:, 1].min() - 1, dt[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "Z = models[\"model_17\"].predict(np.c_[xx.ravel(), yy.ravel()].T) \n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.contourf(xx, yy, Z,alpha=0.4)\n",
    "#plt.axis('off')\n",
    "\n",
    "plt.scatter(dt[:, 0], dt[:, 1], c=y,s=20, edgecolor='k')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "\n",
    "plt.contour(xx, yy, Z, [0.5], linewidths=2, colors=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Make Moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "x,y =make_moons(n_samples=1500, noise=.05)\n",
    "X = x.T\n",
    "Y = one_hot_encode(y).T\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    input_layer=(2, \"sigmoid\"),\n",
    "    hidden_layer=[(8, \"tanh\"),\n",
    "                  (6, \"relu\"),\n",
    "                  (4, \"softmax\")],\n",
    "    output_layer=2,\n",
    "    batch_size=64,\n",
    "    alpha=0.5,\n",
    "    epoch=2500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Decision Boundaries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dt = x\n",
    "x_min, x_max = dt[:, 0].min() - 0.5, dt[:, 0].max() + 0.5\n",
    "y_min, y_max = dt[:, 1].min() - 0.5, dt[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()].T) \n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.contourf(xx, yy, Z,alpha=0.4)\n",
    "#plt.axis('off')\n",
    "plt.scatter(dt[:, 0], dt[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Decision Boundaries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Andrew NG Assignment 2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex2data2 = np.loadtxt(\"../ex2/data/ex2data2.txt\", delimiter=\",\")\n",
    "\n",
    "x = ex2data2[:, :-1]\n",
    "y = ex2data2[:, -1]\n",
    "\n",
    "X = X.T\n",
    "Y = one_hot_encode(y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 118)\n",
      "(2, 118)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********1/162*********\n",
      "Running model 1 fold 1\n",
      "\n",
      "*********2/162*********\n",
      "Running model 1 fold 2\n"
     ]
    }
   ],
   "source": [
    "results_dict_all_models, results_average_dict, models = grid_search(\n",
    "    x,\n",
    "    y,\n",
    "    metric='F1',\n",
    "    clf=NeuralNetwork,\n",
    "    n_fold=3,\n",
    "    param_grid_dict={\n",
    "        'batch_size': [8, 16, 32],\n",
    "        'input_layer': [(2, 'relu'), (2, 'tanh')],\n",
    "        'hidden_layer': [\n",
    "            [(4,'relu'), (8,'sigmoid'), (16,'relu'), (8,'sigmoid'), (4,'softmax')],\n",
    "            [(4,'relu'), (4,'relu'),(4,'softmax')],\n",
    "            [(4,'sigmoid'),(4,'softmax')]\n",
    "        ],\n",
    "        'output_layer': [2],\n",
    "        'alpha': [0.5, 2, 4],\n",
    "        'verbose': [False],\n",
    "        'epoch': [10000]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model_47', 70.81000759906118),\n",
       " ('model_17', 70.35176554804058),\n",
       " ('model_11', 69.99717487121468),\n",
       " ('model_28', 69.65305225763986),\n",
       " ('model_29', 69.22015182529223),\n",
       " ('model_14', 69.11644563414607),\n",
       " ('model_36', 67.7600919888149),\n",
       " ('model_53', 67.4199960208186),\n",
       " ('model_46', 67.30158729772423),\n",
       " ('model_50', 66.99074073663523),\n",
       " ('model_51', 66.65110488256515),\n",
       " ('model_54', 65.77326538412628),\n",
       " ('model_18', 65.71428571011351),\n",
       " ('model_9', 65.53856509345084),\n",
       " ('model_32', 65.30692182458787),\n",
       " ('model_44', 65.05596505241765),\n",
       " ('model_35', 64.90708478147435),\n",
       " ('model_10', 64.84905958221239),\n",
       " ('model_33', 64.63203462811475),\n",
       " ('model_12', 63.52928913584623),\n",
       " ('model_15', 62.6082251043139),\n",
       " ('model_7', 62.34034698790952),\n",
       " ('model_26', 59.84240053648949),\n",
       " ('model_8', 58.80574451659507),\n",
       " ('model_25', 58.79643769265733),\n",
       " ('model_43', 44.24103737360431),\n",
       " ('model_27', 29.61287078735877),\n",
       " ('model_42', 22.641509432951235),\n",
       " ('model_30', 20.155038758588066),\n",
       " ('model_24', 17.777777776823044),\n",
       " ('model_6', 16.6666666657438),\n",
       " ('model_45', 15.384615383659872),\n",
       " ('model_48', 12.962962962076645),\n",
       " ('model_34', 4.444444444),\n",
       " ('model_31', 4.301075268381546),\n",
       " ('model_49', 4.301075268381546),\n",
       " ('model_13', 4.301075268381546),\n",
       " ('model_16', 2.3809523806462582),\n",
       " ('model_52', 2.3809523806462582),\n",
       " ('model_5', 0.0),\n",
       " ('model_1', 0.0),\n",
       " ('model_21', 0.0),\n",
       " ('model_20', 0.0),\n",
       " ('model_22', 0.0),\n",
       " ('model_23', 0.0),\n",
       " ('model_4', 0.0),\n",
       " ('model_41', 0.0),\n",
       " ('model_39', 0.0),\n",
       " ('model_2', 0.0),\n",
       " ('model_38', 0.0),\n",
       " ('model_3', 0.0),\n",
       " ('model_19', 0.0),\n",
       " ('model_37', 0.0),\n",
       " ('model_40', 0.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_average_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer: (2, 'tanh')\n",
      "Hidden layer: [(4, 'relu'), (4, 'relu'), (4, 'softmax')]\n",
      "Output layer: 2\n",
      "Batch size: 32\n",
      "Learning rate: 2\n",
      "Epoch: 500\n",
      "Seed: 42\n",
      "Verbose: False\n",
      "Metric: accuracy\n"
     ]
    }
   ],
   "source": [
    "print(models[results_average_dict[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py:6461: MaskedArrayFutureWarning: In the future the default for ma.maximum.reduce will be axis=0, not the current None, to match np.maximum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n",
      "C:\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py:6461: MaskedArrayFutureWarning: In the future the default for ma.minimum.reduce will be axis=0, not the current None, to match np.minimum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x2e545f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAHpCAYAAACfs8p4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5eeb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Decision Boundaries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "X = ex2data2\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 0.3, X[:, 0].max() + 0.3,\n",
    "x2_min, x2_max = X[:, 1].min() - 0.3, X[:, 1].max() + 0.3,\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "Z = models[\"model_47\"].predict(np.c_[xx1.ravel(), xx2.ravel()].T) \n",
    "\n",
    "negatives = ex2data2[ex2data2[:, -1] == 0]\n",
    "positives = ex2data2[ex2data2[:, -1] == 1]\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx1.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.contourf(xx1, xx2, Z,alpha=0.4)\n",
    "#plt.axis('off')\n",
    "plt.scatter(negatives[:, 0], negatives[:, 1],s=50, color='k')\n",
    "plt.scatter(positives[:, 0], positives[:, 1],s=50, color='r')\n",
    "plt.title('Decision Boundaries')\n",
    "\n",
    "plt.contour(xx1, xx2, Z, [0.5], linewidths=2, colors=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "data = loadmat('../ex3/data/ex3data1.mat')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data[\"X\"]\n",
    "y = data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, validation = split_data_as(x,y, train=0.6, test=0.2, validation=0.2)\n",
    "\n",
    "X_train = train[:, :-1].T\n",
    "Y_train = one_hot_encode(train[:, -1]).T\n",
    "\n",
    "X_test = test[:, :-1].T\n",
    "Y_test = one_hot_encode(test[:, -1]).T\n",
    "\n",
    "X_validation = validation[:, :-1].T\n",
    "Y_validation = one_hot_encode(validation[:, -1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(\"\\n\")\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(\"\\n\")\n",
    "print(X_validation.shape)\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "sample = np.random.choice(data[\"X\"].shape[0], 20)\n",
    "ax.imshow(data[\"X\"][sample,1:].reshape(-1,20).T)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    input_layer=(X_train.shape[0], \"relu\"),\n",
    "    hidden_layer=[(10, \"relu\"),\n",
    "                  (10, \"softmax\")],\n",
    "    output_layer=Y_train.shape[0],\n",
    "    batch_size=16,\n",
    "    alpha=0.2,\n",
    "    epoch=500,\n",
    "    random_state=12\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(model.predict(X_train) == np.argmax(Y_train,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_model_performance(\n",
    "    np.argmax(Y_train,axis=0),\n",
    "    model.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, (act, predicted) in enumerate(zip(np.argmax(Y_train,axis=0), model.predict(X_train))):\n",
    "    if act != predicted:\n",
    "        fig, ax = plt.subplots(figsize = (2,2))\n",
    "        ax.set_title(\"%s: act %s --- predicted %s\" %(index, act + 1, predicted + 1))\n",
    "        ax.imshow(X_train[:, index].reshape(-1,20).T)\n",
    "        ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_model_performance(\n",
    "    np.argmax(Y_test,axis=0),\n",
    "    model.predict(X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, (act, predicted) in enumerate(zip(np.argmax(Y_test,axis=0), model.predict(X_test))):\n",
    "    if act != predicted:\n",
    "        fig, ax = plt.subplots(figsize = (2,2))\n",
    "        ax.set_title(\"%s: act %s --- predicted %s\" %(index, act + 1, predicted + 1))\n",
    "        ax.imshow(X_test[:, index].reshape(-1,20).T)\n",
    "        ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
