{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utility_functions import (calculate_model_performance,\n",
    "                               plot_ROC,\n",
    "                               one_hot_encode,\n",
    "                               split_data_as,\n",
    "                               grid_search,\n",
    "                               shuffled,\n",
    "                               timeit)\n",
    "\n",
    "EPSILON = 10e-08\n",
    "\n",
    "# error rate\n",
    "# https://stats.stackexchange.com/questions/133458/is-accuracy-1-test-error-rate\n",
    "\n",
    "\n",
    "def get_shapes(any_):\n",
    "    for array in any_:\n",
    "        try:\n",
    "            print(array.shape)\n",
    "        except:\n",
    "            print(\"NONE\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "def plot_loss(train_loss, test_loss):\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    \n",
    "    ax.set_xlabel(\"iteration count x 100\", fontsize=15, labelpad=10)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=15, labelpad=10)\n",
    "    ax.set_title(\"Loss vs Iteration\", fontsize=20)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    \n",
    "    lines, = ax.plot(train_loss, c=\"blue\", label=\"train_loss\")\n",
    "    lines, = ax.plot(test_loss, c=\"green\", label=\"test_loss\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# ============= ACTIVATION FUNCTIONS ===============#\n",
    "\n",
    "def sigmoid(Z, prime=False):\n",
    "    # np.\n",
    "    if prime:\n",
    "        return sigmoid(Z) * (1 - sigmoid(Z))\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "def linear(Z, prime=False):\n",
    "    if prime:\n",
    "        return np.ones_like(Z)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def relu(Z, alpha=0.01, prime=False):\n",
    "    if prime:\n",
    "        Z_relu = np.ones_like(Z, dtype=np.float64)\n",
    "        Z_relu[Z < 0] = alpha\n",
    "        return Z_relu\n",
    "    return np.where(Z < 0, alpha * Z, Z)\n",
    "\n",
    "\n",
    "def tanh(Z, prime=False):\n",
    "    # np.tanh() could be used directly to speed this up\n",
    "    if prime:\n",
    "        return 1 - np.power(tanh(Z), 2)\n",
    "    return (2 / (1 + np.exp(-2 * Z))) - 1\n",
    "\n",
    "\n",
    "def elu(Z, prime=False):\n",
    "    # https://mlfromscratch.com/activation-functions-explained/#/\n",
    "    alpha = 0.2\n",
    "    if prime:\n",
    "        return np.where(Z < 0, alpha * (np.exp(Z)), 1)\n",
    "    return np.where(Z < 0, alpha * (np.exp(Z) - 1), Z)\n",
    "\n",
    "\n",
    "def softmax(Z, prime=False):\n",
    "    # https://deepnotes.io/softmax-crossentropy\n",
    "    # max(Z) term is added to stabilise the function.\n",
    "    exps = np.exp(Z - np.max(Z))\n",
    "    return exps / np.sum(exps, axis=0)\n",
    "\n",
    "# References\n",
    "# https://mc.ai/multilayered-neural-network-from-scratch-using-python/\n",
    "# https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "# https://www.coursera.org/learn/machine-learning/home/week/5\n",
    "# https://www.coursera.org/specializations/deep-learning\n",
    "# https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py\n",
    "# https://github.com/JWarmenhoven/Coursera-Machine-Learning\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_layer: tuple,\n",
    "            hidden_layer: list,  # list of tuples\n",
    "            output_layer: int,\n",
    "            batch_size=16,\n",
    "            alpha=0.01,\n",
    "            optimizer=\"SGD\",\n",
    "            weight_initialisation = \"he_uniform\",\n",
    "            penalty=None,\n",
    "            lambd=0.01,\n",
    "            keep_prob = None,\n",
    "            epoch=500,\n",
    "            random_state=42,\n",
    "            verbose=True,\n",
    "            metrics=\"accuracy\",\n",
    "            history=True\n",
    "    ):\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.mini_batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.optimizer = optimizer\n",
    "        self.weight_initialisation = weight_initialisation\n",
    "        self.penalty = penalty\n",
    "        self.lambd = lambd\n",
    "        self.keep_prob = keep_prob\n",
    "        # dropout: http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\n",
    "        self.dropout = True if isinstance(self.keep_prob, float) else False\n",
    "        self.epoch = epoch\n",
    "        self.seed = random_state\n",
    "        self.verbose = verbose\n",
    "        self.metrics = metrics\n",
    "        self.history = history\n",
    "        self.layers = len(self.weight_set_dimensions) + 1\n",
    "        self.EPSILON = 10e-10\n",
    "        self.train_error = []\n",
    "        self.test_error = []\n",
    "\n",
    "        self.initial_lr = alpha[\"initial_lr\"] if isinstance(alpha, dict) else None\n",
    "        self.decay = alpha[\"decay\"] if isinstance(alpha, dict) else None\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        parameters = (\n",
    "            \"Input layer: {0}\\n\"\n",
    "            \"Hidden layer: {1}\\n\"\n",
    "            \"Output layer: {2}\\n\"\n",
    "            \"Batch size: {3}\\n\"\n",
    "            \"Learning rate: {4}\\n\"\n",
    "            \"Epoch: {5}\\n\"\n",
    "            \"Seed: {6}\\n\"\n",
    "            \"Verbose: {7}\\n\"\n",
    "            \"Metric: {8}\"\n",
    "        ).format(\n",
    "            self.input_layer,\n",
    "            \" - \".join(map(str, self.hidden_layer)),\n",
    "            self.output_layer,\n",
    "            self.mini_batch_size,\n",
    "            self.alpha,\n",
    "            self.epoch,\n",
    "            self.seed,\n",
    "            self.verbose,\n",
    "            self.metrics\n",
    "        )\n",
    "        return parameters\n",
    "\n",
    "    def get_A(self, X, predict=True):\n",
    "        A, _ = self.forwardpass(X, predict=predict)\n",
    "        return A\n",
    "\n",
    "    def get_Z(self, X, predict=True):\n",
    "        _, Z = self.forwardpass(X, predict=predict)\n",
    "        return Z\n",
    "        \n",
    "    # ============== LOSS FUNCTIONS ===============#\n",
    "\n",
    "    # https://deepnotes.io/softmax-crossentropy\n",
    "\n",
    "    def calculate_error(self, Y, Y_hat):\n",
    "        # Y and Y_hat should be in the form of (no_of_classes, no_of_training_examples)\n",
    "        cost = -np.sum(Y * np.log(Y_hat + EPSILON)) / self.m\n",
    "        if self.penalty == \"l1\":\n",
    "            for layer in range(1, self.layers):\n",
    "                cost += np.sum(np.abs(self.W[layer])) * self.lambd / (2 * self.m)\n",
    "        elif self.penalty == \"l2\":\n",
    "            for layer in range(1, self.layers):\n",
    "                cost += np.sum(np.square(self.W[layer])) * self.lambd / (2 * self.m)\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def display_information(self, X, Y, X_test, Y_test, alpha):\n",
    "        model_performance_metrics_train = calculate_model_performance(\n",
    "            np.argmax(Y, axis=0),\n",
    "            self.predict(X)\n",
    "        )\n",
    "        \n",
    "        train_error = np.round(self.calculate_error(Y, self.get_A(X)[-1]), 10)\n",
    "        test_error = np.round(self.calculate_error(Y_test, self.get_A(X_test)[-1]), 10)\n",
    "        \n",
    "        if self.history:\n",
    "            self.train_error.append(train_error)\n",
    "            self.test_error.append(test_error)\n",
    "\n",
    "        print(\"train_{0}: {1} - epoch {2}    iteration {3} - train loss {4} ____ test loss {5} --- alpha: {6}\".format(\n",
    "            self.metrics,\n",
    "            np.round(model_performance_metrics_train[self.metrics], 5),\n",
    "            self.epoch_count,\n",
    "            self.no_of_iterations,\n",
    "            train_error,\n",
    "            test_error,\n",
    "            np.round(alpha, 5)\n",
    "        ))\n",
    "\n",
    "\n",
    "    def get_dimensions_and_activations(self):\n",
    "        self.dimensions = []\n",
    "        self.activation_functions = []\n",
    "\n",
    "        self.dimensions.append(self.input_layer[0])\n",
    "        self.activation_functions.append(self.input_layer[1])\n",
    "\n",
    "        for dim, act_func in self.hidden_layer:\n",
    "            self.dimensions.append(dim)\n",
    "            self.activation_functions.append(act_func)\n",
    "\n",
    "        self.dimensions.append(self.output_layer)\n",
    "\n",
    "    @property\n",
    "    def weight_set_dimensions(self):\n",
    "        self.get_dimensions_and_activations()\n",
    "        a, b = itertools.tee(self.dimensions[::-1])\n",
    "        next(b, None)\n",
    "        weight_set_dimensions = list(zip(a, b))[::-1]\n",
    "        return weight_set_dimensions\n",
    "\n",
    "    def initialise_weights(self, layer=None):\n",
    "        self.W = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.B = np.empty_like(range(self.layers), dtype=object)\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        for layer, (y, x) in zip(range(1, self.layers), self.weight_set_dimensions):\n",
    "            # x = (layer - 1) *** fan_in\n",
    "            # y = (layer)  *** fan_out\n",
    "            \n",
    "            # difference between randn and normal:\n",
    "            # https://stackoverflow.com/questions/21738383/python-difference-between-randn-and-normal\n",
    "\n",
    "            if isinstance(self.weight_initialisation, dict):\n",
    "                if self.weight_initialisation[\"method\"] == \"random_normal\":\n",
    "                    mean = self.weight_initialisation[\"mean\"]\n",
    "                    standard_deviation = self.weight_initialisation[\"standard_deviation\"]\n",
    "\n",
    "                    self.W[layer] = np.random.normal(mean, standard_deviation, size=(y, x))\n",
    "                    self.B[layer] = np.random.normal(mean, standard_deviation, size=(y, 1))\n",
    "\n",
    "                elif self.weight_initialisation[\"method\"] == \"random_uniform\":\n",
    "                    min_ = self.weight_initialisation[\"min\"]\n",
    "                    max_ = self.weight_initialisation[\"max\"]\n",
    "\n",
    "                    self.W[layer] = np.random.uniform(min_, max_, size=(y, x))\n",
    "                    self.B[layer] = np.random.uniform(min_, max_, size=(y, 1))\n",
    "\n",
    "            elif self.weight_initialisation == \"zeros\":\n",
    "                self.W[layer] = np.zeros((y, x))\n",
    "                self.B[layer] = np.zeros((y, 1))\n",
    "\n",
    "            elif self.weight_initialisation == \"ones\":\n",
    "                self.W[layer] = np.ones((y, x))\n",
    "                self.B[layer] = np.ones((y, 1))\n",
    "\n",
    "            elif self.weight_initialisation == \"he_normal\":\n",
    "                # https://arxiv.org/abs/1502.01852\n",
    "                # https://keras.rstudio.com/reference/initializer_he_normal.html\n",
    "                self.W[layer] = np.random.normal(\n",
    "                    loc=0,\n",
    "                    scale=np.sqrt(2 / x),\n",
    "                    size=(y, x)\n",
    "                )\n",
    "                self.B[layer] = np.zeros((y, 1))\n",
    "                \n",
    "            elif self.weight_initialisation == \"he_uniform\":\n",
    "                # https://docs.chainer.org/en/stable/reference/generated/chainer.initializers.HeUniform.html\n",
    "                # https://keras.rstudio.com/reference/initializer_he_uniform.html\n",
    "                limit = np.sqrt(6 / x)\n",
    "\n",
    "                self.W[layer] = np.random.uniform(\n",
    "                    low=-limit,\n",
    "                    high=limit,\n",
    "                    size=(y, x)\n",
    "                )\n",
    "                self.B[layer] = np.zeros((y, 1))\n",
    "            \n",
    "            elif self.weight_initialisation == \"xavier_normal\":\n",
    "                # Glorot normal initializer, also called Xavier normal initializer.\n",
    "                # https://keras.rstudio.com/reference/initializer_glorot_normal.html\n",
    "                self.W[layer] = np.random.normal(\n",
    "                    loc=0,\n",
    "                    scale=np.sqrt(2 / (x + y)),\n",
    "                    size=(y, x)\n",
    "                )\n",
    "                self.B[layer] = np.zeros((y, 1))\n",
    "                \n",
    "            elif self.weight_initialisation == \"xavier_uniform\":\n",
    "                # https://keras.rstudio.com/reference/initializer_glorot_uniform.html\n",
    "                limit = np.sqrt(6 / (x + y))\n",
    "\n",
    "                self.W[layer] = np.random.uniform(\n",
    "                    low=-limit,\n",
    "                    high=limit,\n",
    "                    size=(y, x)\n",
    "                )                \n",
    "                self.B[layer] = np.zeros((y, 1))\n",
    "\n",
    "    def forwardpass(self, X, predict=False):\n",
    "        Z = np.empty_like(range(self.layers), dtype=object)\n",
    "        A = np.empty_like(range(self.layers), dtype=object)\n",
    "        A[0] = X\n",
    "\n",
    "        for layer in range(1, self.layers):\n",
    "            # activation_function starts from 0 whereas layer starts from 1\n",
    "            active_function = self.activation_functions[layer - 1]\n",
    "            arg_to_pass_to_eval = \"(Z[layer])\"\n",
    "\n",
    "            Z[layer] = self.W[layer] @ A[layer - 1] + self.B[layer]\n",
    "            A[layer] = eval(active_function + arg_to_pass_to_eval)\n",
    "            \n",
    "            # dropout is only applied to first hidden layer\n",
    "            # https://www.kaggle.com/mtax687/dropout-regularization-of-neural-net-using-numpy\n",
    "            if self.dropout and layer == 1 and not predict:\n",
    "                self.D = np.random.randn(A[layer].shape[0], A[layer].shape[1])\n",
    "                self.D = (self.D < self.keep_prob)\n",
    "                A[layer] = np.multiply(A[layer], self.D) / self.keep_prob\n",
    "\n",
    "        return A, Z\n",
    "\n",
    "    def backpropagation(self, Y, A, Z):\n",
    "        self.delta = np.empty_like(range(self.layers), dtype=object)\n",
    "\n",
    "        self.gradient_W = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.gradient_B = np.empty_like(range(self.layers), dtype=object)\n",
    "\n",
    "        self.delta[-1] = A[-1] - Y\n",
    "\n",
    "        # We substract 1 here as delta_final is calculated seperately above\n",
    "        for layer in reversed(range(1, self.layers - 1)):\n",
    "            # 1 is substracted from layer as activation_functions start indexing from 0\n",
    "            active_function = self.activation_functions[layer - 1]\n",
    "            arg_to_pass_to_eval = \"(Z[layer], prime=True)\"\n",
    "\n",
    "            DA = self.W[layer + 1].T @ self.delta[layer + 1]\n",
    "\n",
    "            # If dropout is applied\n",
    "            if self.dropout and layer == 1:\n",
    "                DA = np.multiply(DA, self.D) / self.keep_prob\n",
    "\n",
    "\n",
    "            self.delta[layer] = (\n",
    "                    DA *\n",
    "                    eval(active_function + arg_to_pass_to_eval)\n",
    "            )\n",
    "\n",
    "        for layer in range(1, self.layers):\n",
    "            self.gradient_W[layer] = (self.delta[layer] @ A[layer - 1].T) / self.m\n",
    "            self.gradient_B[layer] = np.sum(self.delta[layer], axis=1, keepdims=True) / self.m\n",
    "            \n",
    "            if self.penalty == \"l1\":\n",
    "                # https://towardsdatascience.com/only-numpy-implementing-different-combination-of-l1-norm-l2-norm-l1-regularization-and-14b01a9773b\n",
    "                self.gradient_W[layer] += np.where(self.W[layer] < 0, -1, 1) * (self.lambd / self.m)\n",
    "            elif self.penalty == \"l2\":\n",
    "                self.gradient_W[layer] += self.W[layer] * (self.lambd / self.m)\n",
    "\n",
    "        alpha = self.update_weights()\n",
    "        return alpha\n",
    "\n",
    "    def update_weights(self):\n",
    "        # decay the learning rate\n",
    "        if isinstance(self.alpha, dict):\n",
    "            alpha = self.initial_lr / (1. + self.decay * self.epoch_count)\n",
    "        else:\n",
    "            alpha = self.alpha\n",
    "\n",
    "\n",
    "        if self.optimizer == \"SGD\":\n",
    "            for layer in range(1, self.layers):\n",
    "                self.W[layer] -= alpha * self.gradient_W[layer]\n",
    "                self.B[layer] -= alpha * self.gradient_B[layer]\n",
    "\n",
    "        elif self.optimizer[\"method\"] == \"SGDM\":\n",
    "            for layer in range(1, self.layers):\n",
    "                beta = self.optimizer[\"beta\"]\n",
    "                self.v_dw[layer] = beta * self.v_dw[layer] + (1 - beta) * self.gradient_W[layer]\n",
    "                self.v_db[layer] = beta * self.v_db[layer] + (1 - beta) * self.gradient_B[layer]\n",
    "\n",
    "                self.W[layer] -= alpha * self.v_dw[layer]\n",
    "                self.B[layer] -= alpha * self.v_db[layer]\n",
    "\n",
    "        elif self.optimizer[\"method\"] == \"RMSP\":\n",
    "            for layer in range(1, self.layers):\n",
    "                beta = self.optimizer[\"beta\"]\n",
    "                self.s_dw[layer] = beta * self.s_dw[layer] + (1 - beta) * np.square(self.gradient_W[layer])\n",
    "                self.s_db[layer] = beta * self.s_db[layer] + (1 - beta) * np.square(self.gradient_B[layer])\n",
    "\n",
    "                w_rms_grad = self.gradient_W[layer] / (np.sqrt(self.s_dw[layer]) + self.EPSILON)\n",
    "                b_rms_grad = self.gradient_B[layer] / (np.sqrt(self.s_db[layer]) + self.EPSILON)\n",
    "\n",
    "                self.W[layer] -= alpha * w_rms_grad\n",
    "                self.B[layer] -= alpha * b_rms_grad\n",
    "\n",
    "        elif self.optimizer[\"method\"] == \"ADAM\":\n",
    "            # EWA: Exponential weighted average\n",
    "            # ToDo: Check if bias correction is necessary. The EWA will be inaccurate initially,\n",
    "            # but it shouldn't take many iterations to compute correct EWA.\n",
    "            for layer in range(1, self.layers):\n",
    "                beta1 = self.optimizer[\"beta1\"]\n",
    "                beta2 = self.optimizer[\"beta2\"]\n",
    "                self.v_dw[layer] = beta1 * self.v_dw[layer] + (1 - beta1) * self.gradient_W[layer]\n",
    "                self.v_db[layer] = beta1 * self.v_db[layer] + (1 - beta1) * self.gradient_B[layer]\n",
    "\n",
    "                self.s_dw[layer] = beta2 * self.s_dw[layer] + (1 - beta2) * np.square(self.gradient_W[layer])\n",
    "                self.s_db[layer] = beta2 * self.s_db[layer] + (1 - beta2) * np.square(self.gradient_B[layer])\n",
    "\n",
    "                v_dw_corrected = self.v_dw[layer] / (1 - beta1 ** self.no_of_iterations)\n",
    "                s_dw_corrected = self.s_dw[layer] / (1 - beta2 ** self.no_of_iterations)\n",
    "\n",
    "                v_db_corrected = self.v_db[layer] / (1 - beta1 ** self.no_of_iterations)\n",
    "                s_db_corrected = self.s_db[layer] / (1 - beta2 ** self.no_of_iterations)\n",
    "\n",
    "                self.W[layer] -= alpha * (v_dw_corrected / (np.sqrt(s_dw_corrected) + self.EPSILON))\n",
    "                self.B[layer] -= alpha * (v_db_corrected / (np.sqrt(s_db_corrected) + self.EPSILON))\n",
    "        \n",
    "        return alpha\n",
    "\n",
    "\n",
    "    def initialise_cache(self):\n",
    "        self.v_dw = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.v_db = np.empty_like(range(self.layers), dtype=object)\n",
    "    \n",
    "        self.s_dw = np.empty_like(range(self.layers), dtype=object)\n",
    "        self.s_db = np.empty_like(range(self.layers), dtype=object)\n",
    "\n",
    "        for layer, (y, x) in zip(range(1, self.layers), self.weight_set_dimensions):\n",
    "            self.v_dw[layer] = np.zeros((y, x))\n",
    "            self.v_db[layer] = np.zeros((y, 1))\n",
    "            \n",
    "            self.s_dw[layer] = np.zeros((y, x))\n",
    "            self.s_db[layer] = np.zeros((y, 1))\n",
    "\n",
    "    @timeit\n",
    "    def fit(self, X, Y, X_test, Y_test):\n",
    "        self.m = X.shape[1] # where (no_of_features, no_of_training_examples)\n",
    "        self.initialise_weights()\n",
    "        self.initialise_cache()\n",
    "\n",
    "        # By default the method is SGD(Stochastic Gradient Descent) if one wishes to use\n",
    "        # the whole batch, simply pass the number of traning examples available as the\n",
    "        # batch size when instantiating the class\n",
    "        self.epoch_count = 0\n",
    "        self.no_of_iterations = 0\n",
    "\n",
    "        shuffled = np.arange(self.m)\n",
    "        if self.verbose:\n",
    "            print(\"Initialising weights...\")\n",
    "            print(\"Starting the training...\")\n",
    "            print(\"Initial cost: %.10f\\n\" % self.calculate_error(Y, self.get_A(X)[-1]))\n",
    "\n",
    "        for epoch_no in range(1, self.epoch + 1):\n",
    "            self.epoch_count += 1\n",
    "\n",
    "            np.random.shuffle(shuffled)\n",
    "            X_shuffled = X[:, shuffled]\n",
    "            Y_shuffled = Y[:, shuffled]\n",
    "\n",
    "            for i in range(0, self.m, self.mini_batch_size):\n",
    "                self.no_of_iterations += 1\n",
    "                X_mini_batch = X_shuffled[:, i: i + self.mini_batch_size]\n",
    "                Y_mini_batch = Y_shuffled[:, i: i + self.mini_batch_size]\n",
    "\n",
    "                A, Z = self.forwardpass(X_mini_batch)\n",
    "                alpha = self.backpropagation(Y_mini_batch, A, Z)\n",
    "\n",
    "                if self.no_of_iterations % 100 == 0 and self.verbose:\n",
    "                    self.display_information(X, Y, X_test, Y_test, alpha)\n",
    "\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            X: np.ndarray,\n",
    "            apply_dropout=False,\n",
    "            return_prob_matrix=False,\n",
    "    ):\n",
    "        \"\"\"Predict the output given the training data.\n",
    "\n",
    "            Returns the predicted values in two forms:\n",
    "\n",
    "            1.either by picking up the highest value along the columns for every row,\n",
    "                i.e. \"np.argmax(self.A[-1].T, axis=1)\"\n",
    "            2.or by returning a matrix that is in the shape of Y.T where each column\n",
    "                represents the probability of the instance belonging to that class.\n",
    "                Please note that every column in Y.T represents a class. To be able to\n",
    "                return the probability matrix, the final activation function must be\n",
    "                softmax!\n",
    "                i.e. \"array([0.9650488423, 0.0354737543, 0.0005225966])\"\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Training set in the shape of\n",
    "                (no_of_features, no_of_training examples).\n",
    "            return_prob_matrix (bool, optional): Returns the probability matrix if True.\n",
    "                Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray:\n",
    "\n",
    "            if return_prob_matrix is False, the output is in the shape of\n",
    "                (no_of_training_examples, 1)\n",
    "            if return_prob_matrix is True, the output is in the shape of\n",
    "                (no_of_training_examples, no_of_features)\n",
    "        \"\"\"\n",
    "        # here predict means if forwardpass is called from predict method\n",
    "        # if so, there is an option to apply or not apply dropout\n",
    "        predict = np.invert(apply_dropout)\n",
    "        A, Z = self.forwardpass(X, predict=predict)\n",
    "        if return_prob_matrix:\n",
    "            np.set_printoptions(precision=10, suppress=True)\n",
    "            return A[-1].T\n",
    "        return np.argmax(A[-1].T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "x = data.data[:,[0,2]]\n",
    "y = data.target\n",
    "\n",
    "X = x.T\n",
    "Y = one_hot_encode(y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.layers import Dropout\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model_keras = Sequential()\n",
    "model_keras.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model_keras.add(Dropout(0.5))\n",
    "model_keras.add(Dense(4, activation='relu'))\n",
    "model_keras.add(Dense(3, activation='softmax'))\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model_keras.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model_keras.fit(X.T,Y.T, batch_size=10, epochs=100)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with benchmark datasets\n",
    "\n",
    "## 1.Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the dataset as train and test...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "x = data.data[:,[0,2]]\n",
    "y = data.target\n",
    "\n",
    "dataset_train, dataset_test = split_data_as(x, y, train=0.8, test=0.2)\n",
    "\n",
    "X_train = dataset_train[:, :-1].T\n",
    "Y_train = one_hot_encode(dataset_train[:, -1]).T\n",
    "\n",
    "X_test = dataset_test[:, :-1].T\n",
    "Y_test = one_hot_encode(dataset_test[:, -1]).T\n",
    "\n",
    "\n",
    "# X = x.T\n",
    "# Y = one_hot_encode(y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 120)\n",
      "(3, 120)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising weights...\n",
      "Starting the training...\n",
      "Initial cost: 1.0958428580\n",
      "\n",
      "train_accuracy: 34.16667 - epoch 9    iteration 100 - train loss 0.9067453752 ____ test loss 0.2114667334 --- alpha: 0.2\n",
      "train_accuracy: 92.5 - epoch 17    iteration 200 - train loss 0.2689539923 ____ test loss 0.0822877486 --- alpha: 0.11111\n",
      "train_accuracy: 90.0 - epoch 25    iteration 300 - train loss 0.2387033147 ____ test loss 0.0820635277 --- alpha: 0.07692\n",
      "train_accuracy: 92.5 - epoch 34    iteration 400 - train loss 0.2096484695 ____ test loss 0.0678244236 --- alpha: 0.05714\n",
      "train_accuracy: 90.83333 - epoch 42    iteration 500 - train loss 0.2218875152 ____ test loss 0.0839443897 --- alpha: 0.04651\n",
      "train_accuracy: 95.0 - epoch 50    iteration 600 - train loss 0.1895714682 ____ test loss 0.0681775115 --- alpha: 0.03922\n",
      "train_accuracy: 94.16667 - epoch 59    iteration 700 - train loss 0.1804151142 ____ test loss 0.0639657489 --- alpha: 0.03333\n",
      "train_accuracy: 90.0 - epoch 67    iteration 800 - train loss 0.1902546076 ____ test loss 0.0581249294 --- alpha: 0.02941\n",
      "train_accuracy: 95.0 - epoch 75    iteration 900 - train loss 0.1710150982 ____ test loss 0.0649078297 --- alpha: 0.02632\n",
      "train_accuracy: 95.0 - epoch 84    iteration 1000 - train loss 0.162503017 ____ test loss 0.0633481965 --- alpha: 0.02353\n",
      "train_accuracy: 95.0 - epoch 92    iteration 1100 - train loss 0.1587636816 ____ test loss 0.059375091 --- alpha: 0.02151\n",
      "train_accuracy: 95.0 - epoch 100    iteration 1200 - train loss 0.1522316967 ____ test loss 0.0810102475 --- alpha: 0.0198\n",
      "train_accuracy: 94.16667 - epoch 109    iteration 1300 - train loss 0.1492498579 ____ test loss 0.0570588175 --- alpha: 0.01818\n",
      "train_accuracy: 95.0 - epoch 117    iteration 1400 - train loss 0.145745376 ____ test loss 0.0674704177 --- alpha: 0.01695\n",
      "train_accuracy: 95.0 - epoch 125    iteration 1500 - train loss 0.1431671417 ____ test loss 0.0551189153 --- alpha: 0.01587\n",
      "train_accuracy: 95.0 - epoch 134    iteration 1600 - train loss 0.1438765226 ____ test loss 0.0542886844 --- alpha: 0.01481\n",
      "train_accuracy: 95.0 - epoch 142    iteration 1700 - train loss 0.1390657964 ____ test loss 0.0529765131 --- alpha: 0.01399\n",
      "train_accuracy: 95.0 - epoch 150    iteration 1800 - train loss 0.135163303 ____ test loss 0.0660281603 --- alpha: 0.01325\n",
      "train_accuracy: 94.16667 - epoch 159    iteration 1900 - train loss 0.1400847836 ____ test loss 0.0496000814 --- alpha: 0.0125\n",
      "train_accuracy: 95.0 - epoch 167    iteration 2000 - train loss 0.1333696597 ____ test loss 0.0556951681 --- alpha: 0.0119\n",
      "train_accuracy: 95.83333 - epoch 175    iteration 2100 - train loss 0.1305219465 ____ test loss 0.0555651849 --- alpha: 0.01136\n",
      "train_accuracy: 95.83333 - epoch 184    iteration 2200 - train loss 0.1277667808 ____ test loss 0.0734456072 --- alpha: 0.01081\n",
      "train_accuracy: 95.0 - epoch 192    iteration 2300 - train loss 0.1259083199 ____ test loss 0.0709815692 --- alpha: 0.01036\n",
      "train_accuracy: 95.0 - epoch 200    iteration 2400 - train loss 0.1261104536 ____ test loss 0.0498998714 --- alpha: 0.00995\n",
      "train_accuracy: 95.83333 - epoch 209    iteration 2500 - train loss 0.1231689813 ____ test loss 0.0528686772 --- alpha: 0.00952\n",
      "train_accuracy: 95.83333 - epoch 217    iteration 2600 - train loss 0.1220220582 ____ test loss 0.0683037488 --- alpha: 0.00917\n",
      "train_accuracy: 95.0 - epoch 225    iteration 2700 - train loss 0.1193972635 ____ test loss 0.0693716874 --- alpha: 0.00885\n",
      "train_accuracy: 95.0 - epoch 234    iteration 2800 - train loss 0.1268054484 ____ test loss 0.0467838547 --- alpha: 0.00851\n",
      "train_accuracy: 95.83333 - epoch 242    iteration 2900 - train loss 0.1183809634 ____ test loss 0.0532907866 --- alpha: 0.00823\n",
      "train_accuracy: 95.83333 - epoch 250    iteration 3000 - train loss 0.1159138439 ____ test loss 0.0516365684 --- alpha: 0.00797\n",
      "train_accuracy: 95.83333 - epoch 259    iteration 3100 - train loss 0.1143203889 ____ test loss 0.0686079488 --- alpha: 0.00769\n",
      "train_accuracy: 95.83333 - epoch 267    iteration 3200 - train loss 0.1133158265 ____ test loss 0.0670552019 --- alpha: 0.00746\n",
      "train_accuracy: 95.83333 - epoch 275    iteration 3300 - train loss 0.1127606024 ____ test loss 0.0670627971 --- alpha: 0.00725\n",
      "train_accuracy: 95.0 - epoch 284    iteration 3400 - train loss 0.1118432424 ____ test loss 0.0659442356 --- alpha: 0.00702\n",
      "train_accuracy: 95.83333 - epoch 292    iteration 3500 - train loss 0.1097890753 ____ test loss 0.0647347703 --- alpha: 0.00683\n",
      "train_accuracy: 95.83333 - epoch 300    iteration 3600 - train loss 0.1086545235 ____ test loss 0.0647337209 --- alpha: 0.00664\n",
      "train_accuracy: 95.83333 - epoch 309    iteration 3700 - train loss 0.1082666938 ____ test loss 0.0483261871 --- alpha: 0.00645\n",
      "train_accuracy: 95.83333 - epoch 317    iteration 3800 - train loss 0.1073835273 ____ test loss 0.0649377079 --- alpha: 0.00629\n",
      "train_accuracy: 95.83333 - epoch 325    iteration 3900 - train loss 0.1062526593 ____ test loss 0.048318588 --- alpha: 0.00613\n",
      "train_accuracy: 95.83333 - epoch 334    iteration 4000 - train loss 0.1047867374 ____ test loss 0.0625590396 --- alpha: 0.00597\n",
      "train_accuracy: 95.83333 - epoch 342    iteration 4100 - train loss 0.1045541915 ____ test loss 0.0641255666 --- alpha: 0.00583\n",
      "train_accuracy: 95.83333 - epoch 350    iteration 4200 - train loss 0.1032123539 ____ test loss 0.0489036043 --- alpha: 0.0057\n",
      "train_accuracy: 95.83333 - epoch 359    iteration 4300 - train loss 0.1020556862 ____ test loss 0.0615340841 --- alpha: 0.00556\n",
      "train_accuracy: 95.83333 - epoch 367    iteration 4400 - train loss 0.1035327611 ____ test loss 0.0523375869 --- alpha: 0.00543\n",
      "train_accuracy: 95.83333 - epoch 375    iteration 4500 - train loss 0.1008232657 ____ test loss 0.0591715824 --- alpha: 0.00532\n",
      "train_accuracy: 95.83333 - epoch 384    iteration 4600 - train loss 0.1004472296 ____ test loss 0.059859936 --- alpha: 0.00519\n",
      "train_accuracy: 95.83333 - epoch 392    iteration 4700 - train loss 0.0988557223 ____ test loss 0.0598574099 --- alpha: 0.00509\n",
      "train_accuracy: 95.83333 - epoch 400    iteration 4800 - train loss 0.098110054 ____ test loss 0.0594992958 --- alpha: 0.00499\n",
      "train_accuracy: 95.83333 - epoch 409    iteration 4900 - train loss 0.0973472027 ____ test loss 0.0586192646 --- alpha: 0.00488\n",
      "train_accuracy: 95.83333 - epoch 417    iteration 5000 - train loss 0.0969102119 ____ test loss 0.0472630628 --- alpha: 0.00478\n",
      "train_accuracy: 95.83333 - epoch 425    iteration 5100 - train loss 0.0958213188 ____ test loss 0.0579541431 --- alpha: 0.00469\n",
      "train_accuracy: 95.83333 - epoch 434    iteration 5200 - train loss 0.0955165624 ____ test loss 0.0479350197 --- alpha: 0.0046\n",
      "train_accuracy: 95.83333 - epoch 442    iteration 5300 - train loss 0.0948208097 ____ test loss 0.0561646212 --- alpha: 0.00451\n",
      "train_accuracy: 95.83333 - epoch 450    iteration 5400 - train loss 0.0942665893 ____ test loss 0.0560509725 --- alpha: 0.00443\n",
      "train_accuracy: 95.83333 - epoch 459    iteration 5500 - train loss 0.0931483762 ____ test loss 0.0551114163 --- alpha: 0.00435\n",
      "train_accuracy: 95.83333 - epoch 467    iteration 5600 - train loss 0.0923928289 ____ test loss 0.0564905501 --- alpha: 0.00427\n",
      "train_accuracy: 95.83333 - epoch 475    iteration 5700 - train loss 0.0923080107 ____ test loss 0.055960871 --- alpha: 0.0042\n",
      "train_accuracy: 95.83333 - epoch 484    iteration 5800 - train loss 0.0911548898 ____ test loss 0.0540396592 --- alpha: 0.00412\n",
      "train_accuracy: 95.83333 - epoch 492    iteration 5900 - train loss 0.090636157 ____ test loss 0.0523996604 --- alpha: 0.00406\n",
      "train_accuracy: 95.83333 - epoch 500    iteration 6000 - train loss 0.0900063247 ____ test loss 0.0530994046 --- alpha: 0.00399\n",
      "train_accuracy: 95.83333 - epoch 509    iteration 6100 - train loss 0.0894239537 ____ test loss 0.0523841954 --- alpha: 0.00392\n",
      "train_accuracy: 95.83333 - epoch 517    iteration 6200 - train loss 0.0889249433 ____ test loss 0.0507137584 --- alpha: 0.00386\n",
      "train_accuracy: 95.83333 - epoch 525    iteration 6300 - train loss 0.088462537 ____ test loss 0.0505667875 --- alpha: 0.0038\n",
      "train_accuracy: 95.83333 - epoch 534    iteration 6400 - train loss 0.087608124 ____ test loss 0.0522408551 --- alpha: 0.00374\n",
      "train_accuracy: 95.0 - epoch 542    iteration 6500 - train loss 0.087806124 ____ test loss 0.048941705 --- alpha: 0.00368\n",
      "train_accuracy: 95.83333 - epoch 550    iteration 6600 - train loss 0.0866301853 ____ test loss 0.0509958163 --- alpha: 0.00363\n",
      "train_accuracy: 95.83333 - epoch 559    iteration 6700 - train loss 0.0861072581 ____ test loss 0.0496433782 --- alpha: 0.00357\n",
      "train_accuracy: 95.83333 - epoch 567    iteration 6800 - train loss 0.0861831842 ____ test loss 0.0514736974 --- alpha: 0.00352\n",
      "train_accuracy: 95.83333 - epoch 575    iteration 6900 - train loss 0.0854977944 ____ test loss 0.0458181915 --- alpha: 0.00347\n",
      "train_accuracy: 95.83333 - epoch 584    iteration 7000 - train loss 0.0848864929 ____ test loss 0.0458595189 --- alpha: 0.00342\n",
      "train_accuracy: 95.83333 - epoch 592    iteration 7100 - train loss 0.0842901519 ____ test loss 0.046225217 --- alpha: 0.00337\n",
      "train_accuracy: 95.83333 - epoch 600    iteration 7200 - train loss 0.0839047542 ____ test loss 0.0465628166 --- alpha: 0.00333\n",
      "train_accuracy: 95.83333 - epoch 609    iteration 7300 - train loss 0.0832077713 ____ test loss 0.0475196879 --- alpha: 0.00328\n",
      "train_accuracy: 95.83333 - epoch 617    iteration 7400 - train loss 0.0827744979 ____ test loss 0.047734368 --- alpha: 0.00324\n",
      "train_accuracy: 95.83333 - epoch 625    iteration 7500 - train loss 0.0822956422 ____ test loss 0.0468825081 --- alpha: 0.00319\n",
      "train_accuracy: 95.0 - epoch 634    iteration 7600 - train loss 0.0822652129 ____ test loss 0.0439506348 --- alpha: 0.00315\n",
      "train_accuracy: 95.83333 - epoch 642    iteration 7700 - train loss 0.0819654115 ____ test loss 0.0455667348 --- alpha: 0.00311\n",
      "train_accuracy: 95.0 - epoch 650    iteration 7800 - train loss 0.0811642628 ____ test loss 0.0447987186 --- alpha: 0.00307\n",
      "train_accuracy: 95.83333 - epoch 659    iteration 7900 - train loss 0.0805828846 ____ test loss 0.0456044203 --- alpha: 0.00303\n",
      "train_accuracy: 95.83333 - epoch 667    iteration 8000 - train loss 0.0803027766 ____ test loss 0.0439279496 --- alpha: 0.00299\n",
      "train_accuracy: 95.0 - epoch 675    iteration 8100 - train loss 0.0800279933 ____ test loss 0.0441745589 --- alpha: 0.00296\n",
      "train_accuracy: 95.83333 - epoch 684    iteration 8200 - train loss 0.079471072 ____ test loss 0.0429382569 --- alpha: 0.00292\n",
      "train_accuracy: 95.83333 - epoch 692    iteration 8300 - train loss 0.0790962147 ____ test loss 0.0428329014 --- alpha: 0.00289\n",
      "train_accuracy: 95.83333 - epoch 700    iteration 8400 - train loss 0.0787355485 ____ test loss 0.0435220482 --- alpha: 0.00285\n",
      "train_accuracy: 95.83333 - epoch 709    iteration 8500 - train loss 0.0783660715 ____ test loss 0.0440307542 --- alpha: 0.00282\n",
      "train_accuracy: 95.83333 - epoch 717    iteration 8600 - train loss 0.077894998 ____ test loss 0.0427438993 --- alpha: 0.00279\n",
      "train_accuracy: 95.83333 - epoch 725    iteration 8700 - train loss 0.0775057519 ____ test loss 0.0432689767 --- alpha: 0.00275\n",
      "train_accuracy: 95.83333 - epoch 734    iteration 8800 - train loss 0.0772533301 ____ test loss 0.0419625265 --- alpha: 0.00272\n",
      "train_accuracy: 95.83333 - epoch 742    iteration 8900 - train loss 0.0770853527 ____ test loss 0.0427199654 --- alpha: 0.00269\n",
      "train_accuracy: 95.0 - epoch 750    iteration 9000 - train loss 0.0767466161 ____ test loss 0.0400772365 --- alpha: 0.00266\n",
      "train_accuracy: 95.83333 - epoch 759    iteration 9100 - train loss 0.0762863103 ____ test loss 0.0410405303 --- alpha: 0.00263\n",
      "train_accuracy: 95.0 - epoch 767    iteration 9200 - train loss 0.076032471 ____ test loss 0.0407003563 --- alpha: 0.0026\n",
      "train_accuracy: 95.83333 - epoch 775    iteration 9300 - train loss 0.0756025369 ____ test loss 0.0417887889 --- alpha: 0.00258\n",
      "train_accuracy: 95.0 - epoch 784    iteration 9400 - train loss 0.0752654914 ____ test loss 0.0400296189 --- alpha: 0.00255\n",
      "train_accuracy: 95.83333 - epoch 792    iteration 9500 - train loss 0.0749556879 ____ test loss 0.040768835 --- alpha: 0.00252\n",
      "train_accuracy: 95.83333 - epoch 800    iteration 9600 - train loss 0.0745826761 ____ test loss 0.0409673362 --- alpha: 0.0025\n",
      "train_accuracy: 95.0 - epoch 809    iteration 9700 - train loss 0.0742535791 ____ test loss 0.0400867955 --- alpha: 0.00247\n",
      "train_accuracy: 95.83333 - epoch 817    iteration 9800 - train loss 0.0739237554 ____ test loss 0.0405198457 --- alpha: 0.00244\n",
      "train_accuracy: 95.83333 - epoch 825    iteration 9900 - train loss 0.0736694053 ____ test loss 0.0399561533 --- alpha: 0.00242\n",
      "train_accuracy: 95.0 - epoch 834    iteration 10000 - train loss 0.0733302595 ____ test loss 0.0400076261 --- alpha: 0.0024\n",
      "train_accuracy: 95.0 - epoch 842    iteration 10100 - train loss 0.0731748059 ____ test loss 0.0391565679 --- alpha: 0.00237\n",
      "train_accuracy: 95.0 - epoch 850    iteration 10200 - train loss 0.0727893822 ____ test loss 0.0394596953 --- alpha: 0.00235\n",
      "train_accuracy: 95.0 - epoch 859    iteration 10300 - train loss 0.0724710095 ____ test loss 0.0397519652 --- alpha: 0.00233\n",
      "train_accuracy: 95.0 - epoch 867    iteration 10400 - train loss 0.0722326544 ____ test loss 0.0392341741 --- alpha: 0.0023\n",
      "train_accuracy: 95.0 - epoch 875    iteration 10500 - train loss 0.0719285096 ____ test loss 0.0395754467 --- alpha: 0.00228\n",
      "train_accuracy: 95.0 - epoch 884    iteration 10600 - train loss 0.0717503552 ____ test loss 0.0383372498 --- alpha: 0.00226\n",
      "train_accuracy: 95.0 - epoch 892    iteration 10700 - train loss 0.0715650378 ____ test loss 0.0383349175 --- alpha: 0.00224\n",
      "train_accuracy: 95.83333 - epoch 900    iteration 10800 - train loss 0.0712661136 ____ test loss 0.0388539261 --- alpha: 0.00222\n",
      "train_accuracy: 95.0 - epoch 909    iteration 10900 - train loss 0.0709572565 ____ test loss 0.0387052168 --- alpha: 0.0022\n",
      "train_accuracy: 95.0 - epoch 917    iteration 11000 - train loss 0.0707586471 ____ test loss 0.0387804355 --- alpha: 0.00218\n",
      "train_accuracy: 95.0 - epoch 925    iteration 11100 - train loss 0.0704836986 ____ test loss 0.0383073622 --- alpha: 0.00216\n",
      "train_accuracy: 95.0 - epoch 934    iteration 11200 - train loss 0.0705980784 ____ test loss 0.0381469205 --- alpha: 0.00214\n",
      "train_accuracy: 95.0 - epoch 942    iteration 11300 - train loss 0.070011974 ____ test loss 0.0384162859 --- alpha: 0.00212\n",
      "train_accuracy: 95.0 - epoch 950    iteration 11400 - train loss 0.0697638355 ____ test loss 0.0387206064 --- alpha: 0.0021\n",
      "train_accuracy: 95.0 - epoch 959    iteration 11500 - train loss 0.0695188206 ____ test loss 0.038716891 --- alpha: 0.00208\n",
      "train_accuracy: 95.0 - epoch 967    iteration 11600 - train loss 0.0693897069 ____ test loss 0.0378862792 --- alpha: 0.00207\n",
      "train_accuracy: 95.0 - epoch 975    iteration 11700 - train loss 0.0692071269 ____ test loss 0.037888336 --- alpha: 0.00205\n",
      "train_accuracy: 95.0 - epoch 984    iteration 11800 - train loss 0.0689478057 ____ test loss 0.0380362252 --- alpha: 0.00203\n",
      "train_accuracy: 95.0 - epoch 992    iteration 11900 - train loss 0.0687290419 ____ test loss 0.0381472865 --- alpha: 0.00201\n",
      "train_accuracy: 95.0 - epoch 1000    iteration 12000 - train loss 0.0685224265 ____ test loss 0.0382726642 --- alpha: 0.002\n",
      "train_accuracy: 95.0 - epoch 1009    iteration 12100 - train loss 0.068309673 ____ test loss 0.0383535704 --- alpha: 0.00198\n",
      "train_accuracy: 95.0 - epoch 1017    iteration 12200 - train loss 0.0681406959 ____ test loss 0.0383274551 --- alpha: 0.00196\n",
      "train_accuracy: 95.0 - epoch 1025    iteration 12300 - train loss 0.0679267076 ____ test loss 0.0383743904 --- alpha: 0.00195\n",
      "train_accuracy: 95.0 - epoch 1034    iteration 12400 - train loss 0.0677434141 ____ test loss 0.0382270469 --- alpha: 0.00193\n",
      "train_accuracy: 95.0 - epoch 1042    iteration 12500 - train loss 0.0676372409 ____ test loss 0.0384698644 --- alpha: 0.00192\n",
      "train_accuracy: 95.0 - epoch 1050    iteration 12600 - train loss 0.0673918641 ____ test loss 0.0384326399 --- alpha: 0.0019\n",
      "train_accuracy: 95.0 - epoch 1059    iteration 12700 - train loss 0.0671893116 ____ test loss 0.0383102284 --- alpha: 0.00189\n",
      "train_accuracy: 95.0 - epoch 1067    iteration 12800 - train loss 0.0670289368 ____ test loss 0.0382131924 --- alpha: 0.00187\n",
      "train_accuracy: 95.0 - epoch 1075    iteration 12900 - train loss 0.0668435755 ____ test loss 0.0383236043 --- alpha: 0.00186\n",
      "train_accuracy: 95.0 - epoch 1084    iteration 13000 - train loss 0.0667047209 ____ test loss 0.0381394293 --- alpha: 0.00184\n",
      "train_accuracy: 95.0 - epoch 1092    iteration 13100 - train loss 0.0665295207 ____ test loss 0.0382119401 --- alpha: 0.00183\n",
      "train_accuracy: 95.0 - epoch 1100    iteration 13200 - train loss 0.0663476793 ____ test loss 0.038341957 --- alpha: 0.00182\n",
      "train_accuracy: 95.83333 - epoch 1109    iteration 13300 - train loss 0.066262578 ____ test loss 0.0385166186 --- alpha: 0.0018\n",
      "train_accuracy: 95.0 - epoch 1117    iteration 13400 - train loss 0.0660115968 ____ test loss 0.0383586985 --- alpha: 0.00179\n",
      "train_accuracy: 95.0 - epoch 1125    iteration 13500 - train loss 0.0658618141 ____ test loss 0.0383515832 --- alpha: 0.00178\n",
      "train_accuracy: 95.0 - epoch 1134    iteration 13600 - train loss 0.065777975 ____ test loss 0.0383427619 --- alpha: 0.00176\n",
      "train_accuracy: 95.0 - epoch 1142    iteration 13700 - train loss 0.0656028308 ____ test loss 0.0385437961 --- alpha: 0.00175\n",
      "train_accuracy: 95.0 - epoch 1150    iteration 13800 - train loss 0.0654114814 ____ test loss 0.0384796773 --- alpha: 0.00174\n",
      "train_accuracy: 95.0 - epoch 1159    iteration 13900 - train loss 0.0652276839 ____ test loss 0.0385039772 --- alpha: 0.00172\n",
      "train_accuracy: 95.0 - epoch 1167    iteration 14000 - train loss 0.0650983799 ____ test loss 0.0384210674 --- alpha: 0.00171\n",
      "train_accuracy: 95.0 - epoch 1175    iteration 14100 - train loss 0.0651016033 ____ test loss 0.0384461322 --- alpha: 0.0017\n",
      "train_accuracy: 95.0 - epoch 1184    iteration 14200 - train loss 0.0648124904 ____ test loss 0.0384719564 --- alpha: 0.00169\n",
      "train_accuracy: 95.0 - epoch 1192    iteration 14300 - train loss 0.0646637511 ____ test loss 0.0385315077 --- alpha: 0.00168\n",
      "train_accuracy: 95.83333 - epoch 1200    iteration 14400 - train loss 0.064561249 ____ test loss 0.0386687695 --- alpha: 0.00167\n",
      "train_accuracy: 95.0 - epoch 1209    iteration 14500 - train loss 0.0644580402 ____ test loss 0.0386219567 --- alpha: 0.00165\n",
      "train_accuracy: 95.0 - epoch 1217    iteration 14600 - train loss 0.0642671537 ____ test loss 0.0386499771 --- alpha: 0.00164\n",
      "train_accuracy: 95.83333 - epoch 1225    iteration 14700 - train loss 0.0641265058 ____ test loss 0.0387276119 --- alpha: 0.00163\n",
      "train_accuracy: 95.0 - epoch 1234    iteration 14800 - train loss 0.063999889 ____ test loss 0.0386989338 --- alpha: 0.00162\n",
      "train_accuracy: 95.0 - epoch 1242    iteration 14900 - train loss 0.0639249677 ____ test loss 0.0387455819 --- alpha: 0.00161\n",
      "train_accuracy: 95.0 - epoch 1250    iteration 15000 - train loss 0.0637280597 ____ test loss 0.0387959563 --- alpha: 0.0016\n",
      "train_accuracy: 95.83333 - epoch 1259    iteration 15100 - train loss 0.0636357395 ____ test loss 0.0389067613 --- alpha: 0.00159\n",
      "train_accuracy: 95.83333 - epoch 1267    iteration 15200 - train loss 0.0635439833 ____ test loss 0.0389453389 --- alpha: 0.00158\n",
      "train_accuracy: 95.83333 - epoch 1275    iteration 15300 - train loss 0.0633560643 ____ test loss 0.0389497004 --- alpha: 0.00157\n",
      "train_accuracy: 95.0 - epoch 1284    iteration 15400 - train loss 0.0632856494 ____ test loss 0.0389356432 --- alpha: 0.00156\n",
      "train_accuracy: 95.83333 - epoch 1292    iteration 15500 - train loss 0.0631232974 ____ test loss 0.0389874622 --- alpha: 0.00155\n",
      "train_accuracy: 95.83333 - epoch 1300    iteration 15600 - train loss 0.0630127184 ____ test loss 0.0390660175 --- alpha: 0.00154\n",
      "train_accuracy: 95.83333 - epoch 1309    iteration 15700 - train loss 0.0628924671 ____ test loss 0.039089397 --- alpha: 0.00153\n",
      "train_accuracy: 96.66667 - epoch 1317    iteration 15800 - train loss 0.0629250065 ____ test loss 0.0390934133 --- alpha: 0.00152\n",
      "train_accuracy: 95.83333 - epoch 1325    iteration 15900 - train loss 0.0626791977 ____ test loss 0.0391341277 --- alpha: 0.00151\n",
      "train_accuracy: 95.83333 - epoch 1334    iteration 16000 - train loss 0.0626000031 ____ test loss 0.0391841527 --- alpha: 0.0015\n",
      "train_accuracy: 95.83333 - epoch 1342    iteration 16100 - train loss 0.0624751665 ____ test loss 0.0392852649 --- alpha: 0.00149\n",
      "train_accuracy: 96.66667 - epoch 1350    iteration 16200 - train loss 0.0624282343 ____ test loss 0.0392878003 --- alpha: 0.00148\n",
      "train_accuracy: 95.83333 - epoch 1359    iteration 16300 - train loss 0.062294042 ____ test loss 0.0394089351 --- alpha: 0.00147\n",
      "train_accuracy: 95.83333 - epoch 1367    iteration 16400 - train loss 0.0621452073 ____ test loss 0.0394346342 --- alpha: 0.00146\n",
      "train_accuracy: 96.66667 - epoch 1375    iteration 16500 - train loss 0.062007554 ____ test loss 0.0394369519 --- alpha: 0.00145\n",
      "train_accuracy: 96.66667 - epoch 1384    iteration 16600 - train loss 0.0618919112 ____ test loss 0.0394920367 --- alpha: 0.00144\n",
      "train_accuracy: 95.83333 - epoch 1392    iteration 16700 - train loss 0.0618787374 ____ test loss 0.0396076735 --- alpha: 0.00144\n",
      "train_accuracy: 95.83333 - epoch 1400    iteration 16800 - train loss 0.0617349112 ____ test loss 0.0396333634 --- alpha: 0.00143\n",
      "train_accuracy: 95.83333 - epoch 1409    iteration 16900 - train loss 0.06166727 ____ test loss 0.0396961304 --- alpha: 0.00142\n",
      "train_accuracy: 95.83333 - epoch 1417    iteration 17000 - train loss 0.0615551516 ____ test loss 0.0396769951 --- alpha: 0.00141\n",
      "train_accuracy: 96.66667 - epoch 1425    iteration 17100 - train loss 0.0613912961 ____ test loss 0.0397395376 --- alpha: 0.0014\n",
      "train_accuracy: 96.66667 - epoch 1434    iteration 17200 - train loss 0.0612986518 ____ test loss 0.0397865224 --- alpha: 0.00139\n",
      "train_accuracy: 96.66667 - epoch 1442    iteration 17300 - train loss 0.0612487265 ____ test loss 0.0398152568 --- alpha: 0.00139\n",
      "train_accuracy: 96.66667 - epoch 1450    iteration 17400 - train loss 0.0611255397 ____ test loss 0.0398878293 --- alpha: 0.00138\n",
      "train_accuracy: 96.66667 - epoch 1459    iteration 17500 - train loss 0.061016894 ____ test loss 0.0399126589 --- alpha: 0.00137\n",
      "train_accuracy: 96.66667 - epoch 1467    iteration 17600 - train loss 0.0609399241 ____ test loss 0.0399562552 --- alpha: 0.00136\n",
      "train_accuracy: 96.66667 - epoch 1475    iteration 17700 - train loss 0.0608354565 ____ test loss 0.0400099111 --- alpha: 0.00136\n",
      "train_accuracy: 96.66667 - epoch 1484    iteration 17800 - train loss 0.0607512129 ____ test loss 0.0400610917 --- alpha: 0.00135\n",
      "train_accuracy: 96.66667 - epoch 1492    iteration 17900 - train loss 0.0606631233 ____ test loss 0.0401068647 --- alpha: 0.00134\n",
      "train_accuracy: 96.66667 - epoch 1500    iteration 18000 - train loss 0.0605758331 ____ test loss 0.0401519623 --- alpha: 0.00133\n",
      "func:'fit' -- took: 8.7930 sec\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    input_layer=(2, 'relu'),\n",
    "    hidden_layer=[(4,'relu'),(4,'softmax')],\n",
    "    output_layer=3,\n",
    "    batch_size=10,\n",
    "    optimizer={\"method\": \"ADAM\", \"beta1\": 0.9, \"beta2\": 0.999},\n",
    "    weight_initialisation = \"xavier_normal\",\n",
    "    keep_prob=1,\n",
    "    penalty=None,\n",
    "    epoch=1500,\n",
    "    alpha={\"initial_lr\": 2, \"decay\": 1}\n",
    ")\n",
    "\n",
    "model.fit(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F1': 94.11764704725262,\n",
       " 'accuracy': 96.66666666344445,\n",
       " 'false_positive_rate': 0.0,\n",
       " 'precision': 99.9999999875,\n",
       " 'prevalence': 29.999999999,\n",
       " 'sensitivity/recall': 88.88888887901234,\n",
       " 'specificity': 99.9999999952381}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_model_performance(np.argmax(Y_test, axis=0),\n",
    "                           model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results_dict_all_models, results_average_dict, models = grid_search(\n",
    "#     x,\n",
    "#     y,\n",
    "#     clf=NeuralNetwork,\n",
    "#     lst_metrics=[\"F1\", \"accuracy\"],\n",
    "#     sort_by = \"accuracy\",\n",
    "#     n_folds=5,\n",
    "#     dict_param_grid={\n",
    "#         'batch_size': [8, 16, 32],\n",
    "#         'input_layer': [(2, 'relu')],\n",
    "#         'hidden_layer': [\n",
    "#             [(4,'relu'), (4,'softmax')],\n",
    "#             [(4,'sigmoid'),(4,'softmax')]\n",
    "#         ],\n",
    "#         'optimizer': [\n",
    "#             {\n",
    "#                 \"method\": \"RMSP\",\n",
    "#                 \"beta\": 0.9\n",
    "#             }\n",
    "#         ],\n",
    "#         'output_layer': [3],\n",
    "#         'alpha': [0.001],\n",
    "#         'verbose': [False],\n",
    "#         'epoch': [1000]\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py:6461: MaskedArrayFutureWarning: In the future the default for ma.maximum.reduce will be axis=0, not the current None, to match np.maximum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n",
      "C:\\Anaconda3\\lib\\site-packages\\numpy\\ma\\core.py:6461: MaskedArrayFutureWarning: In the future the default for ma.minimum.reduce will be axis=0, not the current None, to match np.minimum.reduce. Explicitly pass 0 or None to silence this warning.\n",
      "  return self.reduce(a)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dt = data.data[:,[0,2]]\n",
    "x_min, x_max = dt[:, 0].min() - 1, dt[:, 0].max() + 1\n",
    "y_min, y_max = dt[:, 1].min() - 1, dt[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()].T, apply_dropout=False)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.contourf(xx, yy, Z,alpha=0.4)\n",
    "#plt.axis('off')\n",
    "\n",
    "plt.scatter(dt[:, 0], dt[:, 1], c=y,s=20, edgecolor='k')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(\n",
    "    model.train_error,\n",
    "    model.test_error\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Make Moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "x,y =make_moons(n_samples=1500, noise=.05)\n",
    "X = x.T\n",
    "Y = one_hot_encode(y).T\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    input_layer=(X.shape[0], 'relu'),\n",
    "    hidden_layer=[(10,'relu'), (4,'softmax')],\n",
    "    output_layer=Y.shape[0],\n",
    "    batch_size=8,\n",
    "    optimizer=\n",
    "    {\n",
    "        \"method\": \"ADAM\",\n",
    "        \"beta1\": 0.9,\n",
    "        \"beta2\": 0.999\n",
    "    },\n",
    "    penalty = \"l2\",\n",
    "    keep_prob=0.5,\n",
    "    lambd=0.001,\n",
    "    epoch=250,\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Decision Boundaries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dt = x\n",
    "x_min, x_max = dt[:, 0].min() - 0.5, dt[:, 0].max() + 0.5\n",
    "y_min, y_max = dt[:, 1].min() - 0.5, dt[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()].T, apply_dropout=False) \n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.contourf(xx, yy, Z,alpha=0.4)\n",
    "#plt.axis('off')\n",
    "plt.scatter(dt[:, 0], dt[:, 1], c=y, s=20, edgecolor='k')\n",
    "plt.title('Decision Boundaries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Andrew NG Assignment 2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex2data2 = np.loadtxt(\"../ex2/data/ex2data2.txt\", delimiter=\",\")\n",
    "\n",
    "x = ex2data2[:, :-1]\n",
    "y = ex2data2[:, -1]\n",
    "\n",
    "X = x.T\n",
    "Y = one_hot_encode(y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    input_layer=(X.shape[0], 'relu'),\n",
    "    hidden_layer=[(8,'relu'), (4,'softmax')],\n",
    "    output_layer=Y.shape[0],\n",
    "    batch_size=8,\n",
    "    optimizer={\"method\": \"ADAM\", \"beta1\": 0.9, \"beta2\": 0.999},\n",
    "    keep_prob=0.8,\n",
    "    epoch=1500,\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results_dict_all_models, results_average_dict, models = grid_search_stratified(\n",
    "#     x,\n",
    "#     y,\n",
    "#     clf=NeuralNetwork,\n",
    "#     metrics=[\"F1\", \"accuracy\"],\n",
    "#     sort_by = \"accuracy\",\n",
    "#     n_fold=6,\n",
    "#     param_grid_dict={\n",
    "#         'batch_size': [16, 32],\n",
    "#         'input_layer': [(2, 'relu')],\n",
    "#         'hidden_layer': [\n",
    "#             [(4,'relu'), (4,'relu'), (4,'softmax')],\n",
    "#             [(4,'sigmoid'),(4,'softmax')]\n",
    "#         ],\n",
    "#         'output_layer': [2],\n",
    "#         'alpha': [2, 4],\n",
    "#         'verbose': [False],\n",
    "#         'epoch': [5000]\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_average_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(models[\"model_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Decision Boundaries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "data = ex2data2\n",
    "\n",
    "x1_min, x1_max = data[:, 0].min() - 0.3, data[:, 0].max() + 0.3,\n",
    "x2_min, x2_max = data[:, 1].min() - 0.3, data[:, 1].max() + 0.3,\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "\n",
    "# here \"model\" is your model's prediction (classification) function\n",
    "Z = model.predict(np.c_[xx1.ravel(), xx2.ravel()].T, apply_dropout=False) \n",
    "\n",
    "negatives = ex2data2[ex2data2[:, -1] == 0]\n",
    "positives = ex2data2[ex2data2[:, -1] == 1]\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx1.shape)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.contourf(xx1, xx2, Z,alpha=0.4)\n",
    "#plt.axis('off')\n",
    "plt.scatter(negatives[:, 0], negatives[:, 1],s=50, color='k')\n",
    "plt.scatter(positives[:, 0], positives[:, 1],s=50, color='r')\n",
    "plt.title('Decision Boundaries')\n",
    "\n",
    "plt.contour(xx1, xx2, Z, [0.5], linewidths=2, colors=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', 'X', '__version__', 'y', '__globals__'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "data = loadmat('../ex3/data/ex3data1.mat')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data[\"X\"]\n",
    "y = data[\"y\"]\n",
    "y[y==10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the dataset as validation, train and test...\n"
     ]
    }
   ],
   "source": [
    "dataset_validation, dataset_train, dataset_test= split_data_as(x, y, train=0.85, test=0.1, validation=0.05)\n",
    "X_train = dataset_train[:, :-1].T\n",
    "Y_train = one_hot_encode(dataset_train[:, -1]).T\n",
    "\n",
    "X_test = dataset_test[:, :-1].T\n",
    "Y_test = one_hot_encode(dataset_test[:, -1]).T\n",
    "\n",
    "X_validation = dataset_validation[:, :-1].T\n",
    "Y_validation = one_hot_encode(dataset_validation[:, -1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "sample = np.random.choice(data[\"X\"].shape[0], 20)\n",
    "ax.imshow(data[\"X\"][sample,1:].reshape(-1,20).T)\n",
    "ax.axis('off');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising weights...\n",
      "Starting the training...\n",
      "Initial cost: 2.3211012987\n",
      "\n",
      "train_accuracy: 93.10588 - epoch 2    iteration 100 - train loss 0.2797590395 ____ test loss 0.0405247539 --- alpha: 0.00333\n",
      "train_accuracy: 95.76471 - epoch 3    iteration 200 - train loss 0.1963221512 ____ test loss 0.032908633 --- alpha: 0.0025\n",
      "train_accuracy: 96.54118 - epoch 4    iteration 300 - train loss 0.1474225174 ____ test loss 0.0275964539 --- alpha: 0.002\n",
      "train_accuracy: 98.0 - epoch 5    iteration 400 - train loss 0.123318226 ____ test loss 0.027028404 --- alpha: 0.00167\n",
      "train_accuracy: 98.25882 - epoch 6    iteration 500 - train loss 0.1115656755 ____ test loss 0.0265492888 --- alpha: 0.00143\n",
      "train_accuracy: 98.68235 - epoch 7    iteration 600 - train loss 0.103083376 ____ test loss 0.0257114228 --- alpha: 0.00125\n",
      "train_accuracy: 98.68235 - epoch 8    iteration 700 - train loss 0.0897645308 ____ test loss 0.023749597 --- alpha: 0.00111\n",
      "train_accuracy: 98.91765 - epoch 9    iteration 800 - train loss 0.0859619539 ____ test loss 0.0234742929 --- alpha: 0.001\n",
      "train_accuracy: 99.27059 - epoch 11    iteration 900 - train loss 0.0782314238 ____ test loss 0.0229843831 --- alpha: 0.00083\n",
      "train_accuracy: 99.31765 - epoch 12    iteration 1000 - train loss 0.0765208662 ____ test loss 0.023118979 --- alpha: 0.00077\n",
      "train_accuracy: 99.24706 - epoch 13    iteration 1100 - train loss 0.0709673517 ____ test loss 0.0229439032 --- alpha: 0.00071\n",
      "train_accuracy: 99.31765 - epoch 14    iteration 1200 - train loss 0.0652565261 ____ test loss 0.0219703274 --- alpha: 0.00067\n",
      "train_accuracy: 99.29412 - epoch 15    iteration 1300 - train loss 0.0672555414 ____ test loss 0.0228621189 --- alpha: 0.00062\n",
      "train_accuracy: 99.6 - epoch 16    iteration 1400 - train loss 0.059988366 ____ test loss 0.0221307841 --- alpha: 0.00059\n",
      "train_accuracy: 99.62353 - epoch 17    iteration 1500 - train loss 0.0568160779 ____ test loss 0.021484775 --- alpha: 0.00056\n",
      "train_accuracy: 99.52941 - epoch 18    iteration 1600 - train loss 0.0583657341 ____ test loss 0.0224211094 --- alpha: 0.00053\n",
      "train_accuracy: 99.6 - epoch 20    iteration 1700 - train loss 0.050952837 ____ test loss 0.0210462552 --- alpha: 0.00048\n",
      "train_accuracy: 99.74118 - epoch 21    iteration 1800 - train loss 0.0516494952 ____ test loss 0.020832098 --- alpha: 0.00045\n",
      "train_accuracy: 99.74118 - epoch 22    iteration 1900 - train loss 0.0504495284 ____ test loss 0.021285616 --- alpha: 0.00043\n",
      "train_accuracy: 99.74118 - epoch 23    iteration 2000 - train loss 0.0542296153 ____ test loss 0.0216532078 --- alpha: 0.00042\n",
      "train_accuracy: 99.85882 - epoch 24    iteration 2100 - train loss 0.0517807198 ____ test loss 0.0215689327 --- alpha: 0.0004\n",
      "train_accuracy: 99.88235 - epoch 25    iteration 2200 - train loss 0.0523422905 ____ test loss 0.0213958647 --- alpha: 0.00038\n",
      "train_accuracy: 99.81176 - epoch 26    iteration 2300 - train loss 0.0472355241 ____ test loss 0.0209485373 --- alpha: 0.00037\n",
      "train_accuracy: 99.76471 - epoch 27    iteration 2400 - train loss 0.0484276766 ____ test loss 0.0206670669 --- alpha: 0.00036\n",
      "train_accuracy: 99.85882 - epoch 29    iteration 2500 - train loss 0.0469055533 ____ test loss 0.0201758739 --- alpha: 0.00033\n",
      "train_accuracy: 99.88235 - epoch 30    iteration 2600 - train loss 0.0475240555 ____ test loss 0.0206622085 --- alpha: 0.00032\n",
      "train_accuracy: 99.92941 - epoch 31    iteration 2700 - train loss 0.0461884674 ____ test loss 0.0207380442 --- alpha: 0.00031\n",
      "train_accuracy: 99.88235 - epoch 32    iteration 2800 - train loss 0.0439067184 ____ test loss 0.0203463343 --- alpha: 0.0003\n",
      "train_accuracy: 99.88235 - epoch 33    iteration 2900 - train loss 0.0443786722 ____ test loss 0.0201971865 --- alpha: 0.00029\n",
      "train_accuracy: 99.88235 - epoch 34    iteration 3000 - train loss 0.0434040522 ____ test loss 0.0206601237 --- alpha: 0.00029\n",
      "train_accuracy: 99.90588 - epoch 35    iteration 3100 - train loss 0.0442293298 ____ test loss 0.0204786861 --- alpha: 0.00028\n",
      "train_accuracy: 99.88235 - epoch 36    iteration 3200 - train loss 0.0449549082 ____ test loss 0.0210183058 --- alpha: 0.00027\n",
      "train_accuracy: 99.90588 - epoch 38    iteration 3300 - train loss 0.0446125918 ____ test loss 0.0207240968 --- alpha: 0.00026\n",
      "train_accuracy: 99.90588 - epoch 39    iteration 3400 - train loss 0.0434968518 ____ test loss 0.0205732324 --- alpha: 0.00025\n",
      "train_accuracy: 99.90588 - epoch 40    iteration 3500 - train loss 0.0436769662 ____ test loss 0.0201865083 --- alpha: 0.00024\n",
      "train_accuracy: 99.90588 - epoch 41    iteration 3600 - train loss 0.0435301619 ____ test loss 0.0211958716 --- alpha: 0.00024\n",
      "train_accuracy: 99.95294 - epoch 42    iteration 3700 - train loss 0.0439138675 ____ test loss 0.0202577687 --- alpha: 0.00023\n",
      "train_accuracy: 99.92941 - epoch 43    iteration 3800 - train loss 0.0420930352 ____ test loss 0.0201191756 --- alpha: 0.00023\n",
      "train_accuracy: 99.92941 - epoch 44    iteration 3900 - train loss 0.0444722399 ____ test loss 0.0210811458 --- alpha: 0.00022\n",
      "train_accuracy: 99.88235 - epoch 45    iteration 4000 - train loss 0.0432020832 ____ test loss 0.0207798523 --- alpha: 0.00022\n",
      "train_accuracy: 99.90588 - epoch 47    iteration 4100 - train loss 0.0415890468 ____ test loss 0.0207494042 --- alpha: 0.00021\n",
      "train_accuracy: 99.90588 - epoch 48    iteration 4200 - train loss 0.0425380788 ____ test loss 0.0206579474 --- alpha: 0.0002\n",
      "train_accuracy: 99.85882 - epoch 49    iteration 4300 - train loss 0.0440279083 ____ test loss 0.0204319586 --- alpha: 0.0002\n",
      "train_accuracy: 99.92941 - epoch 50    iteration 4400 - train loss 0.0462499125 ____ test loss 0.020519857 --- alpha: 0.0002\n",
      "train_accuracy: 99.92941 - epoch 51    iteration 4500 - train loss 0.0417545673 ____ test loss 0.0200680269 --- alpha: 0.00019\n",
      "train_accuracy: 99.92941 - epoch 52    iteration 4600 - train loss 0.042218958 ____ test loss 0.0205627211 --- alpha: 0.00019\n",
      "train_accuracy: 99.97647 - epoch 53    iteration 4700 - train loss 0.0426664124 ____ test loss 0.0201592316 --- alpha: 0.00019\n",
      "train_accuracy: 99.95294 - epoch 54    iteration 4800 - train loss 0.0412696289 ____ test loss 0.0197703219 --- alpha: 0.00018\n",
      "train_accuracy: 99.92941 - epoch 56    iteration 4900 - train loss 0.0408024423 ____ test loss 0.0198725772 --- alpha: 0.00018\n",
      "train_accuracy: 99.95294 - epoch 57    iteration 5000 - train loss 0.0412355317 ____ test loss 0.0201205818 --- alpha: 0.00017\n",
      "train_accuracy: 99.95294 - epoch 58    iteration 5100 - train loss 0.0404403196 ____ test loss 0.0200084034 --- alpha: 0.00017\n",
      "train_accuracy: 99.97647 - epoch 59    iteration 5200 - train loss 0.042354794 ____ test loss 0.0205670699 --- alpha: 0.00017\n",
      "train_accuracy: 99.92941 - epoch 60    iteration 5300 - train loss 0.0422433771 ____ test loss 0.0208935189 --- alpha: 0.00016\n",
      "train_accuracy: 99.95294 - epoch 61    iteration 5400 - train loss 0.0407982678 ____ test loss 0.0201885945 --- alpha: 0.00016\n",
      "train_accuracy: 99.92941 - epoch 62    iteration 5500 - train loss 0.04012677 ____ test loss 0.0200603559 --- alpha: 0.00016\n",
      "train_accuracy: 99.92941 - epoch 63    iteration 5600 - train loss 0.0398730382 ____ test loss 0.0206029897 --- alpha: 0.00016\n",
      "train_accuracy: 99.97647 - epoch 65    iteration 5700 - train loss 0.0409508565 ____ test loss 0.0204244331 --- alpha: 0.00015\n",
      "train_accuracy: 100.0 - epoch 66    iteration 5800 - train loss 0.040737051 ____ test loss 0.0206719236 --- alpha: 0.00015\n",
      "train_accuracy: 99.95294 - epoch 67    iteration 5900 - train loss 0.0403045616 ____ test loss 0.0205745418 --- alpha: 0.00015\n",
      "train_accuracy: 99.95294 - epoch 68    iteration 6000 - train loss 0.0397904634 ____ test loss 0.0204581138 --- alpha: 0.00014\n",
      "train_accuracy: 99.97647 - epoch 69    iteration 6100 - train loss 0.041027728 ____ test loss 0.0207977782 --- alpha: 0.00014\n",
      "train_accuracy: 99.95294 - epoch 70    iteration 6200 - train loss 0.0403947111 ____ test loss 0.0197896174 --- alpha: 0.00014\n",
      "train_accuracy: 99.97647 - epoch 71    iteration 6300 - train loss 0.0410257031 ____ test loss 0.0204133653 --- alpha: 0.00014\n",
      "train_accuracy: 99.95294 - epoch 72    iteration 6400 - train loss 0.0396842292 ____ test loss 0.0199044841 --- alpha: 0.00014\n",
      "train_accuracy: 99.95294 - epoch 74    iteration 6500 - train loss 0.0393952963 ____ test loss 0.0198722422 --- alpha: 0.00013\n",
      "train_accuracy: 99.95294 - epoch 75    iteration 6600 - train loss 0.0386866996 ____ test loss 0.0199788571 --- alpha: 0.00013\n",
      "train_accuracy: 99.97647 - epoch 76    iteration 6700 - train loss 0.040245821 ____ test loss 0.0205585232 --- alpha: 0.00013\n",
      "train_accuracy: 99.97647 - epoch 77    iteration 6800 - train loss 0.0389717802 ____ test loss 0.0203447905 --- alpha: 0.00013\n",
      "train_accuracy: 100.0 - epoch 78    iteration 6900 - train loss 0.0391860169 ____ test loss 0.019969199 --- alpha: 0.00013\n",
      "train_accuracy: 99.97647 - epoch 79    iteration 7000 - train loss 0.0400468509 ____ test loss 0.0202599721 --- alpha: 0.00012\n",
      "train_accuracy: 100.0 - epoch 80    iteration 7100 - train loss 0.0409261097 ____ test loss 0.0201718129 --- alpha: 0.00012\n",
      "train_accuracy: 99.97647 - epoch 81    iteration 7200 - train loss 0.0389749043 ____ test loss 0.020178243 --- alpha: 0.00012\n",
      "train_accuracy: 100.0 - epoch 83    iteration 7300 - train loss 0.0391342912 ____ test loss 0.0201292336 --- alpha: 0.00012\n",
      "train_accuracy: 100.0 - epoch 84    iteration 7400 - train loss 0.0390803432 ____ test loss 0.0202262754 --- alpha: 0.00012\n",
      "train_accuracy: 99.97647 - epoch 85    iteration 7500 - train loss 0.0410982912 ____ test loss 0.0203832606 --- alpha: 0.00012\n",
      "train_accuracy: 99.95294 - epoch 86    iteration 7600 - train loss 0.0388577274 ____ test loss 0.0199101265 --- alpha: 0.00011\n",
      "train_accuracy: 99.95294 - epoch 87    iteration 7700 - train loss 0.0392985749 ____ test loss 0.0202010746 --- alpha: 0.00011\n",
      "train_accuracy: 99.97647 - epoch 88    iteration 7800 - train loss 0.0405666933 ____ test loss 0.0204972559 --- alpha: 0.00011\n",
      "train_accuracy: 99.95294 - epoch 89    iteration 7900 - train loss 0.0392384029 ____ test loss 0.0205663022 --- alpha: 0.00011\n",
      "train_accuracy: 99.95294 - epoch 90    iteration 8000 - train loss 0.0386472099 ____ test loss 0.0203867752 --- alpha: 0.00011\n",
      "train_accuracy: 99.97647 - epoch 92    iteration 8100 - train loss 0.0396488226 ____ test loss 0.0207522683 --- alpha: 0.00011\n",
      "train_accuracy: 100.0 - epoch 93    iteration 8200 - train loss 0.0394520911 ____ test loss 0.0201823501 --- alpha: 0.00011\n",
      "train_accuracy: 99.97647 - epoch 94    iteration 8300 - train loss 0.0385462946 ____ test loss 0.0202180612 --- alpha: 0.00011\n",
      "train_accuracy: 100.0 - epoch 95    iteration 8400 - train loss 0.0388976721 ____ test loss 0.0199030839 --- alpha: 0.0001\n",
      "train_accuracy: 99.97647 - epoch 96    iteration 8500 - train loss 0.039218056 ____ test loss 0.0201285107 --- alpha: 0.0001\n",
      "train_accuracy: 100.0 - epoch 97    iteration 8600 - train loss 0.0390471133 ____ test loss 0.0203935829 --- alpha: 0.0001\n",
      "train_accuracy: 99.97647 - epoch 98    iteration 8700 - train loss 0.0395968673 ____ test loss 0.0204471912 --- alpha: 0.0001\n",
      "train_accuracy: 100.0 - epoch 99    iteration 8800 - train loss 0.0385287353 ____ test loss 0.0199554633 --- alpha: 0.0001\n",
      "train_accuracy: 99.95294 - epoch 100    iteration 8900 - train loss 0.0395143335 ____ test loss 0.0201693615 --- alpha: 0.0001\n",
      "train_accuracy: 100.0 - epoch 102    iteration 9000 - train loss 0.0394520391 ____ test loss 0.0203452195 --- alpha: 0.0001\n",
      "train_accuracy: 100.0 - epoch 103    iteration 9100 - train loss 0.0391574131 ____ test loss 0.0201346428 --- alpha: 0.0001\n",
      "train_accuracy: 100.0 - epoch 104    iteration 9200 - train loss 0.0389907554 ____ test loss 0.0199521573 --- alpha: 0.0001\n",
      "train_accuracy: 100.0 - epoch 105    iteration 9300 - train loss 0.0382295388 ____ test loss 0.0203729452 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 106    iteration 9400 - train loss 0.0392955429 ____ test loss 0.0204103076 --- alpha: 9e-05\n",
      "train_accuracy: 99.97647 - epoch 107    iteration 9500 - train loss 0.0392138387 ____ test loss 0.0202722646 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 108    iteration 9600 - train loss 0.038778734 ____ test loss 0.0201402714 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 109    iteration 9700 - train loss 0.0386304412 ____ test loss 0.0203286912 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 111    iteration 9800 - train loss 0.038227206 ____ test loss 0.0199654901 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 112    iteration 9900 - train loss 0.0383257887 ____ test loss 0.0199898106 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 113    iteration 10000 - train loss 0.0388941837 ____ test loss 0.0201936561 --- alpha: 9e-05\n",
      "train_accuracy: 99.97647 - epoch 114    iteration 10100 - train loss 0.038632901 ____ test loss 0.0201633652 --- alpha: 9e-05\n",
      "train_accuracy: 99.97647 - epoch 115    iteration 10200 - train loss 0.0380736925 ____ test loss 0.019802728 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 116    iteration 10300 - train loss 0.0384158184 ____ test loss 0.020076404 --- alpha: 9e-05\n",
      "train_accuracy: 100.0 - epoch 117    iteration 10400 - train loss 0.0386846651 ____ test loss 0.0203032322 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 118    iteration 10500 - train loss 0.0379850852 ____ test loss 0.0198734539 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 120    iteration 10600 - train loss 0.0374649091 ____ test loss 0.0199214649 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 121    iteration 10700 - train loss 0.0383493612 ____ test loss 0.0200732394 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 122    iteration 10800 - train loss 0.0376204645 ____ test loss 0.0199958225 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 123    iteration 10900 - train loss 0.0376394635 ____ test loss 0.0201344654 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 124    iteration 11000 - train loss 0.0378664813 ____ test loss 0.0200198146 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 125    iteration 11100 - train loss 0.03831013 ____ test loss 0.0199250935 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 126    iteration 11200 - train loss 0.0375212666 ____ test loss 0.0199663665 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 127    iteration 11300 - train loss 0.0377499387 ____ test loss 0.0199684423 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 129    iteration 11400 - train loss 0.0375871305 ____ test loss 0.0197779231 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 130    iteration 11500 - train loss 0.0375091306 ____ test loss 0.019756785 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 131    iteration 11600 - train loss 0.037569323 ____ test loss 0.0198406074 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 132    iteration 11700 - train loss 0.0378427 ____ test loss 0.0199883422 --- alpha: 8e-05\n",
      "train_accuracy: 100.0 - epoch 133    iteration 11800 - train loss 0.0379917928 ____ test loss 0.0199892523 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 134    iteration 11900 - train loss 0.0382613244 ____ test loss 0.0197255092 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 135    iteration 12000 - train loss 0.0384958345 ____ test loss 0.0197180449 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 136    iteration 12100 - train loss 0.037935048 ____ test loss 0.0200745038 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 138    iteration 12200 - train loss 0.038474331 ____ test loss 0.0199216843 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 139    iteration 12300 - train loss 0.0381629222 ____ test loss 0.019869988 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 140    iteration 12400 - train loss 0.0373814898 ____ test loss 0.0198242519 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 141    iteration 12500 - train loss 0.0375930189 ____ test loss 0.0198934832 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 142    iteration 12600 - train loss 0.0373590487 ____ test loss 0.0199366767 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 143    iteration 12700 - train loss 0.0375674606 ____ test loss 0.0197716972 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 144    iteration 12800 - train loss 0.0385447996 ____ test loss 0.0199992074 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 145    iteration 12900 - train loss 0.0381354969 ____ test loss 0.0197453006 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 147    iteration 13000 - train loss 0.0380477638 ____ test loss 0.0200095493 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 148    iteration 13100 - train loss 0.0381408993 ____ test loss 0.0198404754 --- alpha: 7e-05\n",
      "train_accuracy: 99.97647 - epoch 149    iteration 13200 - train loss 0.0382430719 ____ test loss 0.0198685975 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 150    iteration 13300 - train loss 0.0382516271 ____ test loss 0.0200503557 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 151    iteration 13400 - train loss 0.0378854585 ____ test loss 0.0199699177 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 152    iteration 13500 - train loss 0.037698785 ____ test loss 0.0199056194 --- alpha: 7e-05\n",
      "train_accuracy: 100.0 - epoch 153    iteration 13600 - train loss 0.0382537467 ____ test loss 0.0200763244 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 154    iteration 13700 - train loss 0.0373742573 ____ test loss 0.0198661083 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 156    iteration 13800 - train loss 0.0379312822 ____ test loss 0.0198684185 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 157    iteration 13900 - train loss 0.0376859893 ____ test loss 0.0198797159 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 158    iteration 14000 - train loss 0.0375807779 ____ test loss 0.0197478664 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 159    iteration 14100 - train loss 0.0375646839 ____ test loss 0.0195236977 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 160    iteration 14200 - train loss 0.0376768119 ____ test loss 0.019712473 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 161    iteration 14300 - train loss 0.0373032999 ____ test loss 0.0198783475 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 162    iteration 14400 - train loss 0.0376040741 ____ test loss 0.019974597 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 163    iteration 14500 - train loss 0.0372761277 ____ test loss 0.0195887377 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 165    iteration 14600 - train loss 0.0379316685 ____ test loss 0.0197713704 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 166    iteration 14700 - train loss 0.0376926082 ____ test loss 0.0195981231 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 167    iteration 14800 - train loss 0.0375655091 ____ test loss 0.0196113154 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 168    iteration 14900 - train loss 0.0377120057 ____ test loss 0.0195853597 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 169    iteration 15000 - train loss 0.0375074029 ____ test loss 0.0198553405 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 170    iteration 15100 - train loss 0.0380827273 ____ test loss 0.0196835159 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 171    iteration 15200 - train loss 0.0379460575 ____ test loss 0.0197232687 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 172    iteration 15300 - train loss 0.037354436 ____ test loss 0.0196722859 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 174    iteration 15400 - train loss 0.0372277583 ____ test loss 0.0194566265 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 175    iteration 15500 - train loss 0.0373252819 ____ test loss 0.0196008666 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 176    iteration 15600 - train loss 0.0370940893 ____ test loss 0.0194652878 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 177    iteration 15700 - train loss 0.0372593873 ____ test loss 0.0197307591 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 178    iteration 15800 - train loss 0.037589384 ____ test loss 0.0197463418 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 179    iteration 15900 - train loss 0.0373587025 ____ test loss 0.0196908522 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 180    iteration 16000 - train loss 0.0371596369 ____ test loss 0.0198051123 --- alpha: 6e-05\n",
      "train_accuracy: 100.0 - epoch 181    iteration 16100 - train loss 0.0374260314 ____ test loss 0.0197179751 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 183    iteration 16200 - train loss 0.0371557157 ____ test loss 0.0197392729 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 184    iteration 16300 - train loss 0.0372550679 ____ test loss 0.0197548136 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 185    iteration 16400 - train loss 0.0374496414 ____ test loss 0.0199565456 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 186    iteration 16500 - train loss 0.0371609794 ____ test loss 0.0197444557 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 187    iteration 16600 - train loss 0.0372526938 ____ test loss 0.0196108471 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 188    iteration 16700 - train loss 0.0375277993 ____ test loss 0.0196726431 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 189    iteration 16800 - train loss 0.0370018583 ____ test loss 0.0194478102 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 190    iteration 16900 - train loss 0.0369106699 ____ test loss 0.0195822978 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 192    iteration 17000 - train loss 0.037682877 ____ test loss 0.0196273853 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 193    iteration 17100 - train loss 0.0371173231 ____ test loss 0.0197221662 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 194    iteration 17200 - train loss 0.0372121178 ____ test loss 0.0196180408 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 195    iteration 17300 - train loss 0.0377519652 ____ test loss 0.0196223919 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 196    iteration 17400 - train loss 0.0370985248 ____ test loss 0.019679719 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 197    iteration 17500 - train loss 0.0370402646 ____ test loss 0.019572143 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 198    iteration 17600 - train loss 0.0369960545 ____ test loss 0.0195399665 --- alpha: 5e-05\n",
      "train_accuracy: 99.97647 - epoch 199    iteration 17700 - train loss 0.0375716192 ____ test loss 0.0196701077 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 200    iteration 17800 - train loss 0.0374838156 ____ test loss 0.019691379 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 202    iteration 17900 - train loss 0.0372254491 ____ test loss 0.0195963219 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 203    iteration 18000 - train loss 0.037536231 ____ test loss 0.0197135905 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 204    iteration 18100 - train loss 0.0373694191 ____ test loss 0.0194555984 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 205    iteration 18200 - train loss 0.0368843236 ____ test loss 0.0195567912 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 206    iteration 18300 - train loss 0.0370416042 ____ test loss 0.0195816394 --- alpha: 5e-05\n",
      "train_accuracy: 99.97647 - epoch 207    iteration 18400 - train loss 0.0376587033 ____ test loss 0.0196109463 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 208    iteration 18500 - train loss 0.0366987415 ____ test loss 0.0195532228 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 209    iteration 18600 - train loss 0.0366887374 ____ test loss 0.019365702 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 211    iteration 18700 - train loss 0.0368048922 ____ test loss 0.0194947423 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 212    iteration 18800 - train loss 0.0370807053 ____ test loss 0.0195610539 --- alpha: 5e-05\n",
      "train_accuracy: 99.97647 - epoch 213    iteration 18900 - train loss 0.0372592856 ____ test loss 0.0195887638 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 214    iteration 19000 - train loss 0.0371879469 ____ test loss 0.0196025838 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 215    iteration 19100 - train loss 0.0372874076 ____ test loss 0.0195951994 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 216    iteration 19200 - train loss 0.0370452396 ____ test loss 0.0197223477 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 217    iteration 19300 - train loss 0.0374548857 ____ test loss 0.0196985388 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 218    iteration 19400 - train loss 0.0366311418 ____ test loss 0.0195993041 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 220    iteration 19500 - train loss 0.036877639 ____ test loss 0.0195722894 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 221    iteration 19600 - train loss 0.036784438 ____ test loss 0.019601072 --- alpha: 5e-05\n",
      "train_accuracy: 100.0 - epoch 222    iteration 19700 - train loss 0.0371872175 ____ test loss 0.01969137 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 223    iteration 19800 - train loss 0.036742589 ____ test loss 0.0193820436 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 224    iteration 19900 - train loss 0.0366831886 ____ test loss 0.019424768 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 225    iteration 20000 - train loss 0.0367466253 ____ test loss 0.0195085325 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 226    iteration 20100 - train loss 0.0375248512 ____ test loss 0.0194645005 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 227    iteration 20200 - train loss 0.0373737357 ____ test loss 0.0195355511 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 229    iteration 20300 - train loss 0.036839098 ____ test loss 0.0197373024 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 230    iteration 20400 - train loss 0.03743077 ____ test loss 0.019681712 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 231    iteration 20500 - train loss 0.036507018 ____ test loss 0.0196075101 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 232    iteration 20600 - train loss 0.0367543716 ____ test loss 0.0195521322 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 233    iteration 20700 - train loss 0.036735174 ____ test loss 0.0195584765 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 234    iteration 20800 - train loss 0.0364848669 ____ test loss 0.0196053076 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 235    iteration 20900 - train loss 0.0365163648 ____ test loss 0.0196022913 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 236    iteration 21000 - train loss 0.0366049876 ____ test loss 0.0198673263 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 238    iteration 21100 - train loss 0.0367272741 ____ test loss 0.0197449402 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 239    iteration 21200 - train loss 0.0363714434 ____ test loss 0.0198191893 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 240    iteration 21300 - train loss 0.0366924712 ____ test loss 0.0195033978 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 241    iteration 21400 - train loss 0.0366090059 ____ test loss 0.0196219423 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 242    iteration 21500 - train loss 0.0372664881 ____ test loss 0.0196298575 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 243    iteration 21600 - train loss 0.0367185933 ____ test loss 0.0195655178 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 244    iteration 21700 - train loss 0.0367173484 ____ test loss 0.0196729983 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 245    iteration 21800 - train loss 0.0365327949 ____ test loss 0.0195823901 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 247    iteration 21900 - train loss 0.0366156386 ____ test loss 0.0196403334 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 248    iteration 22000 - train loss 0.0369720405 ____ test loss 0.0194885777 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 249    iteration 22100 - train loss 0.0364230248 ____ test loss 0.0196283544 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 250    iteration 22200 - train loss 0.0365749677 ____ test loss 0.0196342476 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 251    iteration 22300 - train loss 0.0369829265 ____ test loss 0.0196090526 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 252    iteration 22400 - train loss 0.036747744 ____ test loss 0.0196986537 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 253    iteration 22500 - train loss 0.0364654816 ____ test loss 0.0196963007 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 254    iteration 22600 - train loss 0.03656952 ____ test loss 0.0195531654 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 256    iteration 22700 - train loss 0.0364353841 ____ test loss 0.0197362064 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 257    iteration 22800 - train loss 0.0365169869 ____ test loss 0.0196416216 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 258    iteration 22900 - train loss 0.0364990596 ____ test loss 0.0195589556 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 259    iteration 23000 - train loss 0.0366847721 ____ test loss 0.0197020368 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 260    iteration 23100 - train loss 0.0367488224 ____ test loss 0.01950296 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 261    iteration 23200 - train loss 0.0362833338 ____ test loss 0.0196662552 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 262    iteration 23300 - train loss 0.0363846544 ____ test loss 0.0196684282 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 263    iteration 23400 - train loss 0.0361878814 ____ test loss 0.019497671 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 265    iteration 23500 - train loss 0.0364953414 ____ test loss 0.019658592 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 266    iteration 23600 - train loss 0.0367234645 ____ test loss 0.0195731298 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 267    iteration 23700 - train loss 0.0364939372 ____ test loss 0.0195979082 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 268    iteration 23800 - train loss 0.0363583908 ____ test loss 0.019494266 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 269    iteration 23900 - train loss 0.036373809 ____ test loss 0.0196602246 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 270    iteration 24000 - train loss 0.0367938137 ____ test loss 0.0194402675 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 271    iteration 24100 - train loss 0.0364667202 ____ test loss 0.0196763055 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 272    iteration 24200 - train loss 0.0363009388 ____ test loss 0.0196635207 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 274    iteration 24300 - train loss 0.0361979605 ____ test loss 0.0195203664 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 275    iteration 24400 - train loss 0.036662345 ____ test loss 0.0195061349 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 276    iteration 24500 - train loss 0.0369800229 ____ test loss 0.0196017218 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 277    iteration 24600 - train loss 0.0367272996 ____ test loss 0.0197275025 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 278    iteration 24700 - train loss 0.0370934023 ____ test loss 0.0193893599 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 279    iteration 24800 - train loss 0.0364967989 ____ test loss 0.0196233824 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 280    iteration 24900 - train loss 0.036785623 ____ test loss 0.0194478886 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 281    iteration 25000 - train loss 0.0365266745 ____ test loss 0.0194812107 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 283    iteration 25100 - train loss 0.0365869842 ____ test loss 0.0195580619 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 284    iteration 25200 - train loss 0.0367209024 ____ test loss 0.0193152124 --- alpha: 4e-05\n",
      "train_accuracy: 100.0 - epoch 285    iteration 25300 - train loss 0.0365749663 ____ test loss 0.0193743215 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 286    iteration 25400 - train loss 0.0368165239 ____ test loss 0.0195636899 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 287    iteration 25500 - train loss 0.0367584664 ____ test loss 0.0195298677 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 288    iteration 25600 - train loss 0.0363667413 ____ test loss 0.0194707213 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 289    iteration 25700 - train loss 0.0366311107 ____ test loss 0.0196368395 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 290    iteration 25800 - train loss 0.0364067518 ____ test loss 0.0194666977 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 292    iteration 25900 - train loss 0.0367611186 ____ test loss 0.0196670066 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 293    iteration 26000 - train loss 0.0365121846 ____ test loss 0.0197508891 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 294    iteration 26100 - train loss 0.0364674207 ____ test loss 0.0196106919 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 295    iteration 26200 - train loss 0.0368335435 ____ test loss 0.0194107681 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 296    iteration 26300 - train loss 0.0368196437 ____ test loss 0.0195440394 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 297    iteration 26400 - train loss 0.0364456327 ____ test loss 0.0194849907 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 298    iteration 26500 - train loss 0.0363783294 ____ test loss 0.019550714 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 299    iteration 26600 - train loss 0.0364371306 ____ test loss 0.0196181914 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 300    iteration 26700 - train loss 0.036427548 ____ test loss 0.0197215889 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 302    iteration 26800 - train loss 0.036392279 ____ test loss 0.0197028289 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 303    iteration 26900 - train loss 0.0364730146 ____ test loss 0.0196123741 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 304    iteration 27000 - train loss 0.0366501684 ____ test loss 0.0197403257 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 305    iteration 27100 - train loss 0.0365175672 ____ test loss 0.019531678 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 306    iteration 27200 - train loss 0.0370729439 ____ test loss 0.0194974053 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 307    iteration 27300 - train loss 0.0365086939 ____ test loss 0.0195271521 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 308    iteration 27400 - train loss 0.036667063 ____ test loss 0.0196651244 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 309    iteration 27500 - train loss 0.0364636862 ____ test loss 0.0195694774 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 311    iteration 27600 - train loss 0.036287519 ____ test loss 0.0196150195 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 312    iteration 27700 - train loss 0.0367550493 ____ test loss 0.0196625398 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 313    iteration 27800 - train loss 0.0362241698 ____ test loss 0.0195914739 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 314    iteration 27900 - train loss 0.0365437078 ____ test loss 0.0195201973 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 315    iteration 28000 - train loss 0.0365781958 ____ test loss 0.0194875207 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 316    iteration 28100 - train loss 0.0366382416 ____ test loss 0.0196070361 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 317    iteration 28200 - train loss 0.0363562027 ____ test loss 0.0195232178 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 318    iteration 28300 - train loss 0.0363679879 ____ test loss 0.01944442 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 320    iteration 28400 - train loss 0.0365835467 ____ test loss 0.0194580528 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 321    iteration 28500 - train loss 0.0364986188 ____ test loss 0.019482099 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 322    iteration 28600 - train loss 0.0362140925 ____ test loss 0.0194442303 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 323    iteration 28700 - train loss 0.0364926662 ____ test loss 0.0194239199 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 324    iteration 28800 - train loss 0.0367800887 ____ test loss 0.0193780168 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 325    iteration 28900 - train loss 0.0370105915 ____ test loss 0.0193864301 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 326    iteration 29000 - train loss 0.0365176263 ____ test loss 0.0194974665 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 327    iteration 29100 - train loss 0.0365646328 ____ test loss 0.0195114492 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 329    iteration 29200 - train loss 0.0363907675 ____ test loss 0.0193657737 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 330    iteration 29300 - train loss 0.0363009862 ____ test loss 0.0194152448 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 331    iteration 29400 - train loss 0.0367017716 ____ test loss 0.0192882721 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 332    iteration 29500 - train loss 0.0370144717 ____ test loss 0.0192969655 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 333    iteration 29600 - train loss 0.0374137683 ____ test loss 0.0195074618 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 334    iteration 29700 - train loss 0.036795267 ____ test loss 0.0193695136 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 335    iteration 29800 - train loss 0.0367674764 ____ test loss 0.0193502316 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 336    iteration 29900 - train loss 0.0365486759 ____ test loss 0.0195493326 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 338    iteration 30000 - train loss 0.0363883031 ____ test loss 0.0193493084 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 339    iteration 30100 - train loss 0.0364235644 ____ test loss 0.0193927416 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 340    iteration 30200 - train loss 0.0366122863 ____ test loss 0.0195534891 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 341    iteration 30300 - train loss 0.0360540875 ____ test loss 0.0193728681 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 342    iteration 30400 - train loss 0.0364662552 ____ test loss 0.0193659872 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 343    iteration 30500 - train loss 0.0361129403 ____ test loss 0.0194082307 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 344    iteration 30600 - train loss 0.0366153056 ____ test loss 0.0194682639 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 345    iteration 30700 - train loss 0.0363075882 ____ test loss 0.0194372036 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 347    iteration 30800 - train loss 0.0369868986 ____ test loss 0.019489561 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 348    iteration 30900 - train loss 0.0369058163 ____ test loss 0.0194913893 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 349    iteration 31000 - train loss 0.0364388295 ____ test loss 0.0194229149 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 350    iteration 31100 - train loss 0.0366020783 ____ test loss 0.019345404 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 351    iteration 31200 - train loss 0.0364095594 ____ test loss 0.0194315908 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 352    iteration 31300 - train loss 0.0364376612 ____ test loss 0.0194359211 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 353    iteration 31400 - train loss 0.0360815377 ____ test loss 0.0195174485 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 354    iteration 31500 - train loss 0.0362519327 ____ test loss 0.0194910979 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 356    iteration 31600 - train loss 0.0362570675 ____ test loss 0.0194404661 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 357    iteration 31700 - train loss 0.0368126819 ____ test loss 0.0194376041 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 358    iteration 31800 - train loss 0.0365081924 ____ test loss 0.019437182 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 359    iteration 31900 - train loss 0.0364714885 ____ test loss 0.0193863209 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 360    iteration 32000 - train loss 0.0363309725 ____ test loss 0.0195902655 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 361    iteration 32100 - train loss 0.0363385284 ____ test loss 0.0194103594 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 362    iteration 32200 - train loss 0.0364204842 ____ test loss 0.0194274753 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 363    iteration 32300 - train loss 0.0361916163 ____ test loss 0.0196456447 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 365    iteration 32400 - train loss 0.0366576807 ____ test loss 0.0194337625 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 366    iteration 32500 - train loss 0.0363794532 ____ test loss 0.0195124001 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 367    iteration 32600 - train loss 0.036562715 ____ test loss 0.01946737 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 368    iteration 32700 - train loss 0.0364043712 ____ test loss 0.0195802922 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 369    iteration 32800 - train loss 0.0364330399 ____ test loss 0.0195319796 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 370    iteration 32900 - train loss 0.0364206754 ____ test loss 0.0196302441 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 371    iteration 33000 - train loss 0.0364040347 ____ test loss 0.0194999756 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 372    iteration 33100 - train loss 0.0360374422 ____ test loss 0.0194905133 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 374    iteration 33200 - train loss 0.0363352775 ____ test loss 0.0195400632 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 375    iteration 33300 - train loss 0.036513867 ____ test loss 0.0195063986 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 376    iteration 33400 - train loss 0.0365015049 ____ test loss 0.0195153899 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 377    iteration 33500 - train loss 0.0364876387 ____ test loss 0.019519193 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 378    iteration 33600 - train loss 0.0360941142 ____ test loss 0.0195555476 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 379    iteration 33700 - train loss 0.0363442504 ____ test loss 0.0193903506 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 380    iteration 33800 - train loss 0.0360043153 ____ test loss 0.0193466462 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 381    iteration 33900 - train loss 0.0365036914 ____ test loss 0.0193634449 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 383    iteration 34000 - train loss 0.0364306527 ____ test loss 0.0195512834 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 384    iteration 34100 - train loss 0.0361134195 ____ test loss 0.0195540134 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 385    iteration 34200 - train loss 0.0362823624 ____ test loss 0.0194805441 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 386    iteration 34300 - train loss 0.0360093512 ____ test loss 0.0193951989 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 387    iteration 34400 - train loss 0.0356596168 ____ test loss 0.0193818487 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 388    iteration 34500 - train loss 0.0360702225 ____ test loss 0.0193688137 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 389    iteration 34600 - train loss 0.0365799135 ____ test loss 0.0193768553 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 390    iteration 34700 - train loss 0.0366753326 ____ test loss 0.0194198885 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 392    iteration 34800 - train loss 0.0366800409 ____ test loss 0.0194101358 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 393    iteration 34900 - train loss 0.0362395884 ____ test loss 0.0194588433 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 394    iteration 35000 - train loss 0.0361047465 ____ test loss 0.0193892782 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 395    iteration 35100 - train loss 0.0361550682 ____ test loss 0.0193728803 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 396    iteration 35200 - train loss 0.0362672266 ____ test loss 0.0193528492 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 397    iteration 35300 - train loss 0.0363162259 ____ test loss 0.0194084408 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 398    iteration 35400 - train loss 0.0362359211 ____ test loss 0.0195264714 --- alpha: 3e-05\n",
      "train_accuracy: 100.0 - epoch 399    iteration 35500 - train loss 0.0363770137 ____ test loss 0.0194633327 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 400    iteration 35600 - train loss 0.0363251477 ____ test loss 0.019485262 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 402    iteration 35700 - train loss 0.036220323 ____ test loss 0.0195650326 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 403    iteration 35800 - train loss 0.0359243154 ____ test loss 0.0196656696 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 404    iteration 35900 - train loss 0.0359437153 ____ test loss 0.0195667904 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 405    iteration 36000 - train loss 0.0364765218 ____ test loss 0.0195122467 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 406    iteration 36100 - train loss 0.0362191581 ____ test loss 0.0193240282 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 407    iteration 36200 - train loss 0.0360871516 ____ test loss 0.0195548343 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 408    iteration 36300 - train loss 0.0360100859 ____ test loss 0.0195290658 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 409    iteration 36400 - train loss 0.0360502518 ____ test loss 0.0195205064 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 411    iteration 36500 - train loss 0.0361098986 ____ test loss 0.019509809 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 412    iteration 36600 - train loss 0.0362717622 ____ test loss 0.019541748 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 413    iteration 36700 - train loss 0.0365429768 ____ test loss 0.0195368827 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 414    iteration 36800 - train loss 0.0360386745 ____ test loss 0.0195713151 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 415    iteration 36900 - train loss 0.0361611287 ____ test loss 0.0193684385 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 416    iteration 37000 - train loss 0.0362576671 ____ test loss 0.0194671968 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 417    iteration 37100 - train loss 0.0361579962 ____ test loss 0.019483981 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 418    iteration 37200 - train loss 0.036104246 ____ test loss 0.0195200511 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 420    iteration 37300 - train loss 0.0363774551 ____ test loss 0.0195283994 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 421    iteration 37400 - train loss 0.036146603 ____ test loss 0.0196122486 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 422    iteration 37500 - train loss 0.0365482654 ____ test loss 0.0195854529 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 423    iteration 37600 - train loss 0.0359512802 ____ test loss 0.0194225087 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 424    iteration 37700 - train loss 0.0360646428 ____ test loss 0.0195394953 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 425    iteration 37800 - train loss 0.0359582828 ____ test loss 0.0194722575 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 426    iteration 37900 - train loss 0.0361425359 ____ test loss 0.0196151948 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 427    iteration 38000 - train loss 0.0361266282 ____ test loss 0.0196178538 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 429    iteration 38100 - train loss 0.0362304532 ____ test loss 0.019519306 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 430    iteration 38200 - train loss 0.0360400425 ____ test loss 0.0194473297 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 431    iteration 38300 - train loss 0.0364286386 ____ test loss 0.0195107615 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 432    iteration 38400 - train loss 0.0361143373 ____ test loss 0.0195288744 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 433    iteration 38500 - train loss 0.0361862878 ____ test loss 0.0194639197 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 434    iteration 38600 - train loss 0.0359753186 ____ test loss 0.0194249526 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 435    iteration 38700 - train loss 0.0363627868 ____ test loss 0.0195501816 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 436    iteration 38800 - train loss 0.0361085932 ____ test loss 0.0194640591 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 438    iteration 38900 - train loss 0.0363580013 ____ test loss 0.0195596235 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 439    iteration 39000 - train loss 0.0363617045 ____ test loss 0.0194257432 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 440    iteration 39100 - train loss 0.0362507653 ____ test loss 0.0195045412 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 441    iteration 39200 - train loss 0.0363308367 ____ test loss 0.0195777751 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 442    iteration 39300 - train loss 0.0364260103 ____ test loss 0.0196017747 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 443    iteration 39400 - train loss 0.036344705 ____ test loss 0.0196208393 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 444    iteration 39500 - train loss 0.0364686511 ____ test loss 0.0195832107 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 445    iteration 39600 - train loss 0.0363325103 ____ test loss 0.0194951744 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 447    iteration 39700 - train loss 0.0361449155 ____ test loss 0.0196630257 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 448    iteration 39800 - train loss 0.0361981342 ____ test loss 0.0195807343 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 449    iteration 39900 - train loss 0.0364009551 ____ test loss 0.0196815409 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 450    iteration 40000 - train loss 0.0363533616 ____ test loss 0.0195927806 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 451    iteration 40100 - train loss 0.0361957137 ____ test loss 0.0195696436 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 452    iteration 40200 - train loss 0.0359383997 ____ test loss 0.0196924367 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 453    iteration 40300 - train loss 0.0362435255 ____ test loss 0.0195347744 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 454    iteration 40400 - train loss 0.0361968335 ____ test loss 0.0194650932 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 456    iteration 40500 - train loss 0.0359799282 ____ test loss 0.0194517902 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 457    iteration 40600 - train loss 0.0356625344 ____ test loss 0.0194604791 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 458    iteration 40700 - train loss 0.0361665281 ____ test loss 0.019569491 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 459    iteration 40800 - train loss 0.0364705617 ____ test loss 0.0196813751 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 460    iteration 40900 - train loss 0.0361902377 ____ test loss 0.0195623695 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 461    iteration 41000 - train loss 0.036478027 ____ test loss 0.0196009678 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 462    iteration 41100 - train loss 0.036153683 ____ test loss 0.0196464984 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 463    iteration 41200 - train loss 0.0358422963 ____ test loss 0.019552421 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 465    iteration 41300 - train loss 0.0362621986 ____ test loss 0.0196430583 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 466    iteration 41400 - train loss 0.0362296141 ____ test loss 0.0195445613 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 467    iteration 41500 - train loss 0.0361432652 ____ test loss 0.0195419417 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 468    iteration 41600 - train loss 0.0359369722 ____ test loss 0.0195206839 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 469    iteration 41700 - train loss 0.0362920123 ____ test loss 0.0195031943 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 470    iteration 41800 - train loss 0.0364499028 ____ test loss 0.0195305242 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 471    iteration 41900 - train loss 0.0364237795 ____ test loss 0.0195085295 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 472    iteration 42000 - train loss 0.0362506142 ____ test loss 0.0194688249 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 474    iteration 42100 - train loss 0.0361499278 ____ test loss 0.0195845976 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 475    iteration 42200 - train loss 0.0363255834 ____ test loss 0.0195680893 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 476    iteration 42300 - train loss 0.0361721983 ____ test loss 0.0194814364 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 477    iteration 42400 - train loss 0.0359557919 ____ test loss 0.0195781501 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 478    iteration 42500 - train loss 0.0360296934 ____ test loss 0.0195414745 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 479    iteration 42600 - train loss 0.0362685796 ____ test loss 0.0196372567 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 480    iteration 42700 - train loss 0.0362450379 ____ test loss 0.0195155566 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 481    iteration 42800 - train loss 0.0360587423 ____ test loss 0.0195422396 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 483    iteration 42900 - train loss 0.0358612286 ____ test loss 0.019667821 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 484    iteration 43000 - train loss 0.0361135377 ____ test loss 0.0195519724 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 485    iteration 43100 - train loss 0.0359088888 ____ test loss 0.0196257464 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 486    iteration 43200 - train loss 0.0358305511 ____ test loss 0.0195639905 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 487    iteration 43300 - train loss 0.0364790801 ____ test loss 0.0195941462 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 488    iteration 43400 - train loss 0.036101855 ____ test loss 0.0195112424 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 489    iteration 43500 - train loss 0.0359067313 ____ test loss 0.0195043281 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 490    iteration 43600 - train loss 0.0356345626 ____ test loss 0.0195082286 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 492    iteration 43700 - train loss 0.0359223331 ____ test loss 0.0195544787 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 493    iteration 43800 - train loss 0.0360126308 ____ test loss 0.0196005608 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 494    iteration 43900 - train loss 0.035668515 ____ test loss 0.0194868204 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 495    iteration 44000 - train loss 0.036036054 ____ test loss 0.0194407413 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 496    iteration 44100 - train loss 0.0357902545 ____ test loss 0.0195132505 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 497    iteration 44200 - train loss 0.0361496441 ____ test loss 0.0194876631 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 498    iteration 44300 - train loss 0.0359705114 ____ test loss 0.0195536503 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 499    iteration 44400 - train loss 0.0360830448 ____ test loss 0.0194575848 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 500    iteration 44500 - train loss 0.0362700633 ____ test loss 0.0195395543 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 502    iteration 44600 - train loss 0.0359619485 ____ test loss 0.0196002758 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 503    iteration 44700 - train loss 0.036462249 ____ test loss 0.0195322105 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 504    iteration 44800 - train loss 0.0358209262 ____ test loss 0.0195366289 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 505    iteration 44900 - train loss 0.0361155705 ____ test loss 0.0194864394 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 506    iteration 45000 - train loss 0.036200553 ____ test loss 0.0195686388 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 507    iteration 45100 - train loss 0.0360179368 ____ test loss 0.0195568869 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 508    iteration 45200 - train loss 0.036082038 ____ test loss 0.0194687194 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 509    iteration 45300 - train loss 0.0360738544 ____ test loss 0.0194133755 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 511    iteration 45400 - train loss 0.0359934423 ____ test loss 0.0194651411 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 512    iteration 45500 - train loss 0.0358758787 ____ test loss 0.0194913882 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 513    iteration 45600 - train loss 0.0361362026 ____ test loss 0.0194504343 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 514    iteration 45700 - train loss 0.0362024531 ____ test loss 0.0194574947 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 515    iteration 45800 - train loss 0.0358822806 ____ test loss 0.0195071947 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 516    iteration 45900 - train loss 0.0358143722 ____ test loss 0.0195371738 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 517    iteration 46000 - train loss 0.0365402846 ____ test loss 0.0195004511 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 518    iteration 46100 - train loss 0.0360316808 ____ test loss 0.0195342049 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 520    iteration 46200 - train loss 0.0360911112 ____ test loss 0.0194785047 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 521    iteration 46300 - train loss 0.0359268406 ____ test loss 0.0195237691 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 522    iteration 46400 - train loss 0.0361827109 ____ test loss 0.0194614598 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 523    iteration 46500 - train loss 0.0361049894 ____ test loss 0.0194487571 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 524    iteration 46600 - train loss 0.0358441596 ____ test loss 0.0195330793 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 525    iteration 46700 - train loss 0.0358214205 ____ test loss 0.0195778252 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 526    iteration 46800 - train loss 0.0361392415 ____ test loss 0.0195489218 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 527    iteration 46900 - train loss 0.0360031775 ____ test loss 0.0195075642 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 529    iteration 47000 - train loss 0.0358338925 ____ test loss 0.0194813875 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 530    iteration 47100 - train loss 0.0360248067 ____ test loss 0.0195357796 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 531    iteration 47200 - train loss 0.0359854222 ____ test loss 0.0194120032 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 532    iteration 47300 - train loss 0.0360694563 ____ test loss 0.0194943389 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 533    iteration 47400 - train loss 0.0359291513 ____ test loss 0.0195001871 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 534    iteration 47500 - train loss 0.0364444007 ____ test loss 0.0195642957 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 535    iteration 47600 - train loss 0.0360860252 ____ test loss 0.0195073076 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 536    iteration 47700 - train loss 0.0361718654 ____ test loss 0.0195463134 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 538    iteration 47800 - train loss 0.0358297262 ____ test loss 0.0195266845 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 539    iteration 47900 - train loss 0.0362950287 ____ test loss 0.0195183044 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 540    iteration 48000 - train loss 0.0357583256 ____ test loss 0.0194684277 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 541    iteration 48100 - train loss 0.0357956255 ____ test loss 0.0193536307 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 542    iteration 48200 - train loss 0.0355092785 ____ test loss 0.0194095689 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 543    iteration 48300 - train loss 0.0358119241 ____ test loss 0.0194282823 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 544    iteration 48400 - train loss 0.0356567183 ____ test loss 0.0193956451 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 545    iteration 48500 - train loss 0.0357964948 ____ test loss 0.0193899847 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 547    iteration 48600 - train loss 0.0359184702 ____ test loss 0.0195158238 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 548    iteration 48700 - train loss 0.036089218 ____ test loss 0.0195505923 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 549    iteration 48800 - train loss 0.0358714127 ____ test loss 0.0194569121 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 550    iteration 48900 - train loss 0.0362501747 ____ test loss 0.0195156741 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 551    iteration 49000 - train loss 0.0361352761 ____ test loss 0.0196385414 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 552    iteration 49100 - train loss 0.0360126441 ____ test loss 0.0194435359 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 553    iteration 49200 - train loss 0.0356930805 ____ test loss 0.0194284435 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 554    iteration 49300 - train loss 0.0356514128 ____ test loss 0.0194238925 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 556    iteration 49400 - train loss 0.0360947979 ____ test loss 0.0194834946 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 557    iteration 49500 - train loss 0.0359858908 ____ test loss 0.019522324 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 558    iteration 49600 - train loss 0.0358318046 ____ test loss 0.0194651044 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 559    iteration 49700 - train loss 0.0357142953 ____ test loss 0.0194066569 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 560    iteration 49800 - train loss 0.0357891648 ____ test loss 0.0195996981 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 561    iteration 49900 - train loss 0.03597346 ____ test loss 0.019600247 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 562    iteration 50000 - train loss 0.0361352915 ____ test loss 0.0196137458 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 563    iteration 50100 - train loss 0.0358469796 ____ test loss 0.019600369 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 565    iteration 50200 - train loss 0.0357335327 ____ test loss 0.0195326502 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 566    iteration 50300 - train loss 0.0357897234 ____ test loss 0.0195290198 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 567    iteration 50400 - train loss 0.0359397651 ____ test loss 0.0195549542 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 568    iteration 50500 - train loss 0.035598422 ____ test loss 0.0195592938 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 569    iteration 50600 - train loss 0.0357879054 ____ test loss 0.0195926929 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 570    iteration 50700 - train loss 0.0359930799 ____ test loss 0.0196768821 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 571    iteration 50800 - train loss 0.0364044953 ____ test loss 0.0197162952 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 572    iteration 50900 - train loss 0.0362732615 ____ test loss 0.0196350257 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 574    iteration 51000 - train loss 0.0360273214 ____ test loss 0.0195829877 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 575    iteration 51100 - train loss 0.0357269477 ____ test loss 0.0196635401 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 576    iteration 51200 - train loss 0.0357837416 ____ test loss 0.0196286193 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 577    iteration 51300 - train loss 0.0358724336 ____ test loss 0.0195902055 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 578    iteration 51400 - train loss 0.0358971898 ____ test loss 0.0195852187 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 579    iteration 51500 - train loss 0.0357915016 ____ test loss 0.0197251762 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 580    iteration 51600 - train loss 0.036036816 ____ test loss 0.0197367457 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 581    iteration 51700 - train loss 0.0360412455 ____ test loss 0.0197026091 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 583    iteration 51800 - train loss 0.0356588576 ____ test loss 0.0195585484 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 584    iteration 51900 - train loss 0.0359224771 ____ test loss 0.0196560476 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 585    iteration 52000 - train loss 0.0361263429 ____ test loss 0.0196817702 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 586    iteration 52100 - train loss 0.0361121402 ____ test loss 0.0195278801 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 587    iteration 52200 - train loss 0.0359610925 ____ test loss 0.0195433394 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 588    iteration 52300 - train loss 0.0358503483 ____ test loss 0.0196074399 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 589    iteration 52400 - train loss 0.0363913381 ____ test loss 0.0196303296 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 590    iteration 52500 - train loss 0.0359497156 ____ test loss 0.0195575463 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 592    iteration 52600 - train loss 0.0358136462 ____ test loss 0.0194635339 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 593    iteration 52700 - train loss 0.0359701774 ____ test loss 0.019569024 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 594    iteration 52800 - train loss 0.0357181408 ____ test loss 0.0195506931 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 595    iteration 52900 - train loss 0.0361603331 ____ test loss 0.0195203627 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 596    iteration 53000 - train loss 0.0363568599 ____ test loss 0.0194873265 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 597    iteration 53100 - train loss 0.0358516923 ____ test loss 0.019567296 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 598    iteration 53200 - train loss 0.0360408329 ____ test loss 0.0194974566 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 599    iteration 53300 - train loss 0.0358827121 ____ test loss 0.0196214966 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 600    iteration 53400 - train loss 0.0361527479 ____ test loss 0.0195714886 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 602    iteration 53500 - train loss 0.0360220705 ____ test loss 0.0195984994 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 603    iteration 53600 - train loss 0.036222181 ____ test loss 0.0196010971 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 604    iteration 53700 - train loss 0.0359658475 ____ test loss 0.0195511581 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 605    iteration 53800 - train loss 0.035968938 ____ test loss 0.0195151241 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 606    iteration 53900 - train loss 0.0358555415 ____ test loss 0.0195237366 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 607    iteration 54000 - train loss 0.0360382659 ____ test loss 0.0195288744 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 608    iteration 54100 - train loss 0.035990101 ____ test loss 0.0195818683 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 609    iteration 54200 - train loss 0.0359490097 ____ test loss 0.0195562454 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 611    iteration 54300 - train loss 0.0357960722 ____ test loss 0.0195539554 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 612    iteration 54400 - train loss 0.0359603921 ____ test loss 0.0195456917 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 613    iteration 54500 - train loss 0.0357820117 ____ test loss 0.0195632004 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 614    iteration 54600 - train loss 0.0356701926 ____ test loss 0.0195555487 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 615    iteration 54700 - train loss 0.0355689319 ____ test loss 0.0196029 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 616    iteration 54800 - train loss 0.0355874446 ____ test loss 0.0195547445 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 617    iteration 54900 - train loss 0.0359047368 ____ test loss 0.0196276964 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 618    iteration 55000 - train loss 0.0358778692 ____ test loss 0.0196119824 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 620    iteration 55100 - train loss 0.035695059 ____ test loss 0.0195480985 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 621    iteration 55200 - train loss 0.0359149102 ____ test loss 0.0195886848 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 622    iteration 55300 - train loss 0.0361101314 ____ test loss 0.0197093037 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 623    iteration 55400 - train loss 0.0358723695 ____ test loss 0.0197183774 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 624    iteration 55500 - train loss 0.0356459937 ____ test loss 0.0196080072 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 625    iteration 55600 - train loss 0.0358164494 ____ test loss 0.019563976 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 626    iteration 55700 - train loss 0.0358158985 ____ test loss 0.0196192678 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 627    iteration 55800 - train loss 0.0359072194 ____ test loss 0.0195839264 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 629    iteration 55900 - train loss 0.0360403286 ____ test loss 0.0195062232 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 630    iteration 56000 - train loss 0.0362167991 ____ test loss 0.0194717407 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 631    iteration 56100 - train loss 0.0358031277 ____ test loss 0.0195269406 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 632    iteration 56200 - train loss 0.035644324 ____ test loss 0.0194337704 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 633    iteration 56300 - train loss 0.0358960476 ____ test loss 0.019470991 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 634    iteration 56400 - train loss 0.0357649104 ____ test loss 0.0194636147 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 635    iteration 56500 - train loss 0.0361284898 ____ test loss 0.0194962214 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 636    iteration 56600 - train loss 0.0359022584 ____ test loss 0.019510348 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 638    iteration 56700 - train loss 0.0359634995 ____ test loss 0.0196260573 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 639    iteration 56800 - train loss 0.0357877152 ____ test loss 0.0195297439 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 640    iteration 56900 - train loss 0.0356768 ____ test loss 0.0196370619 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 641    iteration 57000 - train loss 0.0357563119 ____ test loss 0.0195494458 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 642    iteration 57100 - train loss 0.0360205257 ____ test loss 0.0195603731 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 643    iteration 57200 - train loss 0.0356269047 ____ test loss 0.0196344297 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 644    iteration 57300 - train loss 0.0361361579 ____ test loss 0.0197177762 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 645    iteration 57400 - train loss 0.0358857302 ____ test loss 0.0196904688 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 647    iteration 57500 - train loss 0.0356756757 ____ test loss 0.0196522979 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 648    iteration 57600 - train loss 0.0358511864 ____ test loss 0.0196237311 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 649    iteration 57700 - train loss 0.0358106502 ____ test loss 0.0195403562 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 650    iteration 57800 - train loss 0.0357987471 ____ test loss 0.0194716247 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 651    iteration 57900 - train loss 0.0355409163 ____ test loss 0.0195777113 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 652    iteration 58000 - train loss 0.0355829074 ____ test loss 0.0195042208 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 653    iteration 58100 - train loss 0.0356438077 ____ test loss 0.0195333212 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 654    iteration 58200 - train loss 0.0358604519 ____ test loss 0.0194507204 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 656    iteration 58300 - train loss 0.0356998993 ____ test loss 0.0195085451 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 657    iteration 58400 - train loss 0.0359220756 ____ test loss 0.0196121548 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 658    iteration 58500 - train loss 0.0359779779 ____ test loss 0.0196582584 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 659    iteration 58600 - train loss 0.0356173152 ____ test loss 0.0195744575 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 660    iteration 58700 - train loss 0.035747461 ____ test loss 0.019614741 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 661    iteration 58800 - train loss 0.0356722836 ____ test loss 0.0196085236 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 662    iteration 58900 - train loss 0.0358088718 ____ test loss 0.0195351465 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 663    iteration 59000 - train loss 0.035732483 ____ test loss 0.0197088167 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 665    iteration 59100 - train loss 0.0357449134 ____ test loss 0.0196614178 --- alpha: 2e-05\n",
      "train_accuracy: 100.0 - epoch 666    iteration 59200 - train loss 0.0355104204 ____ test loss 0.019633156 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 667    iteration 59300 - train loss 0.0354578396 ____ test loss 0.0196527399 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 668    iteration 59400 - train loss 0.0356958417 ____ test loss 0.0196308185 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 669    iteration 59500 - train loss 0.0358449241 ____ test loss 0.0196345975 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 670    iteration 59600 - train loss 0.0355420539 ____ test loss 0.0195608056 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 671    iteration 59700 - train loss 0.0357205928 ____ test loss 0.0195146865 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 672    iteration 59800 - train loss 0.0356060933 ____ test loss 0.0195671228 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 674    iteration 59900 - train loss 0.0355631756 ____ test loss 0.0194841102 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 675    iteration 60000 - train loss 0.0355061985 ____ test loss 0.0195327252 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 676    iteration 60100 - train loss 0.035855488 ____ test loss 0.0195748045 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 677    iteration 60200 - train loss 0.0356926914 ____ test loss 0.0196364598 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 678    iteration 60300 - train loss 0.0359306147 ____ test loss 0.0195620542 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 679    iteration 60400 - train loss 0.0354993178 ____ test loss 0.0195805861 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 680    iteration 60500 - train loss 0.0355173969 ____ test loss 0.0195518046 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 681    iteration 60600 - train loss 0.0356382927 ____ test loss 0.019583524 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 683    iteration 60700 - train loss 0.035694634 ____ test loss 0.0195217187 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 684    iteration 60800 - train loss 0.0355279695 ____ test loss 0.0195910848 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 685    iteration 60900 - train loss 0.0357578005 ____ test loss 0.0196087931 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 686    iteration 61000 - train loss 0.0359149874 ____ test loss 0.0195971846 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 687    iteration 61100 - train loss 0.0359663954 ____ test loss 0.0195794824 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 688    iteration 61200 - train loss 0.0361846027 ____ test loss 0.0195566292 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 689    iteration 61300 - train loss 0.0359770725 ____ test loss 0.0195000664 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 690    iteration 61400 - train loss 0.0359400965 ____ test loss 0.0195030486 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 692    iteration 61500 - train loss 0.0358221613 ____ test loss 0.0195201184 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 693    iteration 61600 - train loss 0.0358219134 ____ test loss 0.0195850321 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 694    iteration 61700 - train loss 0.0359624148 ____ test loss 0.019512239 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 695    iteration 61800 - train loss 0.0358144989 ____ test loss 0.019539815 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 696    iteration 61900 - train loss 0.0358782886 ____ test loss 0.019545199 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 697    iteration 62000 - train loss 0.0356315221 ____ test loss 0.0196242499 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 698    iteration 62100 - train loss 0.0356441262 ____ test loss 0.0195956546 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 699    iteration 62200 - train loss 0.035769103 ____ test loss 0.0196537602 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 700    iteration 62300 - train loss 0.0356181716 ____ test loss 0.0196298515 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 702    iteration 62400 - train loss 0.0357458903 ____ test loss 0.0195857928 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 703    iteration 62500 - train loss 0.0357499043 ____ test loss 0.0195963595 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 704    iteration 62600 - train loss 0.0359012833 ____ test loss 0.0196006183 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 705    iteration 62700 - train loss 0.0356886194 ____ test loss 0.0196481112 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 706    iteration 62800 - train loss 0.0358768018 ____ test loss 0.0196315378 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 707    iteration 62900 - train loss 0.0357482778 ____ test loss 0.0196027244 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 708    iteration 63000 - train loss 0.0357581261 ____ test loss 0.0196086884 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 709    iteration 63100 - train loss 0.0356575202 ____ test loss 0.0196235855 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 711    iteration 63200 - train loss 0.0359057028 ____ test loss 0.0195421518 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 712    iteration 63300 - train loss 0.0357321942 ____ test loss 0.0195905517 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 713    iteration 63400 - train loss 0.0359227587 ____ test loss 0.0195386858 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 714    iteration 63500 - train loss 0.0359572843 ____ test loss 0.019525125 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 715    iteration 63600 - train loss 0.0356629755 ____ test loss 0.0195097236 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 716    iteration 63700 - train loss 0.0356372901 ____ test loss 0.0196046357 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 717    iteration 63800 - train loss 0.0359458353 ____ test loss 0.0196065529 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 718    iteration 63900 - train loss 0.0358017293 ____ test loss 0.0195904789 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 720    iteration 64000 - train loss 0.0356432519 ____ test loss 0.0196145305 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 721    iteration 64100 - train loss 0.0357971491 ____ test loss 0.0196670448 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 722    iteration 64200 - train loss 0.0357627481 ____ test loss 0.0195464658 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 723    iteration 64300 - train loss 0.035496836 ____ test loss 0.0196281267 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 724    iteration 64400 - train loss 0.0357005296 ____ test loss 0.0195839714 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 725    iteration 64500 - train loss 0.0361325237 ____ test loss 0.0196166657 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 726    iteration 64600 - train loss 0.0358436744 ____ test loss 0.0195494952 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 727    iteration 64700 - train loss 0.0357715254 ____ test loss 0.0195776219 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 729    iteration 64800 - train loss 0.0360480628 ____ test loss 0.0195317731 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 730    iteration 64900 - train loss 0.0358588382 ____ test loss 0.0195523421 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 731    iteration 65000 - train loss 0.0360099173 ____ test loss 0.0195844126 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 732    iteration 65100 - train loss 0.0357856998 ____ test loss 0.019585952 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 733    iteration 65200 - train loss 0.0356632468 ____ test loss 0.0195804057 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 734    iteration 65300 - train loss 0.0357936414 ____ test loss 0.0195771099 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 735    iteration 65400 - train loss 0.0359321377 ____ test loss 0.0195464318 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 736    iteration 65500 - train loss 0.035653714 ____ test loss 0.0195549247 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 738    iteration 65600 - train loss 0.0357142419 ____ test loss 0.0195935403 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 739    iteration 65700 - train loss 0.03558293 ____ test loss 0.0195999778 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 740    iteration 65800 - train loss 0.035821403 ____ test loss 0.0196009401 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 741    iteration 65900 - train loss 0.0357256008 ____ test loss 0.0196142292 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 742    iteration 66000 - train loss 0.0358165914 ____ test loss 0.0195386141 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 743    iteration 66100 - train loss 0.0355841562 ____ test loss 0.0195430062 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 744    iteration 66200 - train loss 0.0357557516 ____ test loss 0.0195674367 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 745    iteration 66300 - train loss 0.0355956658 ____ test loss 0.0196417326 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 747    iteration 66400 - train loss 0.0355670282 ____ test loss 0.0196042777 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 748    iteration 66500 - train loss 0.035624865 ____ test loss 0.0196364674 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 749    iteration 66600 - train loss 0.0355691289 ____ test loss 0.0195763516 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 750    iteration 66700 - train loss 0.0354902968 ____ test loss 0.0195835621 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 751    iteration 66800 - train loss 0.0356691657 ____ test loss 0.0196012302 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 752    iteration 66900 - train loss 0.035749811 ____ test loss 0.0195993819 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 753    iteration 67000 - train loss 0.03587772 ____ test loss 0.019659814 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 754    iteration 67100 - train loss 0.035783243 ____ test loss 0.0195175334 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 756    iteration 67200 - train loss 0.0354688412 ____ test loss 0.0195568114 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 757    iteration 67300 - train loss 0.0354528931 ____ test loss 0.0195595123 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 758    iteration 67400 - train loss 0.0354242487 ____ test loss 0.0194814357 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 759    iteration 67500 - train loss 0.0355824845 ____ test loss 0.0195086077 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 760    iteration 67600 - train loss 0.0355300522 ____ test loss 0.0195003037 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 761    iteration 67700 - train loss 0.0356489479 ____ test loss 0.0195330644 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 762    iteration 67800 - train loss 0.0358007755 ____ test loss 0.0194986383 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 763    iteration 67900 - train loss 0.0355016251 ____ test loss 0.0195745647 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 765    iteration 68000 - train loss 0.0357039598 ____ test loss 0.0195544974 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 766    iteration 68100 - train loss 0.0357771287 ____ test loss 0.0196950018 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 767    iteration 68200 - train loss 0.0357922816 ____ test loss 0.0195848273 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 768    iteration 68300 - train loss 0.0356104616 ____ test loss 0.0196528308 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 769    iteration 68400 - train loss 0.0357314107 ____ test loss 0.019653045 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 770    iteration 68500 - train loss 0.0358367953 ____ test loss 0.0196483839 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 771    iteration 68600 - train loss 0.0357538092 ____ test loss 0.0196105581 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 772    iteration 68700 - train loss 0.035589384 ____ test loss 0.0196341598 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 774    iteration 68800 - train loss 0.0356503436 ____ test loss 0.0196080194 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 775    iteration 68900 - train loss 0.0355186197 ____ test loss 0.0196916845 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 776    iteration 69000 - train loss 0.0354697499 ____ test loss 0.0196403572 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 777    iteration 69100 - train loss 0.0354119553 ____ test loss 0.0197247867 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 778    iteration 69200 - train loss 0.0354229157 ____ test loss 0.0196868219 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 779    iteration 69300 - train loss 0.0354112235 ____ test loss 0.0196488839 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 780    iteration 69400 - train loss 0.0354004812 ____ test loss 0.0196775419 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 781    iteration 69500 - train loss 0.0355445052 ____ test loss 0.0195832554 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 783    iteration 69600 - train loss 0.0355016539 ____ test loss 0.0195647237 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 784    iteration 69700 - train loss 0.0354501266 ____ test loss 0.0197225087 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 785    iteration 69800 - train loss 0.0355249111 ____ test loss 0.0196175232 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 786    iteration 69900 - train loss 0.0356783878 ____ test loss 0.0196389876 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 787    iteration 70000 - train loss 0.0355884575 ____ test loss 0.0196687951 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 788    iteration 70100 - train loss 0.0357164141 ____ test loss 0.0196084374 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 789    iteration 70200 - train loss 0.0353820371 ____ test loss 0.019615145 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 790    iteration 70300 - train loss 0.0357646513 ____ test loss 0.0195117214 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 792    iteration 70400 - train loss 0.0354925528 ____ test loss 0.0195615183 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 793    iteration 70500 - train loss 0.0355357026 ____ test loss 0.0195293354 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 794    iteration 70600 - train loss 0.0355515156 ____ test loss 0.0195719415 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 795    iteration 70700 - train loss 0.0355018326 ____ test loss 0.0195886854 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 796    iteration 70800 - train loss 0.0353113227 ____ test loss 0.0196271037 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 797    iteration 70900 - train loss 0.0355288464 ____ test loss 0.0195836614 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 798    iteration 71000 - train loss 0.0354767897 ____ test loss 0.0195469115 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 799    iteration 71100 - train loss 0.0356922219 ____ test loss 0.0194375703 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 800    iteration 71200 - train loss 0.0356684134 ____ test loss 0.0195226546 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 802    iteration 71300 - train loss 0.0355335092 ____ test loss 0.0195405723 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 803    iteration 71400 - train loss 0.0355050594 ____ test loss 0.019539446 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 804    iteration 71500 - train loss 0.0356003629 ____ test loss 0.0195594159 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 805    iteration 71600 - train loss 0.0357640779 ____ test loss 0.01952928 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 806    iteration 71700 - train loss 0.0355740108 ____ test loss 0.0194743431 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 807    iteration 71800 - train loss 0.035858693 ____ test loss 0.0195226521 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 808    iteration 71900 - train loss 0.0356912457 ____ test loss 0.0195729708 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 809    iteration 72000 - train loss 0.0356360471 ____ test loss 0.0195396369 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 811    iteration 72100 - train loss 0.0355483633 ____ test loss 0.0194988302 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 812    iteration 72200 - train loss 0.0354924926 ____ test loss 0.0195500969 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 813    iteration 72300 - train loss 0.0356725394 ____ test loss 0.0195819535 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 814    iteration 72400 - train loss 0.0356798565 ____ test loss 0.0195238762 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 815    iteration 72500 - train loss 0.0356336681 ____ test loss 0.0195210414 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 816    iteration 72600 - train loss 0.0355285003 ____ test loss 0.0196089683 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 817    iteration 72700 - train loss 0.035836897 ____ test loss 0.019542116 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 818    iteration 72800 - train loss 0.035676573 ____ test loss 0.019505926 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 820    iteration 72900 - train loss 0.0360630543 ____ test loss 0.0195238879 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 821    iteration 73000 - train loss 0.0356897927 ____ test loss 0.0194572635 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 822    iteration 73100 - train loss 0.0357886641 ____ test loss 0.0195185815 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 823    iteration 73200 - train loss 0.0356623197 ____ test loss 0.0195939342 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 824    iteration 73300 - train loss 0.0356152809 ____ test loss 0.0195390633 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 825    iteration 73400 - train loss 0.0354351813 ____ test loss 0.0194844364 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 826    iteration 73500 - train loss 0.0356032932 ____ test loss 0.0195136798 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 827    iteration 73600 - train loss 0.0357806448 ____ test loss 0.0194747131 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 829    iteration 73700 - train loss 0.0356724706 ____ test loss 0.0194570618 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 830    iteration 73800 - train loss 0.0355774172 ____ test loss 0.0195497527 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 831    iteration 73900 - train loss 0.0355156077 ____ test loss 0.0196027553 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 832    iteration 74000 - train loss 0.0355131443 ____ test loss 0.0195368657 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 833    iteration 74100 - train loss 0.0357390064 ____ test loss 0.0195155185 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 834    iteration 74200 - train loss 0.0355843905 ____ test loss 0.0196275509 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 835    iteration 74300 - train loss 0.035597678 ____ test loss 0.0195421324 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 836    iteration 74400 - train loss 0.0357212656 ____ test loss 0.0195220901 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 838    iteration 74500 - train loss 0.0357405977 ____ test loss 0.0194754991 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 839    iteration 74600 - train loss 0.0356237545 ____ test loss 0.0194789417 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 840    iteration 74700 - train loss 0.0355942549 ____ test loss 0.0194813066 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 841    iteration 74800 - train loss 0.0354956354 ____ test loss 0.019459426 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 842    iteration 74900 - train loss 0.0355824304 ____ test loss 0.0194629442 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 843    iteration 75000 - train loss 0.0355238697 ____ test loss 0.0193860421 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 844    iteration 75100 - train loss 0.0355089636 ____ test loss 0.019442471 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 845    iteration 75200 - train loss 0.0354846263 ____ test loss 0.0194478707 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 847    iteration 75300 - train loss 0.035623993 ____ test loss 0.0194589287 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 848    iteration 75400 - train loss 0.0356426699 ____ test loss 0.0194493661 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 849    iteration 75500 - train loss 0.0356395399 ____ test loss 0.0195557239 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 850    iteration 75600 - train loss 0.0355825106 ____ test loss 0.0195816277 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 851    iteration 75700 - train loss 0.0356015135 ____ test loss 0.0194605297 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 852    iteration 75800 - train loss 0.0356830457 ____ test loss 0.0195175273 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 853    iteration 75900 - train loss 0.0356695299 ____ test loss 0.0195191299 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 854    iteration 76000 - train loss 0.0355705903 ____ test loss 0.0195246804 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 856    iteration 76100 - train loss 0.0357727024 ____ test loss 0.0195262804 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 857    iteration 76200 - train loss 0.035762381 ____ test loss 0.0195411301 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 858    iteration 76300 - train loss 0.0355687133 ____ test loss 0.0194867331 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 859    iteration 76400 - train loss 0.0354383274 ____ test loss 0.0195583377 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 860    iteration 76500 - train loss 0.0354646851 ____ test loss 0.0194863322 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 861    iteration 76600 - train loss 0.0355082125 ____ test loss 0.0194835386 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 862    iteration 76700 - train loss 0.0353877633 ____ test loss 0.0194955069 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 863    iteration 76800 - train loss 0.0355138625 ____ test loss 0.0194984977 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 865    iteration 76900 - train loss 0.035926844 ____ test loss 0.0193906264 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 866    iteration 77000 - train loss 0.0355334059 ____ test loss 0.0193810155 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 867    iteration 77100 - train loss 0.0355546412 ____ test loss 0.0194186765 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 868    iteration 77200 - train loss 0.0355524642 ____ test loss 0.0194940008 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 869    iteration 77300 - train loss 0.0356072589 ____ test loss 0.0194998573 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 870    iteration 77400 - train loss 0.0355226453 ____ test loss 0.0195221873 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 871    iteration 77500 - train loss 0.035614184 ____ test loss 0.0194938875 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 872    iteration 77600 - train loss 0.0353648749 ____ test loss 0.019520575 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 874    iteration 77700 - train loss 0.0354032801 ____ test loss 0.0195195317 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 875    iteration 77800 - train loss 0.0356009029 ____ test loss 0.0194704866 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 876    iteration 77900 - train loss 0.0354939188 ____ test loss 0.0194835381 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 877    iteration 78000 - train loss 0.0356332001 ____ test loss 0.0194583288 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 878    iteration 78100 - train loss 0.0354498706 ____ test loss 0.019497868 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 879    iteration 78200 - train loss 0.0354931025 ____ test loss 0.0194347216 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 880    iteration 78300 - train loss 0.0355486363 ____ test loss 0.0194556067 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 881    iteration 78400 - train loss 0.0355845116 ____ test loss 0.0195152736 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 883    iteration 78500 - train loss 0.0356352763 ____ test loss 0.0195269855 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 884    iteration 78600 - train loss 0.0355925222 ____ test loss 0.0194837272 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 885    iteration 78700 - train loss 0.0355328005 ____ test loss 0.0194784131 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 886    iteration 78800 - train loss 0.0354969857 ____ test loss 0.0195514743 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 887    iteration 78900 - train loss 0.0355565519 ____ test loss 0.0195279623 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 888    iteration 79000 - train loss 0.0354642127 ____ test loss 0.0195342542 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 889    iteration 79100 - train loss 0.0356243448 ____ test loss 0.019521144 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 890    iteration 79200 - train loss 0.0356235352 ____ test loss 0.0195541794 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 892    iteration 79300 - train loss 0.0356707266 ____ test loss 0.0195535417 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 893    iteration 79400 - train loss 0.0356186935 ____ test loss 0.0194827552 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 894    iteration 79500 - train loss 0.0356117025 ____ test loss 0.0195072237 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 895    iteration 79600 - train loss 0.0357530463 ____ test loss 0.0195402319 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 896    iteration 79700 - train loss 0.0354979741 ____ test loss 0.019471951 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 897    iteration 79800 - train loss 0.0357782665 ____ test loss 0.0194729088 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 898    iteration 79900 - train loss 0.035609523 ____ test loss 0.0194218339 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 899    iteration 80000 - train loss 0.0357833818 ____ test loss 0.0194234512 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 900    iteration 80100 - train loss 0.0356214533 ____ test loss 0.0194765479 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 902    iteration 80200 - train loss 0.0356257022 ____ test loss 0.019466225 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 903    iteration 80300 - train loss 0.0355932485 ____ test loss 0.0194385603 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 904    iteration 80400 - train loss 0.0355102064 ____ test loss 0.0194272428 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 905    iteration 80500 - train loss 0.0353496476 ____ test loss 0.0194340878 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 906    iteration 80600 - train loss 0.0355896482 ____ test loss 0.0194317949 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 907    iteration 80700 - train loss 0.0356519566 ____ test loss 0.0193698769 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 908    iteration 80800 - train loss 0.0356852028 ____ test loss 0.0194243123 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 909    iteration 80900 - train loss 0.0355961051 ____ test loss 0.0194370512 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 911    iteration 81000 - train loss 0.0354898998 ____ test loss 0.0194944738 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 912    iteration 81100 - train loss 0.0354501765 ____ test loss 0.0194480961 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 913    iteration 81200 - train loss 0.0357139545 ____ test loss 0.0193716521 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 914    iteration 81300 - train loss 0.0356176572 ____ test loss 0.0193744597 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 915    iteration 81400 - train loss 0.0355550027 ____ test loss 0.0193810312 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 916    iteration 81500 - train loss 0.0356259126 ____ test loss 0.0194154022 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 917    iteration 81600 - train loss 0.0355272644 ____ test loss 0.0194302833 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 918    iteration 81700 - train loss 0.0355414868 ____ test loss 0.0193945826 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 920    iteration 81800 - train loss 0.0354998575 ____ test loss 0.0193588576 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 921    iteration 81900 - train loss 0.0353163064 ____ test loss 0.0193622261 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 922    iteration 82000 - train loss 0.0356080083 ____ test loss 0.0194636599 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 923    iteration 82100 - train loss 0.0356577368 ____ test loss 0.0194222114 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 924    iteration 82200 - train loss 0.0353068163 ____ test loss 0.0194668513 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 925    iteration 82300 - train loss 0.0355123803 ____ test loss 0.0194480473 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 926    iteration 82400 - train loss 0.0356115903 ____ test loss 0.0194808062 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 927    iteration 82500 - train loss 0.0356110552 ____ test loss 0.01943983 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 929    iteration 82600 - train loss 0.0355831691 ____ test loss 0.0194296747 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 930    iteration 82700 - train loss 0.0356027832 ____ test loss 0.0194217033 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 931    iteration 82800 - train loss 0.0355135182 ____ test loss 0.019400759 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 932    iteration 82900 - train loss 0.0356062939 ____ test loss 0.0194237534 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 933    iteration 83000 - train loss 0.0356619209 ____ test loss 0.0194453181 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 934    iteration 83100 - train loss 0.0353956756 ____ test loss 0.0194620151 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 935    iteration 83200 - train loss 0.0355224393 ____ test loss 0.0194464459 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 936    iteration 83300 - train loss 0.0355556568 ____ test loss 0.0194619994 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 938    iteration 83400 - train loss 0.0355383339 ____ test loss 0.0195544361 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 939    iteration 83500 - train loss 0.0356276326 ____ test loss 0.0195141045 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 940    iteration 83600 - train loss 0.035561378 ____ test loss 0.0195369903 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 941    iteration 83700 - train loss 0.0354108922 ____ test loss 0.0194850188 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 942    iteration 83800 - train loss 0.03573298 ____ test loss 0.0195176517 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 943    iteration 83900 - train loss 0.0356736641 ____ test loss 0.0194947574 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 944    iteration 84000 - train loss 0.0356676021 ____ test loss 0.0194742213 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 945    iteration 84100 - train loss 0.0354953836 ____ test loss 0.0194685867 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 947    iteration 84200 - train loss 0.0356616622 ____ test loss 0.0194568154 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 948    iteration 84300 - train loss 0.0359319966 ____ test loss 0.0194071375 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 949    iteration 84400 - train loss 0.0356586909 ____ test loss 0.019382187 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 950    iteration 84500 - train loss 0.0359660513 ____ test loss 0.0193611125 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 951    iteration 84600 - train loss 0.0358713227 ____ test loss 0.0193680484 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 952    iteration 84700 - train loss 0.0356117008 ____ test loss 0.0194267015 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 953    iteration 84800 - train loss 0.0357670358 ____ test loss 0.0194319024 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 954    iteration 84900 - train loss 0.0358059529 ____ test loss 0.0194603369 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 956    iteration 85000 - train loss 0.0357544055 ____ test loss 0.0194678254 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 957    iteration 85100 - train loss 0.035535578 ____ test loss 0.0194655148 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 958    iteration 85200 - train loss 0.0356645115 ____ test loss 0.0194444086 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 959    iteration 85300 - train loss 0.0355866401 ____ test loss 0.0194615956 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 960    iteration 85400 - train loss 0.0355820676 ____ test loss 0.0194440022 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 961    iteration 85500 - train loss 0.0356435964 ____ test loss 0.0193639499 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 962    iteration 85600 - train loss 0.0358431705 ____ test loss 0.0194661918 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 963    iteration 85700 - train loss 0.0355363352 ____ test loss 0.0194432621 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 965    iteration 85800 - train loss 0.0356381174 ____ test loss 0.0194549595 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 966    iteration 85900 - train loss 0.0353635332 ____ test loss 0.0193851801 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 967    iteration 86000 - train loss 0.0355261561 ____ test loss 0.0193505374 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 968    iteration 86100 - train loss 0.0355202241 ____ test loss 0.0194119167 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 969    iteration 86200 - train loss 0.0357050367 ____ test loss 0.0194384171 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 970    iteration 86300 - train loss 0.0359571269 ____ test loss 0.0194717731 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 971    iteration 86400 - train loss 0.0358132808 ____ test loss 0.0194828816 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 972    iteration 86500 - train loss 0.0355887844 ____ test loss 0.0194319722 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 974    iteration 86600 - train loss 0.0354306745 ____ test loss 0.0194342884 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 975    iteration 86700 - train loss 0.0356559404 ____ test loss 0.0194259256 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 976    iteration 86800 - train loss 0.0354468267 ____ test loss 0.0193567005 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 977    iteration 86900 - train loss 0.0355009424 ____ test loss 0.0193903739 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 978    iteration 87000 - train loss 0.0356119123 ____ test loss 0.01939329 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 979    iteration 87100 - train loss 0.0355289748 ____ test loss 0.0193852455 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 980    iteration 87200 - train loss 0.0358044723 ____ test loss 0.0194460607 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 981    iteration 87300 - train loss 0.0355653844 ____ test loss 0.0194453307 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 983    iteration 87400 - train loss 0.0357112452 ____ test loss 0.0195075966 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 984    iteration 87500 - train loss 0.035725928 ____ test loss 0.0194815911 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 985    iteration 87600 - train loss 0.0355556135 ____ test loss 0.0195106766 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 986    iteration 87700 - train loss 0.0357546178 ____ test loss 0.0194257903 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 987    iteration 87800 - train loss 0.0357056103 ____ test loss 0.0194572007 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 988    iteration 87900 - train loss 0.0355223145 ____ test loss 0.0194656769 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 989    iteration 88000 - train loss 0.0354864595 ____ test loss 0.0194336552 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 990    iteration 88100 - train loss 0.035440444 ____ test loss 0.0195111528 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 992    iteration 88200 - train loss 0.0354205429 ____ test loss 0.0194946797 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 993    iteration 88300 - train loss 0.0355725517 ____ test loss 0.0194545528 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 994    iteration 88400 - train loss 0.0354357501 ____ test loss 0.0194136281 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 995    iteration 88500 - train loss 0.0353604731 ____ test loss 0.0194879673 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 996    iteration 88600 - train loss 0.0355855454 ____ test loss 0.0194067873 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 997    iteration 88700 - train loss 0.0353698058 ____ test loss 0.0194933884 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 998    iteration 88800 - train loss 0.0355693676 ____ test loss 0.0193554829 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 999    iteration 88900 - train loss 0.0355232163 ____ test loss 0.0194175127 --- alpha: 1e-05\n",
      "train_accuracy: 100.0 - epoch 1000    iteration 89000 - train loss 0.0355804335 ____ test loss 0.0194311029 --- alpha: 1e-05\n",
      "func:'fit' -- took: 1047.2417 sec\n"
     ]
    }
   ],
   "source": [
    "# http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    input_layer=(X_train.shape[0], 'relu'),\n",
    "    hidden_layer=[(200,'relu'),(100,'relu'),(50,'softmax')],\n",
    "    output_layer=Y_train.shape[0],\n",
    "    batch_size=48,\n",
    "    optimizer={\"method\": \"ADAM\", \"beta1\": 0.9, \"beta2\": 0.999},\n",
    "    weight_initialisation = \"xavier_uniform\",\n",
    "    metrics=\"accuracy\",\n",
    "    penalty=\"l2\",\n",
    "    lambd=0.1,\n",
    "    keep_prob=0.5,\n",
    "    epoch=1000,\n",
    "    alpha={\"initial_lr\": 0.01, \"decay\": 1},\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "model.fit(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F1': 84.11214953064793,\n",
       " 'accuracy': 96.59999999980681,\n",
       " 'false_positive_rate': 3.5242290748821055,\n",
       " 'precision': 73.77049180206934,\n",
       " 'prevalence': 9.1999999999816,\n",
       " 'sensitivity/recall': 97.8260869543951,\n",
       " 'specificity': 96.47577092489763}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_model_performance(np.argmax(Y_test, axis=0),\n",
    "                           model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F1': 76.66666666362,\n",
       " 'accuracy': 94.39999999962241,\n",
       " 'false_positive_rate': 4.910714285692363,\n",
       " 'precision': 67.6470588215398,\n",
       " 'prevalence': 10.399999999958402,\n",
       " 'sensitivity/recall': 88.46153845813609,\n",
       " 'specificity': 95.08928571386122}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_model_performance(np.argmax(Y_validation, axis=0),\n",
    "                           model.predict(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(\n",
    "    model.train_error,\n",
    "    model.test_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results_dict_all_models, results_average_dict, models = grid_search(\n",
    "#     x,\n",
    "#     y,\n",
    "#     clf=NeuralNetwork,\n",
    "#     lst_metrics=[\"F1\", \"accuracy\"],\n",
    "#     sort_by = \"F1\",\n",
    "#     n_folds=10,\n",
    "#     dict_param_grid={\n",
    "#         'batch_size': [64, 128, 256],\n",
    "#         'input_layer': [(x.shape[1], 'relu')],\n",
    "#         'hidden_layer': [\n",
    "#             [(50, 'relu'), (25, 'relu'), (10,'softmax')],\n",
    "#             [(200, 'relu'), (100, 'relu'), (50, 'relu'), (10,'softmax')]\n",
    "#         ],\n",
    "#         'optimizer':[\n",
    "#             {\n",
    "#                 \"method\": \"ADAM\",\n",
    "#                 \"beta1\": 0.9,\n",
    "#                 \"beta2\": 0.999\n",
    "#             }\n",
    "#         ],\n",
    "#         'output_layer': [10],\n",
    "#         'alpha': [0.0001, 0.001],\n",
    "#         'verbose': [False],\n",
    "#         'epoch': [250]\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# results_average_dict\n",
    "# print(models[\"model_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_miss_clasifications(model, digits_to_display):\n",
    "    count = 0\n",
    "    for index, (act, predicted) in enumerate(zip(np.argmax(Y,axis=0), model.predict(X))):\n",
    "        if act != predicted:\n",
    "            fig, ax = plt.subplots(figsize = (2,2))\n",
    "            ax.set_title(\"%s: act %s --- predicted %s\" %(index, act, predicted))\n",
    "            ax.imshow(X[:, index].reshape(-1,20).T)\n",
    "            ax.axis('off');\n",
    "            count += 1\n",
    "        if count == digits_to_display:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_miss_clasifications(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
