{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimensions_and_activations(\n",
    "    input_layer:tuple,\n",
    "    hidden_layer:list,\n",
    "    output_layer:int\n",
    "):\n",
    "\n",
    "    dimensions = []\n",
    "    activation_functions = []\n",
    "\n",
    "    hidden_layer.insert(0, input_layer)\n",
    "\n",
    "    for dim, act_func in hidden_layer:\n",
    "        dimensions.append(dim)\n",
    "        activation_functions.append(act_func)\n",
    "        \n",
    "    dimensions.append(output_layer)\n",
    "    \n",
    "    return dimensions, activation_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight_set_dimensions(dimensions):\n",
    "    a, b = itertools.tee(dimensions[::-1])\n",
    "    next(b, None)\n",
    "    weight_set_dimensions = list(zip(a, b))[::-1]\n",
    "    \n",
    "    return weight_set_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_weights(dimensions):\n",
    "    # For single hidden layer neural network there will be 2 sets of weights;\n",
    "    # 1- one set to hidden layer\n",
    "    # 2- one set from hidden layer\n",
    "    # number of weight sets = no_of_hidden_layers + 1\n",
    "    weight_dims = calculate_weight_set_dimensions(dimensions)\n",
    "    no_of_weight_sets = len(weight_dims)\n",
    "    \n",
    "    # W_set holds weight sets such as w1, w2, w3 etc.\n",
    "    W = np.empty_like(range(no_of_weight_sets), dtype=object)\n",
    "    B = np.empty_like(range(no_of_weight_sets), dtype=object)\n",
    "    for index, (row, column) in enumerate(weight_dims):\n",
    "        np.random.seed(42)\n",
    "        W[index] = np.random.rand(row, column)\n",
    "        B[index] = np.random.rand(row, 1)\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardpass(X, W, B, dimensions):\n",
    "    weight_dims = calculate_weight_set_dimensions(dimensions)\n",
    "    no_of_weight_sets = len(weight_dims)\n",
    "\n",
    "    Z = np.empty_like(range(no_of_weight_sets + 1), dtype=object)\n",
    "    A = np.empty_like(range(no_of_weight_sets + 1), dtype=object)\n",
    "    A[0] = X\n",
    "    Z[0] = None\n",
    "    for index in range(no_of_weight_sets):\n",
    "        Z[index + 1] = W[index] @ A[index] + B[index]\n",
    "        A[index + 1] = sigmoid(Z[index + 1])\n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(Y, Y_hat):\n",
    "    m = Y.shape[1]\n",
    "    return np.sum(0.5 * np.square(Y - Y_hat)) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_final(Y, A, Z):\n",
    "    return (A[-1] - Y) * (sigmoid_prime(Z[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(A, Z, Y, B, W, dimensions, alfa):\n",
    "    m = Y.shape[1]\n",
    "    weight_dims = calculate_weight_set_dimensions(dimensions)\n",
    "    no_of_weight_sets = len(weight_dims)\n",
    "\n",
    "    delta_final = calculate_delta_final(Y, A, Z)\n",
    "    delta = np.empty_like(range(no_of_weight_sets), dtype=object)\n",
    "    delta[-1] = delta_final\n",
    "\n",
    "    gradient_W = np.empty_like(range(no_of_weight_sets), dtype=object)\n",
    "    gradient_B = np.empty_like(range(no_of_weight_sets), dtype=object)\n",
    "    \n",
    "    # here Z[index+1] is passed instead of Z[index] this is because Z[0] is none.\n",
    "    # So Z[index+1] is effectively Z[index].\n",
    "    for index in reversed(range(no_of_weight_sets - 1)): # 1 is substracted as delta_final is calculated above\n",
    "        delta[index] = W[index + 1].T @ delta[index + 1] * sigmoid_prime(Z[index + 1])\n",
    "    \n",
    "    # calculate the gradient\n",
    "    for index in range(no_of_weight_sets):\n",
    "        gradient_W[index] = (delta[index] @ A[index].T) / m\n",
    "        gradient_B[index] = delta[index]\n",
    "\n",
    "    #update the weights\n",
    "    for index, _ in enumerate(W):\n",
    "        W[index] = W[index] - alfa * gradient_W[index]\n",
    "        B[index] = B[index] - alfa * gradient_B[index]\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    no_of_iterations,\n",
    "    dimensions,\n",
    "    X,\n",
    "    Y,\n",
    "    alfa\n",
    "):\n",
    "    W, B = initialise_weights(dimensions)\n",
    "    \n",
    "    initial_weights = W[0]\n",
    "    initial_weights[0][0] = 0.15\n",
    "    initial_weights[0][1] = 0.2\n",
    "    initial_weights[1][0] = 0.25\n",
    "    initial_weights[1][1] = 0.30\n",
    "    B[0] = 0.35\n",
    "\n",
    "    second_set_of_weights = W[1]\n",
    "    second_set_of_weights[0][0] = 0.4\n",
    "    second_set_of_weights[0][1] = 0.45\n",
    "    second_set_of_weights[1][0] = 0.5\n",
    "    second_set_of_weights[1][1] = 0.55\n",
    "    B[1] = 0.6\n",
    "\n",
    "    for iteration in range(no_of_iterations + 1):\n",
    "        A, Z = forwardpass(X, W, B, dimensions)\n",
    "        W, B = backpropagation(A, Z, Y, B, W, dimensions, alfa)\n",
    "        if iteration % 100 == 0 or iteration == no_of_iterations:\n",
    "            print(\"iteration %s - loss %.10f\" %(iteration, calculate_error(Y, A[-1])))\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimensions_and_activations(\n",
    "    input_layer:tuple,\n",
    "    hidden_layer:list,\n",
    "    output_layer:int\n",
    "):\n",
    "\n",
    "    dimensions = []\n",
    "    activation_functions = []\n",
    "\n",
    "    hidden_layer.insert(0, input_layer)\n",
    "\n",
    "    for dim, act_func in hidden_layer:\n",
    "        dimensions.append(dim)\n",
    "        activation_functions.append(act_func)\n",
    "\n",
    "    dimensions.append(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([0.05, 0.10]).reshape((2, 1))\n",
    "# Y = np.array([0.01, 0.99]).reshape((2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dimensions = [2,2,2]\n",
    "\n",
    "# W, B = fit(20000, dimensions, X, Y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data[:,[0,2]].T\n",
    "y = data.target\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "Y = lb.fit_transform(y)\n",
    "Y = Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(any_):\n",
    "    for array in any_:\n",
    "        try:\n",
    "            print(array.shape)\n",
    "        except:\n",
    "            print(\"NONE\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, B = initialise_weights([2,6,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 2), (4, 6), (3, 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_weight_set_dimensions([2,6,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, Z = forwardpass(X, W, B, [2,6,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "(4, 6)\n",
      "(3, 4)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_shapes(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n",
      "(4, 1)\n",
      "(3, 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_shapes(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 150)\n",
      "(6, 150)\n",
      "(4, 150)\n",
      "(3, 150)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_shapes(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NONE\n",
      "(6, 150)\n",
      "(4, 150)\n",
      "(3, 150)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_shapes(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96550778, 0.96548475, 0.96540214, 0.96550258, 0.96549641,\n",
       "        0.96568006, 0.96544787, 0.96554871, 0.96542153, 0.96553762,\n",
       "        0.96559046, 0.96557578, 0.96547278, 0.96520908, 0.96547184,\n",
       "        0.96561934, 0.96548612, 0.96550778, 0.96570642, 0.96555953,\n",
       "        0.96568006, 0.96555953, 0.9651824 , 0.9656519 , 0.96570356,\n",
       "        0.96559717, 0.96559717, 0.96557009, 0.96551888, 0.96556467,\n",
       "        0.96557578, 0.96559046, 0.96557009, 0.9655506 , 0.96553762,\n",
       "        0.96537912, 0.96549697, 0.96548475, 0.96536103, 0.96555953,\n",
       "        0.96543999, 0.96537512, 0.96536103, 0.96559717, 0.96573118,\n",
       "        0.96547278, 0.96560748, 0.96544787, 0.96558039, 0.96549641,\n",
       "        0.96624529, 0.96621497, 0.9662519 , 0.96614496, 0.96622406,\n",
       "        0.96618959, 0.96622282, 0.96603974, 0.96622737, 0.96612268,\n",
       "        0.96607082, 0.96617704, 0.96616585, 0.96621598, 0.96611188,\n",
       "        0.96621925, 0.96618575, 0.9661656 , 0.96620798, 0.96614072,\n",
       "        0.96621447, 0.96616984, 0.96623316, 0.96621598, 0.96620261,\n",
       "        0.96621586, 0.9662441 , 0.96625045, 0.96620079, 0.96610579,\n",
       "        0.96612717, 0.96611747, 0.96614932, 0.96623299, 0.96617789,\n",
       "        0.96620079, 0.96623593, 0.96620541, 0.96615735, 0.96614496,\n",
       "        0.96617521, 0.96621033, 0.96615769, 0.96604538, 0.96616501,\n",
       "        0.96616908, 0.96616908, 0.96619536, 0.96600642, 0.96616151,\n",
       "        0.96627761, 0.96622632, 0.96629524, 0.96626338, 0.96627628,\n",
       "        0.96632586, 0.96615715, 0.96631164, 0.96628169, 0.96630369,\n",
       "        0.96624886, 0.96625443, 0.96627379, 0.96621794, 0.96622632,\n",
       "        0.96625443, 0.96626535, 0.96633029, 0.96633483, 0.96622818,\n",
       "        0.96628359, 0.96620918, 0.96633029, 0.96623316, 0.96627825,\n",
       "        0.96630074, 0.96622477, 0.96622655, 0.96626627, 0.96629457,\n",
       "        0.96630838, 0.96632722, 0.96626627, 0.96624264, 0.96625749,\n",
       "        0.96631518, 0.96626338, 0.96626246, 0.96621795, 0.96627281,\n",
       "        0.96627469, 0.96626077, 0.96622632, 0.96628763, 0.96627825,\n",
       "        0.96625916, 0.966238  , 0.96625322, 0.96625252, 0.96622968],\n",
       "       [0.79613852, 0.79607011, 0.79587079, 0.79608194, 0.79610471,\n",
       "        0.79654441, 0.79596124, 0.79621972, 0.79588403, 0.79618647,\n",
       "        0.79634563, 0.79626241, 0.79603469, 0.7954115 , 0.79612168,\n",
       "        0.79643338, 0.79611778, 0.79613852, 0.79662614, 0.79625223,\n",
       "        0.79654441, 0.79625223, 0.79538736, 0.79645762, 0.79655065,\n",
       "        0.79632713, 0.79632713, 0.79628403, 0.79617159, 0.79622893,\n",
       "        0.79626241, 0.79634563, 0.79628403, 0.79626657, 0.79618647,\n",
       "        0.79584981, 0.79615   , 0.79607011, 0.7957514 , 0.79625223,\n",
       "        0.79598158, 0.79579223, 0.7957514 , 0.79632713, 0.7966368 ,\n",
       "        0.79603469, 0.79635843, 0.79596124, 0.79631516, 0.79610471,\n",
       "        0.79801177, 0.79790756, 0.7980302 , 0.79767891, 0.79793712,\n",
       "        0.79781486, 0.79792911, 0.79736865, 0.79794927, 0.79760583,\n",
       "        0.79745567, 0.79778312, 0.79775406, 0.79790399, 0.79759087,\n",
       "        0.79792732, 0.79780085, 0.7977472 , 0.79788199, 0.79767027,\n",
       "        0.79789519, 0.79776845, 0.79796104, 0.79790399, 0.79787107,\n",
       "        0.79791494, 0.79800427, 0.79802226, 0.7978557 , 0.79757847,\n",
       "        0.797629  , 0.79760226, 0.79770109, 0.79795528, 0.79777224,\n",
       "        0.7978557 , 0.79797731, 0.79787677, 0.79771745, 0.79767891,\n",
       "        0.79776677, 0.79788678, 0.79772465, 0.79738814, 0.79773957,\n",
       "        0.7977543 , 0.7977543 , 0.79784465, 0.79729265, 0.79773243,\n",
       "        0.7981065 , 0.79793066, 0.79817341, 0.79805848, 0.7981038 ,\n",
       "        0.79828249, 0.79769699, 0.79823112, 0.79812397, 0.79820304,\n",
       "        0.79801394, 0.79803034, 0.79809875, 0.79790226, 0.79793066,\n",
       "        0.79803034, 0.79806736, 0.79829858, 0.79831469, 0.79794001,\n",
       "        0.79813234, 0.79787278, 0.79829858, 0.79796104, 0.79811243,\n",
       "        0.79819295, 0.79793306, 0.79793669, 0.79806922, 0.79817205,\n",
       "        0.79822059, 0.79828884, 0.79806922, 0.79799096, 0.79803655,\n",
       "        0.79824603, 0.79805848, 0.79805661, 0.79790799, 0.79809676,\n",
       "        0.79810059, 0.79805805, 0.79793066, 0.79814498, 0.79811243,\n",
       "        0.7980499 , 0.79797623, 0.79802788, 0.79802137, 0.79794306],\n",
       "       [0.91351654, 0.91346417, 0.91330243, 0.91348136, 0.91349066,\n",
       "        0.91384842, 0.9133807 , 0.91358673, 0.91332141, 0.91356132,\n",
       "        0.91368284, 0.91362684, 0.91343703, 0.91292828, 0.91348565,\n",
       "        0.91374976, 0.91349195, 0.91351654, 0.91391047, 0.91361156,\n",
       "        0.91384842, 0.91361156, 0.91289847, 0.91378247, 0.91386547,\n",
       "        0.9136762 , 0.9136762 , 0.91363584, 0.91354184, 0.91360128,\n",
       "        0.91362684, 0.91368284, 0.91363584, 0.91361448, 0.91356132,\n",
       "        0.9132768 , 0.91351664, 0.91346417, 0.91321057, 0.91361156,\n",
       "        0.91338752, 0.91324201, 0.91321057, 0.9136762 , 0.91393076,\n",
       "        0.91343703, 0.91370005, 0.9133807 , 0.91365959, 0.91349066,\n",
       "        0.91501543, 0.91493821, 0.91502984, 0.91476658, 0.91496041,\n",
       "        0.91487043, 0.91495513, 0.91452772, 0.91496928, 0.91471176,\n",
       "        0.9145956 , 0.91484492, 0.91482176, 0.9149368 , 0.91469693,\n",
       "        0.91495198, 0.91486018, 0.91481769, 0.91491952, 0.91475917,\n",
       "        0.91493091, 0.91483232, 0.91497944, 0.9149368 , 0.91491012,\n",
       "        0.91494293, 0.91501048, 0.91502449, 0.9149003 , 0.9146863 ,\n",
       "        0.91472765, 0.9147067 , 0.91478181, 0.91497609, 0.91483924,\n",
       "        0.9149003 , 0.91499031, 0.91491502, 0.91479587, 0.91476658,\n",
       "        0.91483453, 0.91492365, 0.91480018, 0.91454217, 0.914813  ,\n",
       "        0.91482379, 0.91482379, 0.91489079, 0.91446495, 0.91480686,\n",
       "        0.91508856, 0.91495815, 0.91513695, 0.91505281, 0.91508621,\n",
       "        0.91521699, 0.91478407, 0.91517944, 0.91510086, 0.91515879,\n",
       "        0.91501883, 0.91503148, 0.91508183, 0.91493701, 0.91495815,\n",
       "        0.91503148, 0.91505901, 0.91522874, 0.91524057, 0.91496455,\n",
       "        0.91510672, 0.91491504, 0.91522874, 0.91497944, 0.91509226,\n",
       "        0.91515131, 0.91495855, 0.91496168, 0.91506062, 0.91513577,\n",
       "        0.91517151, 0.91522138, 0.91506062, 0.91500209, 0.91503686,\n",
       "        0.91518995, 0.91505281, 0.91505119, 0.91494025, 0.9150801 ,\n",
       "        0.91508342, 0.91505094, 0.91495815, 0.91511631, 0.91509226,\n",
       "        0.91504538, 0.91499095, 0.91502935, 0.91502527, 0.91496718]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00114868, -0.00115018, -0.0011556 , -0.00114902, -0.00114942,\n",
       "        -0.00113743, -0.0011526 , -0.001146  , -0.00115433, -0.00114673,\n",
       "        -0.00114327, -0.00114423, -0.00115097, -0.0011683 , -0.00115103,\n",
       "        -0.00114139, -0.00115009, -0.00114868, -0.00113572, -0.00114529,\n",
       "        -0.00113743, -0.00114529, -0.00117006, -0.00113927, -0.0011359 ,\n",
       "        -0.00114284, -0.00114284, -0.00114461, -0.00114795, -0.00114496,\n",
       "        -0.00114423, -0.00114327, -0.00114461, -0.00114588, -0.00114673,\n",
       "        -0.00115711, -0.00114938, -0.00115018, -0.0011583 , -0.00114529,\n",
       "        -0.00115312, -0.00115737, -0.0011583 , -0.00114284, -0.00113411,\n",
       "        -0.00115097, -0.00114216, -0.0011526 , -0.00114393, -0.00114942,\n",
       "         0.03151441,  0.03154074,  0.03150867,  0.03160152,  0.03153284,\n",
       "         0.03156277,  0.03153392,  0.03169283,  0.03152997,  0.03162086,\n",
       "         0.03166586,  0.03157367,  0.03158338,  0.03153986,  0.03163023,\n",
       "         0.03153702,  0.03156611,  0.0315836 ,  0.03154681,  0.0316052 ,\n",
       "         0.03154117,  0.03157992,  0.03152494,  0.03153986,  0.03155147,\n",
       "         0.03153996,  0.03151544,  0.03150992,  0.03155305,  0.03163552,\n",
       "         0.03161696,  0.03162538,  0.03159773,  0.03152509,  0.03157293,\n",
       "         0.03155305,  0.03152253,  0.03154904,  0.03159076,  0.03160152,\n",
       "         0.03157526,  0.03154476,  0.03159047,  0.03168793,  0.03158411,\n",
       "         0.03158058,  0.03158058,  0.03155776,  0.03172174,  0.03158715,\n",
       "         0.03148634,  0.03153088,  0.03147103,  0.0314987 ,  0.0314875 ,\n",
       "         0.03144443,  0.03159094,  0.03145678,  0.0314828 ,  0.03146368,\n",
       "         0.03151131,  0.03150647,  0.03148966,  0.03153816,  0.03153088,\n",
       "         0.03150647,  0.03149698,  0.03144058,  0.03143664,  0.03152926,\n",
       "         0.03148115,  0.03154576,  0.03144058,  0.03152494,  0.03148579,\n",
       "         0.03146625,  0.03153223,  0.03153068,  0.03149619,  0.03147161,\n",
       "         0.03145961,  0.03144325,  0.03149619,  0.03151671,  0.03150382,\n",
       "         0.03145371,  0.0314987 ,  0.0314995 ,  0.03153815,  0.03149051,\n",
       "         0.03148887,  0.03150097,  0.03153088,  0.03147764,  0.03148579,\n",
       "         0.03150236,  0.03152074,  0.03150752,  0.03150813,  0.03152796],\n",
       "       [ 0.12921486,  0.129236  ,  0.12929755,  0.12923235,  0.12922531,\n",
       "         0.12908911,  0.12926963,  0.12918974,  0.12929346,  0.12920003,\n",
       "         0.12915075,  0.12917652,  0.12924695,  0.12943894,  0.12922006,\n",
       "         0.12912355,  0.12922127,  0.12921486,  0.12906374,  0.12917967,\n",
       "         0.12908911,  0.12917967,  0.12944636,  0.12911604,  0.12908717,\n",
       "         0.12915648,  0.12915648,  0.12916983,  0.12920463,  0.12918689,\n",
       "         0.12917652,  0.12915075,  0.12916983,  0.12917523,  0.12920003,\n",
       "         0.12930402,  0.12921131,  0.129236  ,  0.12933436,  0.12917967,\n",
       "         0.12926335,  0.12932177,  0.12933436,  0.12915648,  0.12906043,\n",
       "         0.12924695,  0.12914679,  0.12926963,  0.12916019,  0.12922531,\n",
       "        -0.03255828, -0.03258763, -0.03255309, -0.03265205, -0.0325793 ,\n",
       "        -0.03261374, -0.03258156, -0.03273953, -0.03257588, -0.03267265,\n",
       "        -0.03271498, -0.03262268, -0.03263087, -0.03258863, -0.03267686,\n",
       "        -0.03258206, -0.03261768, -0.0326328 , -0.03259483, -0.03265448,\n",
       "        -0.03259111, -0.03262681, -0.03257256, -0.03258863, -0.0325979 ,\n",
       "        -0.03258555, -0.03256039, -0.03255532, -0.03260223, -0.03268036,\n",
       "        -0.03266612, -0.03267365, -0.0326458 , -0.03257419, -0.03262575,\n",
       "        -0.03260223, -0.03256798, -0.0325963 , -0.03264119, -0.03265205,\n",
       "        -0.03262729, -0.03259348, -0.03263916, -0.03273403, -0.03263495,\n",
       "        -0.0326308 , -0.0326308 , -0.03260535, -0.03276097, -0.03263696,\n",
       "         0.12860091,  0.1286562 ,  0.12857984,  0.12861602,  0.12860176,\n",
       "         0.12854548,  0.12872955,  0.12856167,  0.12859541,  0.12857051,\n",
       "         0.12863003,  0.12862487,  0.12860334,  0.12866513,  0.1286562 ,\n",
       "         0.12862487,  0.12861322,  0.12854041,  0.12853533,  0.12865326,\n",
       "         0.12859277,  0.12867438,  0.12854041,  0.12864666,  0.12859904,\n",
       "         0.12857369,  0.12865545,  0.12865431,  0.12861264,  0.12858027,\n",
       "         0.12856498,  0.12854348,  0.12861264,  0.12863725,  0.12862292,\n",
       "         0.12855697,  0.12861602,  0.12861661,  0.12866332,  0.12860397,\n",
       "         0.12860277,  0.12861615,  0.1286562 ,  0.1285888 ,  0.12859904,\n",
       "         0.12861871,  0.12864188,  0.12862564,  0.12862769,  0.12865231],\n",
       "       [ 0.07217152,  0.07220695,  0.07231629,  0.07219532,  0.07218903,\n",
       "         0.07194682,  0.07226339,  0.07212403,  0.07230347,  0.07214123,\n",
       "         0.07205897,  0.07209688,  0.07222531,  0.07256889,  0.07219242,\n",
       "         0.07201366,  0.07218816,  0.07217152,  0.07190476,  0.07210723,\n",
       "         0.07194682,  0.07210723,  0.07258899,  0.0719915 ,  0.07193526,\n",
       "         0.07206347,  0.07206347,  0.07209079,  0.07215441,  0.07211418,\n",
       "         0.07209688,  0.07205897,  0.07209079,  0.07210526,  0.07214123,\n",
       "         0.07233361,  0.07217146,  0.07220695,  0.07237835,  0.07210723,\n",
       "         0.07225878,  0.07235712,  0.07237835,  0.07206347,  0.07189101,\n",
       "         0.07222531,  0.07204732,  0.07226339,  0.07207471,  0.07218903,\n",
       "         0.0711536 ,  0.07120624,  0.07114378,  0.07132314,  0.07119111,\n",
       "         0.07125242,  0.07119471,  0.07148568,  0.07118506,  0.07136046,\n",
       "         0.07143951,  0.0712698 ,  0.07128557,  0.0712072 ,  0.07137056,\n",
       "         0.07119686,  0.0712594 ,  0.07128834,  0.07121897,  0.07132819,\n",
       "         0.07121122,  0.07127838,  0.07117814,  0.0712072 ,  0.07122538,\n",
       "         0.07120302,  0.07115698,  0.07114743,  0.07123207,  0.0713778 ,\n",
       "         0.07134965,  0.07136391,  0.07131277,  0.07118042,  0.07127367,\n",
       "         0.07123207,  0.07117073,  0.07122204,  0.0713032 ,  0.07132314,\n",
       "         0.07127688,  0.07121616,  0.07130027,  0.07147585,  0.07129154,\n",
       "         0.07128419,  0.07128419,  0.07123855,  0.07152835,  0.07129572,\n",
       "        -0.00659775, -0.00661708, -0.00659058, -0.00660304, -0.00659809,\n",
       "        -0.00657872, -0.00664294, -0.00658428, -0.00659592, -0.00658734,\n",
       "        -0.00660808, -0.00660621, -0.00659874, -0.00662022, -0.00661708,\n",
       "        -0.00660621, -0.00660213, -0.00657699, -0.00657524, -0.00661613,\n",
       "        -0.00659505, -0.00662348, -0.00657699, -0.00661393, -0.0065972 ,\n",
       "        -0.00658845, -0.00661702, -0.00661656, -0.00660189, -0.00659075,\n",
       "        -0.00658546, -0.00657808, -0.00660189, -0.00661057, -0.00660541,\n",
       "        -0.00658273, -0.00660304, -0.00660328, -0.00661974, -0.006599  ,\n",
       "        -0.00659851, -0.00660332, -0.00661708, -0.00659363, -0.0065972 ,\n",
       "        -0.00660415, -0.00661222, -0.00660652, -0.00660713, -0.00661574]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_delta_final(Y, A, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[-1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[-1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Benchmark Datasets - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data[:,[0,2]].T\n",
    "y = data.target\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "Y = lb.fit_transform(y)\n",
    "Y = Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dimensions = [X.shape[0], 6, 4, 3]\n",
    "\n",
    "W, B = fit(50000, dimensions, X, Y, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, Z = forwardpass(X, W, B, dimensions)\n",
    "y_hat = A[-1]\n",
    "\n",
    "for index,(act, predicted) in enumerate(zip(y, np.argmax(A[-1], axis = 0))):\n",
    "    print(\"index: %s___actual %s__predicted %s\" %(index, act, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =make_moons(n_samples=1500, noise=.05)\n",
    "X = x.T\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "Y = lb.fit_transform(y)\n",
    "y_next = np.where(y==0,1,0)\n",
    "Y = Y.T\n",
    "Y = list(Y)\n",
    "Y.append(y_next)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dimensions = [X.shape[0], 6, 4, Y.shape[0]]\n",
    "\n",
    "W, B = fit(50000, dimensions, X, Y, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A, Z = forwardpass(X, W, B, dimensions)\n",
    "y_hat = A[-1]\n",
    "\n",
    "for index,(act, predicted) in enumerate(zip(y, np.argmax(A[-1], axis = 0))):\n",
    "    if predicted == 1:\n",
    "        predicted = 0\n",
    "    else:\n",
    "        predicted = 1\n",
    "    if predicted != act:\n",
    "        print(\"NO MATCH!\")\n",
    "    print(\"index: %s___actual %s__predicted %s\" %(index, act, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# Divide the dataset as negatives and positives.\n",
    "dataset = np.c_[x,y]\n",
    "negatives = dataset[dataset[:, -1] == 0]\n",
    "positives = dataset[dataset[:, -1] == 1]\n",
    "\n",
    "# Make the plot pretty.\n",
    "ax.set_xlabel(\"Class 1\", fontsize=15, labelpad=10)\n",
    "ax.set_ylabel(\"Class 2\", fontsize=15, labelpad=10)\n",
    "ax.set_title(\"Class 1 vs Class 2\", fontsize=20)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "# Plot both negative and positive classes to the same figure.\n",
    "plot_data(ax, negatives[:, 0], negatives[:, 1], param_dict={\"c\": \"black\", \"marker\": \"x\", \"label\": \"not admitted\"})\n",
    "plot_data(ax, positives[:, 0], positives[:, 1], param_dict={\"c\": \"y\", \"marker\": \"d\", \"label\": \"admitted\"})\n",
    "ax.legend(prop={'size': 14});\n",
    "\n",
    "# Get the decision boundary and plot it within the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1, 10, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(\n",
    "    ax,\n",
    "    data1,\n",
    "    data2,\n",
    "    param_dict\n",
    "):\n",
    "\n",
    "    ax.scatter(data1, data2, **param_dict)\n",
    "\n",
    "\n",
    "def get_decision_boundary(\n",
    "    X,\n",
    "    thetas,\n",
    "    is_polynomial=False,\n",
    "    PolynomialFeatures_instance=None\n",
    "):\n",
    "    thetas = thetas.reshape(-1, 1)\n",
    "\n",
    "    x1_min, x1_max = X[:, 0].min(), X[:, 0].max(),\n",
    "    x2_min, x2_max = X[:, 1].min(), X[:, 1].max(),\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "\n",
    "    if is_polynomial:\n",
    "        h = sigmoid(PolynomialFeatures_instance.fit_transform(np.c_[xx1.flatten(), xx2.flatten()]) @ (thetas))\n",
    "\n",
    "    else:\n",
    "        constant = np.ones((xx1.flatten().shape[0], 1))\n",
    "        h = sigmoid(np.c_[constant, xx1.flatten(), xx2.flatten()] @ (thetas))\n",
    "\n",
    "    h = h.reshape(xx1.shape)\n",
    "\n",
    "    return xx1, xx2, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# W, B = initialise_weights(dimensions)\n",
    "\n",
    "# initial_weights = W[0]\n",
    "# initial_weights[0][0] = 0.15\n",
    "# initial_weights[0][1] = 0.2\n",
    "# initial_weights[1][0] = 0.25\n",
    "# initial_weights[1][1] = 0.30\n",
    "# B[0] = 0.35\n",
    "\n",
    "# second_set_of_weights = W[1]\n",
    "# second_set_of_weights[0][0] = 0.4\n",
    "# second_set_of_weights[0][1] = 0.45\n",
    "# second_set_of_weights[1][0] = 0.5\n",
    "# second_set_of_weights[1][1] = 0.55\n",
    "# B[1] = 0.6\n",
    "\n",
    "# A, Z = forwardpass(X, W, B)\n",
    "# J = calculate_error(Y, A[-1])\n",
    "# W = backpropagation(A, Z, Y, W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
